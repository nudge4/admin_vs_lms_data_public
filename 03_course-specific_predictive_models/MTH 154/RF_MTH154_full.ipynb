{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script fits the random forest model for the course MTH 154, using the full set of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from scipy.stats.mstats import gmean\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_dir = \"~\\\\Box Sync\\\\Clickstream\\\\evaluation_results\\\\full\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sn_dict = {\"Blue Ridge\": \"BRCC\",\n",
    "           \"Central Virginia\": \"CVCC\",\n",
    "           \"Dabney S. Lancaster\": \"DSLCC\",\n",
    "           \"Danville\": \"DCC\",\n",
    "           \"Eastern Shore\": \"ESCC\",\n",
    "           \"Germanna\": \"GCC\",\n",
    "           'J. Sargeant Reynolds': \"JSRCC\",\n",
    "           'John Tyler': \"JTCC\",\n",
    "           \"Lord Fairfax\": \"LFCC\",\n",
    "           \"Mountain Empire\": \"MECC\",\n",
    "           \"New River\": \"NRCC\",\n",
    "           \"Northern Virginia\": \"NVCC\",\n",
    "           \"Patrick Henry\": \"PHCC\",\n",
    "           \"Paul D. Camp\": \"PDCCC\",\n",
    "           \"Piedmont Virginia\": \"PVCC\",\n",
    "           \"Rappahannock\": \"RCC\",\n",
    "           \"Southside Virginia\": \"SSVCC\",\n",
    "           \"Southwest Virginia\": \"SWVCC\",\n",
    "           \"Thomas Nelson\": \"TNCC\",\n",
    "           \"Tidewater\": \"TCC\",\n",
    "           \"Virginia Highlands\": \"VHCC\",\n",
    "           \"Virginia Western\": \"VWCC\",\n",
    "           \"Wytheville\": \"WCC\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\LMS_data_final_full_new.csv\")\n",
    "df1 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\course_specific_predictors_new.csv\")\n",
    "df2 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\term_specific_predictors_new.csv\")\n",
    "df3 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\cluster_specific_predictors.csv\")\n",
    "df3 = df3.loc[:,['vccsid','strm','college','course','section'] + [e for e in df3.columns.values if e.endswith(\"MTH\") or e.endswith(\"MTH_grade\")]]\n",
    "df4 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\instructor_related_predictors.dta\")\n",
    "df = df0.merge(df1, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df2, how='inner', on=['vccsid','strm'])\\\n",
    ".merge(df3, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df4, how='inner', on=['vccsid','strm','college','course','section'])\n",
    "df = df[df.course == \"MTH_154\"]\n",
    "df.loc[:,'first_ind'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df0 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\LMS_data_final.dta\")\n",
    "df1 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\course_specific_predictors_new.csv\")\n",
    "df2 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\term_specific_predictors_new.csv\")\n",
    "df4 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\instructor_related_predictors.dta\")\n",
    "df5 = df0.loc[:,['vccsid','strm','college','course','section']].copy()\n",
    "df_first = df0.merge(df1, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df2, how='inner', on=['vccsid','strm'])\\\n",
    ".merge(df4, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df5, how='inner', on=['vccsid','strm','college','course','section'])\n",
    "df_first = df_first[df_first.course == \"MTH_154\"]\n",
    "df_first.loc[:,'first_ind'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df, df_first], axis=0, join='outer').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 18892, 1: 6283})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df.first_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for v in [int(e) for e in np.unique(df.cip) if e != 0]:\n",
    "    df.loc[:,'cip_'+str(v)] = (df.cip == v).astype(int)\n",
    "for v in [int(e) for e in np.unique(df.degree_level) if e != 4]:\n",
    "    df.loc[:,'degree_level_'+str(v)] = (df.degree_level == v).astype(int)\n",
    "df = df.drop(['cip', 'degree_level'], axis=1)\n",
    "df.loc[:,'college_new'] = df.college.apply(lambda x: sn_dict[x])\n",
    "for sn in [e for e in sn_dict.values() if e != \"BRCC\"]:\n",
    "    df.loc[:,'college_'+sn] = (df.college_new == sn).astype(int)\n",
    "df = df.drop(['college_new'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>has_prereq_grade</th>\n",
       "      <td>25175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lvl2_ind</th>\n",
       "      <td>25175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prereq_grade</th>\n",
       "      <td>25175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count  mean  std  min  25%  50%  75%  max\n",
       "has_prereq_grade  25175.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "lvl2_ind          25175.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "prereq_grade      25175.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.describe().T\n",
    "test[test['mean'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['lvl2_ind', 'has_prereq_grade', 'prereq_grade'], axis=1)\n",
    "predictors = [e for e in list(df.columns) if e not in {\"grade\",'vccsid','strm','college','course','section'}]\n",
    "len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert pd.isnull(df).any().any() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25175, 154)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19437, 154) (5738, 154)\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df.strm != 2212]\n",
    "test_df = df[df.strm == 2212]\n",
    "original_test_grade = np.array(test_df.grade)\n",
    "train_df.loc[:,'grade'] = train_df.apply(lambda x: 1 if x.loc['grade'] in {'A','B','C'} else 0, axis=1)\n",
    "test_df.loc[:,'grade'] = test_df.apply(lambda x: 1 if x.loc['grade'] in {'A','B','C'} else 0, axis=1)\n",
    "print(train_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "online_ind_df_1 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\updated_online_ind.dta\")\n",
    "online_ind_df_2 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\updated_online_ind.dta\")\n",
    "online_ind_df = pd.concat([online_ind_df_1, online_ind_df_2])\n",
    "test_df = test_df.merge(online_ind_df, how='inner', on=['vccsid','strm','college','course','section'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 5572, 1.0: 166})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(test_df.inperson_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[np.array(test_df.inperson_ind == 1) & np.array(test_df.first_ind == 1)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cv_folds(train, n_fold = 5):\n",
    "    folds = []\n",
    "    k_fold = StratifiedKFold(n_splits = n_fold, random_state = 12345, shuffle=True)\n",
    "    for train_indices, test_indices in k_fold.split(train, train.grade):\n",
    "        train_part = train.iloc[train_indices,:]\n",
    "        test_part = train.iloc[test_indices,:]\n",
    "        X_1 = train_part.loc[:,predictors]\n",
    "        y_1 = train_part.grade\n",
    "        X_2 = test_part.loc[:,predictors]\n",
    "        y_2 = test_part.grade\n",
    "        folds.append([(X_1.copy(),y_1.copy()),(X_2.copy(),y_2.copy())])\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "five_folds = create_cv_folds(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_RF(rf_model, folds):\n",
    "    auc_by_fold = []\n",
    "    for f in folds:\n",
    "        X_1 = f[0][0]\n",
    "        y_1 = f[0][1]\n",
    "        X_2 = f[1][0]\n",
    "        y_2 = f[1][1]\n",
    "        rf_model.fit(X_1,y_1)\n",
    "        y_2_pred = rf_model.predict_proba(X_2)[:,1]\n",
    "        auc_by_fold.append(roc_auc_score(y_2,y_2_pred))\n",
    "    return round(np.mean(auc_by_fold),4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_cw(y):\n",
    "    # Calculate the weight of each letter grade to be used in the modeling fitting procedure: the weight is inversely proportional to the square root of the frequency of the letter grade in the training sample\n",
    "    cw = Counter(y)\n",
    "    class_weight = {k:np.sqrt(cw.most_common()[0][-1]/v, dtype=np.float32) for k,v in cw.items()}\n",
    "    return class_weight # The output is a dictionary mapping letter grade to the corresponding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_depth = 2\n",
      "Mean CV AUC: 0.7379\n",
      "\n",
      "Max_depth = 3\n",
      "Mean CV AUC: 0.7479\n",
      "\n",
      "Max_depth = 4\n",
      "Mean CV AUC: 0.7568\n",
      "\n",
      "Max_depth = 5\n",
      "Mean CV AUC: 0.7654\n",
      "\n",
      "Max_depth = 6\n",
      "Mean CV AUC: 0.7713\n",
      "\n",
      "Max_depth = 7\n",
      "Mean CV AUC: 0.7778\n",
      "\n",
      "Max_depth = 8\n",
      "Mean CV AUC: 0.7816\n",
      "\n",
      "Max_depth = 9\n",
      "Mean CV AUC: 0.7862\n",
      "\n",
      "Max_depth = 10\n",
      "Mean CV AUC: 0.7892\n",
      "\n",
      "Max_depth = 11\n",
      "Mean CV AUC: 0.7931\n",
      "\n",
      "Max_depth = 12\n",
      "Mean CV AUC: 0.7953\n",
      "\n",
      "Max_depth = 13\n",
      "Mean CV AUC: 0.7962\n",
      "\n",
      "Max_depth = 14\n",
      "Mean CV AUC: 0.7976\n",
      "\n",
      "Max_depth = 15\n",
      "Mean CV AUC: 0.7985\n",
      "\n",
      "Max_depth = 16\n",
      "Mean CV AUC: 0.7993\n",
      "\n",
      "Max_depth = 17\n",
      "Mean CV AUC: 0.8011\n",
      "\n",
      "Max_depth = 18\n",
      "Mean CV AUC: 0.8029\n",
      "\n",
      "Max_depth = 19\n",
      "Mean CV AUC: 0.8026\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-05f00e2a8144>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m                                 \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"auto\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                 class_weight = calc_cw(train_df.grade))\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation_RF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfive_folds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mauc_by_d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Max_depth =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-fb80a74de69f>\u001b[0m in \u001b[0;36mcross_validation_RF\u001b[1;34m(rf_model, folds)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mX_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0my_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0my_2_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mauc_by_fold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_2_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    333\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 335\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 996\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    997\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    900\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 602\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Using grid search to find the optimal maximum tree depth\n",
    "auc_by_d=[]\n",
    "for d in range(2,26):\n",
    "    rf = RandomForestClassifier(n_estimators=200, criterion=\"entropy\", \n",
    "                                max_depth=d,\n",
    "                                random_state=0, n_jobs=20, max_features=\"auto\",\n",
    "                                class_weight = calc_cw(train_df.grade))\n",
    "    auc = cross_validation_RF(rf, five_folds)\n",
    "    auc_by_d.append(auc)\n",
    "    print(\"Max_depth =\", d)\n",
    "    print(\"Mean CV AUC:\", auc)\n",
    "    print(\"\")\n",
    "plt.plot(range(2,26),auc_by_d)\n",
    "plt.xlabel(\"Maximum Depth\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trees = 100\n",
      "Mean CV AUC: 0.7942\n",
      "\n",
      "Number of Trees = 120\n",
      "Mean CV AUC: 0.7946\n",
      "\n",
      "Number of Trees = 140\n",
      "Mean CV AUC: 0.7944\n",
      "\n",
      "Number of Trees = 160\n",
      "Mean CV AUC: 0.7948\n",
      "\n",
      "Number of Trees = 180\n",
      "Mean CV AUC: 0.7953\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-3a1db1cceabf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m                                 \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"auto\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                 class_weight = calc_cw(train_df.grade))\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation_RF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfive_folds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mauc_by_n\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of Trees =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-fb80a74de69f>\u001b[0m in \u001b[0;36mcross_validation_RF\u001b[1;34m(rf_model, folds)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mX_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0my_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0my_2_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mauc_by_fold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_2_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[1;32m--> 321\u001b[1;33m                                             random_state=random_state)\n\u001b[0m\u001b[0;32m    322\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[1;34m(self, append, random_state)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         estimator.set_params(**dict((p, getattr(self, p))\n\u001b[1;32m--> 128\u001b[1;33m                                     for p in self.estimator_params))\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# Simple optimization to gain speed (inspect is slow)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[0mvalid_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0mnested_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# grouped by prefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mget_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \"\"\"\n\u001b[0;32m    180\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdeep\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'get_params'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;31m# introspect the constructor arguments to find the model parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;31m# to represent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0minit_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m         \u001b[1;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36msignature\u001b[1;34m(obj, follow_wrapped)\u001b[0m\n\u001b[0;32m   2986\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2987\u001b[0m     \u001b[1;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2988\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2990\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[1;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[0;32m   2736\u001b[0m         \u001b[1;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2737\u001b[0m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[1;32m-> 2738\u001b[1;33m                                         follow_wrapper_chains=follow_wrapped)\n\u001b[0m\u001b[0;32m   2739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2740\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[1;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[0;32m   2225\u001b[0m         \u001b[1;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m         \u001b[1;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2227\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_signature_from_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_signature_is_builtin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[1;34m(cls, func)\u001b[0m\n\u001b[0;32m   2108\u001b[0m         parameters.append(Parameter(name, annotation=annotation,\n\u001b[0;32m   2109\u001b[0m                                     \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_POSITIONAL_OR_KEYWORD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2110\u001b[1;33m                                     default=defaults[offset]))\n\u001b[0m\u001b[0;32m   2111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2112\u001b[0m     \u001b[1;31m# *args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[0;32m   2410\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2411\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2412\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_annotation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mannotation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2414\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0m_empty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Using grid search to find the optimal number of estimators (trees)\n",
    "auc_by_n = []\n",
    "for n in range(100,320,20):\n",
    "    rf = RandomForestClassifier(n_estimators=n, criterion=\"entropy\", \n",
    "                                max_depth=12,\n",
    "                                random_state=0, n_jobs=-1, max_features=\"auto\",\n",
    "                                class_weight = calc_cw(train_df.grade))\n",
    "    auc = cross_validation_RF(rf, five_folds)\n",
    "    auc_by_n.append(auc)\n",
    "    print(\"Number of Trees =\", n)\n",
    "    print(\"Mean CV AUC:\", auc)\n",
    "    print(\"\")\n",
    "plt.plot(range(100,320,20), auc_by_n)\n",
    "plt.xlabel(\"Number of Trees\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_features = 2\n",
      "Mean CV AUC: 0.7614\n",
      "\n",
      "Max_features = 3\n",
      "Mean CV AUC: 0.7705\n",
      "\n",
      "Max_features = 4\n",
      "Mean CV AUC: 0.7757\n",
      "\n",
      "Max_features = 5\n",
      "Mean CV AUC: 0.7775\n",
      "\n",
      "Max_features = 6\n",
      "Mean CV AUC: 0.7828\n",
      "\n",
      "Max_features = 7\n",
      "Mean CV AUC: 0.784\n",
      "\n",
      "Max_features = 8\n",
      "Mean CV AUC: 0.7877\n",
      "\n",
      "Max_features = 9\n",
      "Mean CV AUC: 0.7897\n",
      "\n",
      "Max_features = 10\n",
      "Mean CV AUC: 0.7911\n",
      "\n",
      "Max_features = 11\n",
      "Mean CV AUC: 0.7917\n",
      "\n",
      "Max_features = 12\n",
      "Mean CV AUC: 0.7946\n",
      "\n",
      "Max_features = 13\n",
      "Mean CV AUC: 0.7946\n",
      "\n",
      "Max_features = 14\n",
      "Mean CV AUC: 0.7949\n",
      "\n",
      "Max_features = 15\n",
      "Mean CV AUC: 0.7967\n",
      "\n",
      "Max_features = 16\n",
      "Mean CV AUC: 0.7969\n",
      "\n",
      "Max_features = 17\n",
      "Mean CV AUC: 0.7975\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-91e06f038a94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m                                 \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                 class_weight = calc_cw(train_df.grade))\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation_RF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfive_folds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mauc_by_nf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Max_features =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-fb80a74de69f>\u001b[0m in \u001b[0;36mcross_validation_RF\u001b[1;34m(rf_model, folds)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mX_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0my_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0my_2_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mauc_by_fold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_2_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    333\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 335\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 996\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    997\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    900\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 602\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Using grid search to find the optimal maximum number of features (trees)\n",
    "auc_by_nf = []\n",
    "max_nf = int(np.floor(2*np.sqrt(len(predictors))))\n",
    "for nf in range(2,max_nf+1):\n",
    "    rf = RandomForestClassifier(n_estimators=120, criterion=\"entropy\", \n",
    "                                max_depth=12,\n",
    "                                random_state=0, n_jobs=-1, max_features=nf,\n",
    "                                class_weight = calc_cw(train_df.grade))\n",
    "    auc = cross_validation_RF(rf, five_folds)\n",
    "    auc_by_nf.append(auc)\n",
    "    print(\"Max_features =\", nf)\n",
    "    print(\"Mean CV AUC:\", auc)\n",
    "    print(\"\")\n",
    "plt.plot(range(2,max_nf+1), auc_by_nf)\n",
    "plt.xlabel(\"Maximum Number of Features\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight={0: 1.3534144, 1: 1.0},\n",
       "            criterion='entropy', max_depth=12, max_features=12,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=120, n_jobs=-1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=120, criterion=\"entropy\",\n",
    "                            max_depth=12,\n",
    "                            random_state=0, n_jobs=-1, max_features=12,\n",
    "                            class_weight = calc_cw(train_df.grade))\n",
    "rf.fit(train_df.loc[:,predictors], train_df.grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "AUC = 0.8143\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest:\")\n",
    "print(\"AUC = {}\".format(round(roc_auc_score(test_df.grade, rf.predict_proba(test_df.loc[:,predictors])[:,1]),4)))\n",
    "y_test_pred_rf = rf.predict_proba(test_df.loc[:,predictors])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "AUC = 0.8218\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest:\")\n",
    "print(\"AUC = {}\".format(round(roc_auc_score(test_df[test_df.first_ind == 0].grade, rf.predict_proba(test_df[test_df.first_ind == 0].loc[:,predictors])[:,1]),4)))\n",
    "y_test_pred_rf_nonfirst = rf.predict_proba(test_df[test_df.first_ind == 0].loc[:,predictors])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "AUC = 0.7709\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest:\")\n",
    "print(\"AUC = {}\".format(round(roc_auc_score(test_df[test_df.first_ind == 1].grade, rf.predict_proba(test_df[test_df.first_ind == 1].loc[:,predictors])[:,1]),4)))\n",
    "y_test_pred_rf_first = rf.predict_proba(test_df[test_df.first_ind == 1].loc[:,predictors])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Online AUC = 0.8224\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest:\")\n",
    "print(\"Online AUC = {}\".format(round(roc_auc_score(test_df[test_df.online_ind == 1].grade, rf.predict_proba(test_df[test_df.online_ind == 1].loc[:,predictors])[:,1]),4)))\n",
    "y_test_pred_rf_first = rf.predict_proba(test_df[test_df.online_ind == 1].loc[:,predictors])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "In-person AUC = 0.8135\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest:\")\n",
    "print(\"In-person AUC = {}\".format(round(roc_auc_score(test_df[test_df.online_ind == 0].grade, rf.predict_proba(test_df[test_df.online_ind == 0].loc[:,predictors])[:,1]),4)))\n",
    "y_test_pred_rf_first = rf.predict_proba(test_df[test_df.online_ind == 0].loc[:,predictors])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"ABC vs. DF\")\n",
    "# print(\"AUC = {}\".format(round(roc_auc_score(np.array(test_df.grade)[np.where(np.array(original_test_grade) != \"W\")[0]], \n",
    "#                                             rf.predict_proba(test_df.loc[:,predictors])[np.where(np.array(original_test_grade) != \"W\")[0],1]),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def find_optimal_threshold(p,r,t):\n",
    "#     to_drop = np.union1d(np.where(pd.isnull(p[:-1]) == True)[0], np.where(pd.isnull(r[:-1]) == True)[0])\n",
    "#     to_drop = np.union1d(to_drop, np.where(pd.isnull(t) == True)[0])\n",
    "#     to_keep = np.setdiff1d(np.array(list(range(len(p)-1))), to_drop)\n",
    "#     p,r,t = p[to_keep],r[to_keep],t[to_keep]\n",
    "#     to_keep_2 = np.where(t < 0.8)[0]\n",
    "#     p,r,t = p[to_keep_2],r[to_keep_2],t[to_keep_2]\n",
    "#     f1 = 2*p*r/(p+r)\n",
    "#     best_t = t[np.argmax(f1)]\n",
    "#     best_t\n",
    "#     return best_t\n",
    "\n",
    "# def cross_validation(train, model):\n",
    "#     threshold_list = []\n",
    "#     auc_list = []\n",
    "#     k_fold =  StratifiedKFold(n_splits = 10, random_state = 54321, shuffle=True)\n",
    "#     for train_indices, test_indices in k_fold.split(train, train.grade):\n",
    "#         train_part = train.iloc[train_indices,:]\n",
    "#         test_part = train.iloc[test_indices,:]\n",
    "#         X_1 = train_part.loc[:,predictors]\n",
    "#         y_1 = train_part.grade\n",
    "#         X_2 = test_part.loc[:,predictors]\n",
    "#         y_2 = test_part.grade\n",
    "#         model.fit(X_1,y_1)\n",
    "#         p,r,t = precision_recall_curve(1-np.array(y_2), model.predict_proba(X_2)[:,0])\n",
    "#         threshold_list.append(1-find_optimal_threshold(p,r,t))\n",
    "#         auc = roc_auc_score(y_2, model.predict_proba(X_2)[:,1])\n",
    "#         auc_list.append(auc)\n",
    "#     print(threshold_list)\n",
    "#     print(np.mean(auc_list), np.std(auc_list, ddof=1))\n",
    "#     return gmean(threshold_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best_threshold = cross_validation(train_df,rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_threshold = np.sort(y_test_pred_rf)[int(len(y_test_pred_rf) * (1-np.mean(train_df.grade)))-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_confusion_matrix_old(y_test_pred, threshold, fname):\n",
    "    cm_arr = confusion_matrix(y_test, np.where(y_test_pred > threshold, 1, 0))\n",
    "    cm_df = pd.DataFrame(cm_arr, columns=['Pred_DFW','Pred_ABC'], index=['Actual_DFW', 'Actual_ABC'])\n",
    "    cm_df.loc[:,''] = cm_df.sum(axis=1)\n",
    "    cm_df.loc['',:] = cm_df.sum(axis=0)\n",
    "    print(cm_df)\n",
    "    print(\"\")\n",
    "    p1 = cm_df.iloc[1,1]/cm_df.iloc[2,1]\n",
    "    r1 = cm_df.iloc[1,1]/cm_df.iloc[1,2]\n",
    "    p0 = cm_df.iloc[0,0]/cm_df.iloc[2,0]\n",
    "    r0 = cm_df.iloc[0,0]/cm_df.iloc[0,2]    \n",
    "    print(\"F1 score for A/B/C = {}\".format(round(2*p1*r1/(p1+r1),4)))\n",
    "    print(\"F1 score for D/F/W = {}\".format(round(2*p0*r0/(p0+r0),4))) \n",
    "    cm_df.to_csv(results_dir + fname + \".csv\")\n",
    "    y_test_pred_bin = np.where(y_test_pred > best_threshold, 1, 0)\n",
    "    cm_dict = {}\n",
    "    cm_dict['Pred_DFW'] = Counter(original_test_grade[np.where(y_test_pred_bin==0)[0]])\n",
    "    cm_dict['Pred_ABC'] = Counter(original_test_grade[np.where(y_test_pred_bin==1)[0]])\n",
    "    new_cm = pd.DataFrame.from_dict(cm_dict, orient='index').T.loc[['W','F','D','C','B','A'],['Pred_DFW','Pred_ABC']]\n",
    "    new_cm.index = [\"Actual_\"+e for e in new_cm.index]\n",
    "    new_cm.loc[:,''] = new_cm.sum(axis=1)\n",
    "    new_cm.loc['',:] = new_cm.sum(axis=0)\n",
    "    new_cm.to_csv(results_dir + fname + \"_6x2.csv\")\n",
    "    return round(p1,4),round(r1,4),round(p0,4),round(r0,4),round(2*p1*r1/(p1+r1),4),round(2*p0*r0/(p0+r0),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.5291:\n",
      "\n",
      "            Pred_DFW  Pred_ABC        \n",
      "Actual_DFW    1386.0     848.0  2234.0\n",
      "Actual_ABC     640.0    2864.0  3504.0\n",
      "              2026.0    3712.0  5738.0\n",
      "\n",
      "F1 score for A/B/C = 0.7938\n",
      "F1 score for D/F/W = 0.6507\n",
      "(0.7716, 0.8174, 0.6841, 0.6204, 0.7938, 0.6507)\n"
     ]
    }
   ],
   "source": [
    "y_test = np.array(test_df.grade)\n",
    "print(\"F1 threshold = {}:\\n\".format(str(round(best_threshold,4))))\n",
    "pr_rf = create_confusion_matrix_old(y_test_pred_rf, best_threshold, \"RF_MTH154_all_cm\")\n",
    "print(pr_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_confusion_matrix(y_test_pred, threshold, fname, ind = 0):\n",
    "    cm_arr = confusion_matrix(y_test[np.array(test_df.first_ind == ind)], np.where(y_test_pred > threshold, 1, 0))\n",
    "    cm_df = pd.DataFrame(cm_arr, columns=['Pred_DFW','Pred_ABC'], index=['Actual_DFW', 'Actual_ABC'])\n",
    "    cm_df.loc[:,''] = cm_df.sum(axis=1)\n",
    "    cm_df.loc['',:] = cm_df.sum(axis=0)\n",
    "    print(cm_df)\n",
    "    print(\"\")\n",
    "    p1 = cm_df.iloc[1,1]/cm_df.iloc[2,1]\n",
    "    r1 = cm_df.iloc[1,1]/cm_df.iloc[1,2]\n",
    "    p0 = cm_df.iloc[0,0]/cm_df.iloc[2,0]\n",
    "    r0 = cm_df.iloc[0,0]/cm_df.iloc[0,2]    \n",
    "    print(\"F1 score for A/B/C = {}\".format(round(2*p1*r1/(p1+r1),4)))\n",
    "    print(\"F1 score for D/F/W = {}\".format(round(2*p0*r0/(p0+r0),4))) \n",
    "    cm_df.to_csv(results_dir + fname + \".csv\")\n",
    "    y_test_pred_bin = np.where(y_test_pred > best_threshold, 1, 0)\n",
    "    cm_dict = {}\n",
    "    cm_dict['Pred_DFW'] = Counter(original_test_grade[np.array(test_df.first_ind == ind)][np.where(y_test_pred_bin==0)[0]])\n",
    "    cm_dict['Pred_ABC'] = Counter(original_test_grade[np.array(test_df.first_ind == ind)][np.where(y_test_pred_bin==1)[0]])\n",
    "    new_cm = pd.DataFrame.from_dict(cm_dict, orient='index').T.loc[['W','F','D','C','B','A'],['Pred_DFW','Pred_ABC']]\n",
    "    new_cm.index = [\"Actual_\"+e for e in new_cm.index]\n",
    "    new_cm.loc[:,''] = new_cm.sum(axis=1)\n",
    "    new_cm.loc['',:] = new_cm.sum(axis=0)\n",
    "    new_cm.to_csv(results_dir + fname + \"_6x2.csv\")\n",
    "    return round(p1,4),round(r1,4),round(p0,4),round(r0,4),round(2*p1*r1/(p1+r1),4),round(2*p0*r0/(p0+r0),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.5291:\n",
      "\n",
      "            Pred_DFW  Pred_ABC        \n",
      "Actual_DFW    1211.0     740.0  1951.0\n",
      "Actual_ABC     554.0    2560.0  3114.0\n",
      "              1765.0    3300.0  5065.0\n",
      "\n",
      "F1 score for A/B/C = 0.7983\n",
      "F1 score for D/F/W = 0.6518\n"
     ]
    }
   ],
   "source": [
    "y_test = np.array(test_df.grade)\n",
    "print(\"F1 threshold = {}:\\n\".format(str(round(best_threshold,4))))\n",
    "pr_rf = create_confusion_matrix(y_test_pred_rf_nonfirst, best_threshold, \"RF_MTH154_full_cm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7758, 0.8221, 0.6861, 0.6207, 0.7983, 0.6518)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.5291:\n",
      "\n",
      "            Pred_DFW  Pred_ABC       \n",
      "Actual_DFW     175.0     108.0  283.0\n",
      "Actual_ABC      86.0     304.0  390.0\n",
      "               261.0     412.0  673.0\n",
      "\n",
      "F1 score for A/B/C = 0.7581\n",
      "F1 score for D/F/W = 0.6434\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 threshold = {}:\\n\".format(str(round(best_threshold,4))))\n",
    "pr_rf = create_confusion_matrix(y_test_pred_rf_first, best_threshold, \"RF_MTH154_first_cm\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7379, 0.7795, 0.6705, 0.6184, 0.7581, 0.6434)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi_df = pd.DataFrame({\"feature_importance\": rf.feature_importances_, \"predictor\": predictors})\\\n",
    ".loc[:,['predictor', 'feature_importance']].sort_values(['feature_importance'], ascending=False)\n",
    "fi_df.loc[:,'feature_ranking'] = np.arange(1, fi_df.shape[0] + 1) / fi_df.shape[0]\n",
    "cw_df = pd.read_csv(results_dir + \"predictor_crosswalk.csv\").iloc[:,[0,3,4]]\n",
    "fi_df = fi_df.merge(cw_df, on=['predictor'], how='left')\n",
    "fi_df.loc[:,'predictor_category'] = fi_df.predictor_category.apply(lambda x: \"Admin\" if pd.isnull(x) else x)\n",
    "fi_df.loc[:,'predictor_subcategory'] = fi_df.predictor_subcategory.apply(lambda x: \"Non-course-specific academic records\" if pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>predictor_type</th>\n",
       "      <th>predictor_subcategory</th>\n",
       "      <th>ranking</th>\n",
       "      <th>feature_importance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pct_withdrawn</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cum_gpa</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>2</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tot_click_cnt_qrt1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>3</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>term_gpa_1</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>4</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crnt_enrl_intensity</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>5</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tot_time_qrt1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>6</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>term_gpa_2</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>7</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>overall_prop_comp</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>8</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>assign_sub_cnt_qtr1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>9</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HUM_MTH_grade</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Course-subject-specific</td>\n",
       "      <td>10</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tot_click_cnt_qrt1c</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term concurrent</td>\n",
       "      <td>11</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SOC_MTH_grade</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Course-subject-specific</td>\n",
       "      <td>12</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tot_time_qrt1c</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term concurrent</td>\n",
       "      <td>13</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>irreg_session_len_qrt1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>14</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>avg_session_len_qrt1c</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term concurrent</td>\n",
       "      <td>15</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>disc_reply_cnt_qtr1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>16</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>irreg_session_len_qrt1c</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term concurrent</td>\n",
       "      <td>17</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gpa_trend</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>18</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>past_avg_grade</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Instructor-related</td>\n",
       "      <td>19</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>avg_session_len_qrt1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>20</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>disc_post_cnt_qtr1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>21</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>avg_word_tot_qtr1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>22</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>age</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>23</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>avg_g_concurrent</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Course-specific</td>\n",
       "      <td>24</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SCI_MTH_grade</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Course-subject-specific</td>\n",
       "      <td>25</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>on_time_assign_share_qtr1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>26</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>avg_depth_post_qtr1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>27</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>cum_cred_earn</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>28</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>section_size</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Course-specific</td>\n",
       "      <td>29</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>prop_comp_sd</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>30</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    predictor predictor_type  \\\n",
       "0               pct_withdrawn          Admin   \n",
       "1                     cum_gpa          Admin   \n",
       "2          tot_click_cnt_qrt1            LMS   \n",
       "3                  term_gpa_1          Admin   \n",
       "4         crnt_enrl_intensity          Admin   \n",
       "5               tot_time_qrt1            LMS   \n",
       "6                  term_gpa_2          Admin   \n",
       "7           overall_prop_comp          Admin   \n",
       "8         assign_sub_cnt_qtr1            LMS   \n",
       "9               HUM_MTH_grade          Admin   \n",
       "10        tot_click_cnt_qrt1c            LMS   \n",
       "11              SOC_MTH_grade          Admin   \n",
       "12             tot_time_qrt1c            LMS   \n",
       "13     irreg_session_len_qrt1            LMS   \n",
       "14      avg_session_len_qrt1c            LMS   \n",
       "15        disc_reply_cnt_qtr1            LMS   \n",
       "16    irreg_session_len_qrt1c            LMS   \n",
       "17                  gpa_trend          Admin   \n",
       "18             past_avg_grade          Admin   \n",
       "19       avg_session_len_qrt1            LMS   \n",
       "20         disc_post_cnt_qtr1            LMS   \n",
       "21          avg_word_tot_qtr1            LMS   \n",
       "22                        age          Admin   \n",
       "23           avg_g_concurrent          Admin   \n",
       "24              SCI_MTH_grade          Admin   \n",
       "25  on_time_assign_share_qtr1            LMS   \n",
       "26        avg_depth_post_qtr1            LMS   \n",
       "27              cum_cred_earn          Admin   \n",
       "28               section_size          Admin   \n",
       "29               prop_comp_sd          Admin   \n",
       "\n",
       "                   predictor_subcategory  ranking  feature_importance_score  \n",
       "0   Non-course-specific academic records        1                     0.071  \n",
       "1   Non-course-specific academic records        2                     0.059  \n",
       "2                             Early-term        3                     0.058  \n",
       "3   Non-course-specific academic records        4                     0.045  \n",
       "4   Non-course-specific academic records        5                     0.045  \n",
       "5                             Early-term        6                     0.040  \n",
       "6   Non-course-specific academic records        7                     0.029  \n",
       "7   Non-course-specific academic records        8                     0.023  \n",
       "8                             Early-term        9                     0.023  \n",
       "9                Course-subject-specific       10                     0.021  \n",
       "10                 Early-term concurrent       11                     0.018  \n",
       "11               Course-subject-specific       12                     0.017  \n",
       "12                 Early-term concurrent       13                     0.016  \n",
       "13                            Early-term       14                     0.014  \n",
       "14                 Early-term concurrent       15                     0.013  \n",
       "15                            Early-term       16                     0.013  \n",
       "16                 Early-term concurrent       17                     0.013  \n",
       "17  Non-course-specific academic records       18                     0.013  \n",
       "18                    Instructor-related       19                     0.013  \n",
       "19                            Early-term       20                     0.013  \n",
       "20                            Early-term       21                     0.012  \n",
       "21                            Early-term       22                     0.012  \n",
       "22                           Demographic       23                     0.012  \n",
       "23                       Course-specific       24                     0.012  \n",
       "24               Course-subject-specific       25                     0.012  \n",
       "25                            Early-term       26                     0.012  \n",
       "26                            Early-term       27                     0.011  \n",
       "27  Non-course-specific academic records       28                     0.011  \n",
       "28                       Course-specific       29                     0.011  \n",
       "29  Non-course-specific academic records       30                     0.011  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_df.loc[:,'predictor_subcategory'] = fi_df.predictor_subcategory.apply(lambda x: x.split(\" & \")[0])\n",
    "fi_df_top30 = fi_df.iloc[:30,:].drop(['feature_ranking'], axis=1)\n",
    "fi_df_top30.loc[:,'feature_ranking'] = np.arange(1,31)\n",
    "fi_df_top30 = fi_df_top30.round(3)\n",
    "fi_df_top30 = fi_df_top30.rename(columns = {'feature_importance': 'feature_importance_score',\n",
    "                                            'feature_ranking': 'ranking',\n",
    "                                            'predictor_category': 'predictor_type'})\n",
    "fi_df_top30 = fi_df_top30.loc[:,['predictor', 'predictor_type', 'predictor_subcategory', 'ranking', 'feature_importance_score']]\n",
    "fi_df_top30.to_csv(results_dir + \"top30_predictors_MTH154.csv\", index=False)\n",
    "fi_df_top30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor_subcategory</th>\n",
       "      <th>number_of_predictors</th>\n",
       "      <th>highest_normalized_ranking</th>\n",
       "      <th>average_normalized_ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Admin -- Course-specific</td>\n",
       "      <td>31</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.736704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Admin -- Course-subject-specific</td>\n",
       "      <td>20</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>0.493581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Admin -- Demographic</td>\n",
       "      <td>1</td>\n",
       "      <td>0.155405</td>\n",
       "      <td>0.155405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Admin -- Instructor-related</td>\n",
       "      <td>4</td>\n",
       "      <td>0.128378</td>\n",
       "      <td>0.459459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Admin -- Non-course-specific academic records</td>\n",
       "      <td>42</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.533301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LMS -- Early-term</td>\n",
       "      <td>12</td>\n",
       "      <td>0.020270</td>\n",
       "      <td>0.175113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LMS -- Early-term concurrent</td>\n",
       "      <td>9</td>\n",
       "      <td>0.074324</td>\n",
       "      <td>0.322072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LMS -- Prior early-term</td>\n",
       "      <td>13</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.451143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LMS -- Prior full-term</td>\n",
       "      <td>16</td>\n",
       "      <td>0.222973</td>\n",
       "      <td>0.408361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All Admin</td>\n",
       "      <td>98</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.582667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All LMS</td>\n",
       "      <td>50</td>\n",
       "      <td>0.020270</td>\n",
       "      <td>0.347973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           predictor_subcategory  number_of_predictors  \\\n",
       "0                       Admin -- Course-specific                    31   \n",
       "1               Admin -- Course-subject-specific                    20   \n",
       "2                           Admin -- Demographic                     1   \n",
       "3                    Admin -- Instructor-related                     4   \n",
       "4  Admin -- Non-course-specific academic records                    42   \n",
       "5                              LMS -- Early-term                    12   \n",
       "6                   LMS -- Early-term concurrent                     9   \n",
       "7                        LMS -- Prior early-term                    13   \n",
       "8                         LMS -- Prior full-term                    16   \n",
       "0                                      All Admin                    98   \n",
       "1                                        All LMS                    50   \n",
       "\n",
       "   highest_normalized_ranking  average_normalized_ranking  \n",
       "0                    0.162162                    0.736704  \n",
       "1                    0.067568                    0.493581  \n",
       "2                    0.155405                    0.155405  \n",
       "3                    0.128378                    0.459459  \n",
       "4                    0.006757                    0.533301  \n",
       "5                    0.020270                    0.175113  \n",
       "6                    0.074324                    0.322072  \n",
       "7                    0.250000                    0.451143  \n",
       "8                    0.222973                    0.408361  \n",
       "0                    0.006757                    0.582667  \n",
       "1                    0.020270                    0.347973  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_part1 = fi_df.iloc[:,:-1]\n",
    "fi_part1.loc[:,'predictor_category'] = fi_part1.predictor_category.apply(lambda x: \"All \" + x)\n",
    "fi_part2 = fi_df.copy()\n",
    "fi_part2.loc[:,'predictor_subcategory'] = fi_part2.predictor_subcategory.apply(lambda x: x.split(\" & \")[0])\n",
    "fi_part2.loc[:,'predictor_subcategory'] = fi_part2.predictor_category + \" -- \" + fi_part2.predictor_subcategory\n",
    "fi_part2 = fi_part2.groupby(['predictor_subcategory']).agg({'feature_ranking': ['count','first','mean']}).reset_index()\n",
    "fi_part2.columns = ['predictor_subcategory', 'number_of_predictors', 'highest_normalized_ranking', 'average_normalized_ranking']\n",
    "fi_part1 = fi_part1.groupby(['predictor_category']).agg({'feature_ranking': ['count','first','mean']}).reset_index()\n",
    "fi_part1.columns = ['predictor_subcategory', 'number_of_predictors', 'highest_normalized_ranking', 'average_normalized_ranking']\n",
    "fi_all_parts = pd.concat([fi_part2, fi_part1])\n",
    "fi_all_parts.round(3).to_csv(results_dir + \"normalized_feature_ranking_MTH154.csv\", index=False)\n",
    "fi_all_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
