{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script tests the BIO101-specific model which only includes the early-term LMS predictors associated with the concurrent courses in the target term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from scipy.stats.mstats import gmean\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_dir = \"~\\\\Box Sync\\\\Clickstream\\\\evaluation_results\\\\full\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sn_dict = {\"Blue Ridge\": \"BRCC\",\n",
    "           \"Central Virginia\": \"CVCC\",\n",
    "           \"Dabney S. Lancaster\": \"DSLCC\",\n",
    "           \"Danville\": \"DCC\",\n",
    "           \"Eastern Shore\": \"ESCC\",\n",
    "           \"Germanna\": \"GCC\",\n",
    "           'J. Sargeant Reynolds': \"JSRCC\",\n",
    "           'John Tyler': \"JTCC\",\n",
    "           \"Lord Fairfax\": \"LFCC\",\n",
    "           \"Mountain Empire\": \"MECC\",\n",
    "           \"New River\": \"NRCC\",\n",
    "           \"Northern Virginia\": \"NVCC\",\n",
    "           \"Patrick Henry\": \"PHCC\",\n",
    "           \"Paul D. Camp\": \"PDCCC\",\n",
    "           \"Piedmont Virginia\": \"PVCC\",\n",
    "           \"Rappahannock\": \"RCC\",\n",
    "           \"Southside Virginia\": \"SSVCC\",\n",
    "           \"Southwest Virginia\": \"SWVCC\",\n",
    "           \"Thomas Nelson\": \"TNCC\",\n",
    "           \"Tidewater\": \"TCC\",\n",
    "           \"Virginia Highlands\": \"VHCC\",\n",
    "           \"Virginia Western\": \"VWCC\",\n",
    "           \"Wytheville\": \"WCC\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\LMS_data_final_full_new.csv\")\n",
    "df1 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\course_specific_predictors_new.csv\")\n",
    "df2 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\term_specific_predictors_new.csv\")\n",
    "df3 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\cluster_specific_predictors.csv\")\n",
    "df3 = df3.loc[:,['vccsid','strm','college','course','section'] + [e for e in df3.columns.values if e.endswith(\"SCI\") or e.endswith(\"SCI_grade\")]]\n",
    "df4 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\instructor_related_predictors.dta\")\n",
    "df = df0.merge(df1, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df2, how='inner', on=['vccsid','strm'])\\\n",
    ".merge(df3, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df4, how='inner', on=['vccsid','strm','college','course','section'])\n",
    "df = df[df.course == \"BIO_101\"]\n",
    "df.loc[:,'first_ind'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df0 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\LMS_data_final.dta\")\n",
    "df1 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\course_specific_predictors_new.csv\")\n",
    "df2 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\term_specific_predictors_new.csv\")\n",
    "df4 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\instructor_related_predictors.dta\")\n",
    "df5 = df0.loc[:,['vccsid','strm','college','course','section']].copy()\n",
    "df_first = df0.merge(df1, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df2, how='inner', on=['vccsid','strm'])\\\n",
    ".merge(df4, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df5, how='inner', on=['vccsid','strm','college','course','section'])\n",
    "df_first = df_first[df_first.course == \"BIO_101\"]\n",
    "df_first.loc[:,'first_ind'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df, df_first], axis=0, join='outer').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 32208, 1: 6598})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df.first_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for v in [int(e) for e in np.unique(df.cip) if e != 0]:\n",
    "    df.loc[:,'cip_'+str(v)] = (df.cip == v).astype(int)\n",
    "for v in [int(e) for e in np.unique(df.degree_level) if e != 4]:\n",
    "    df.loc[:,'degree_level_'+str(v)] = (df.degree_level == v).astype(int)\n",
    "df = df.drop(['cip', 'degree_level'], axis=1)\n",
    "df.loc[:,'college_new'] = df.college.apply(lambda x: sn_dict[x])\n",
    "for sn in [e for e in sn_dict.values() if e != \"BRCC\"]:\n",
    "    df.loc[:,'college_'+sn] = (df.college_new == sn).astype(int)\n",
    "df = df.drop(['college_new'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>has_prereq_grade</th>\n",
       "      <td>38806.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lvl2_ind</th>\n",
       "      <td>38806.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prereq_grade</th>\n",
       "      <td>38806.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count  mean  std  min  25%  50%  75%  max\n",
       "has_prereq_grade  38806.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "lvl2_ind          38806.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "prereq_grade      38806.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.describe().T\n",
    "test[test['mean'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['lvl2_ind', 'has_prereq_grade', 'prereq_grade'], axis=1)\n",
    "predictors = [e for e in list(df.columns) if e not in {\"grade\",'vccsid','strm','college','course','section'}]\n",
    "len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert pd.isnull(df).any().any() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38806, 153)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_lms = [e for e in predictors if (e.endswith(\"_qtr1\") or e.endswith(\"_qrt1\")) and (e != \"has_concurrent_qtr1\") and (e.startswith(\"prior_\") == False)]\n",
    "concurrent_lms = [e for e in predictors if e.endswith(\"_qtr1c\") or e.endswith(\"_qrt1c\") or e == 'has_concurrent_qtr1']\n",
    "historical_early_lms = [e for e in predictors if e.startswith(\"prior\") and (e.endswith(\"_qrt1\") or e.endswith(\"_qtr1\"))]\n",
    "historical_full_lms = [e for e in predictors if e.startswith(\"prior\") and e.endswith(\"_qrt1\") == False and e.endswith(\"_qtr1\") == False]\n",
    "all_lms = early_lms + concurrent_lms + historical_early_lms + historical_full_lms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = [e for e in predictors if e in set(all_lms)]\n",
    "len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_category = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\evaluation_results\\\\first\\\\predictor_category_table.csv\")\n",
    "predictor_df = pd.DataFrame({'predictor': predictors}).merge(predictor_category, how='inner', on=['predictor'])\n",
    "predictor_df = predictor_df[predictor_df.predictor_subcategory.apply(lambda x: x.startswith(\"Early-term concurrent &\") == True)]\n",
    "predictors = list(predictor_df.predictor)\n",
    "len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29925, 153) (8881, 153)\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df.strm != 2212]\n",
    "test_df = df[df.strm == 2212]\n",
    "original_test_grade = np.array(test_df.grade)\n",
    "train_df.loc[:,'grade'] = train_df.apply(lambda x: 1 if x.loc['grade'] in {'A','B','C'} else 0, axis=1)\n",
    "test_df.loc[:,'grade'] = test_df.apply(lambda x: 1 if x.loc['grade'] in {'A','B','C'} else 0, axis=1)\n",
    "print(train_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cv_folds(train, n_fold = 5):\n",
    "    folds = []\n",
    "    k_fold = StratifiedKFold(n_splits = n_fold, random_state = 12345, shuffle=True)\n",
    "    for train_indices, test_indices in k_fold.split(train, train.grade):\n",
    "        train_part = train.iloc[train_indices,:]\n",
    "        test_part = train.iloc[test_indices,:]\n",
    "        X_1 = train_part.loc[:,predictors]\n",
    "        y_1 = train_part.grade\n",
    "        X_2 = test_part.loc[:,predictors]\n",
    "        y_2 = test_part.grade\n",
    "        folds.append([(X_1.copy(),y_1.copy()),(X_2.copy(),y_2.copy())])\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "five_folds = create_cv_folds(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_RF(rf_model, folds):\n",
    "    auc_by_fold = []\n",
    "    for f in folds:\n",
    "        X_1 = f[0][0]\n",
    "        y_1 = f[0][1]\n",
    "        X_2 = f[1][0]\n",
    "        y_2 = f[1][1]\n",
    "        rf_model.fit(X_1,y_1)\n",
    "        y_2_pred = rf_model.predict_proba(X_2)[:,1]\n",
    "        auc_by_fold.append(roc_auc_score(y_2,y_2_pred))\n",
    "    return round(np.mean(auc_by_fold),4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_cw(y):\n",
    "    # Calculate the weight of each letter grade to be used in the modeling fitting procedure: the weight is inversely proportional to the square root of the frequency of the letter grade in the training sample\n",
    "    cw = Counter(y)\n",
    "    class_weight = {k:np.sqrt(cw.most_common()[0][-1]/v, dtype=np.float32) for k,v in cw.items()}\n",
    "    return class_weight # The output is a dictionary mapping letter grade to the corresponding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_depth = 2\n",
      "Mean CV AUC: 0.5999\n",
      "\n",
      "Max_depth = 3\n",
      "Mean CV AUC: 0.6119\n",
      "\n",
      "Max_depth = 4\n",
      "Mean CV AUC: 0.6165\n",
      "\n",
      "Max_depth = 5\n",
      "Mean CV AUC: 0.6185\n",
      "\n",
      "Max_depth = 6\n",
      "Mean CV AUC: 0.6215\n",
      "\n",
      "Max_depth = 7\n",
      "Mean CV AUC: 0.6229\n",
      "\n",
      "Max_depth = 8\n",
      "Mean CV AUC: 0.6224\n",
      "\n",
      "Max_depth = 9\n",
      "Mean CV AUC: 0.6216\n",
      "\n",
      "Max_depth = 10\n",
      "Mean CV AUC: 0.6197\n",
      "\n",
      "Max_depth = 11\n",
      "Mean CV AUC: 0.6184\n",
      "\n",
      "Max_depth = 12\n",
      "Mean CV AUC: 0.6172\n",
      "\n",
      "Max_depth = 13\n",
      "Mean CV AUC: 0.6145\n",
      "\n",
      "Max_depth = 14\n",
      "Mean CV AUC: 0.6122\n",
      "\n",
      "Max_depth = 15\n",
      "Mean CV AUC: 0.6096\n",
      "\n",
      "Max_depth = 16\n",
      "Mean CV AUC: 0.6066\n",
      "\n",
      "Max_depth = 17\n",
      "Mean CV AUC: 0.6073\n",
      "\n",
      "Max_depth = 18\n",
      "Mean CV AUC: 0.6044\n",
      "\n",
      "Max_depth = 19\n",
      "Mean CV AUC: 0.6018\n",
      "\n",
      "Max_depth = 20\n",
      "Mean CV AUC: 0.5998\n",
      "\n",
      "Max_depth = 21\n",
      "Mean CV AUC: 0.5995\n",
      "\n",
      "Max_depth = 22\n",
      "Mean CV AUC: 0.5976\n",
      "\n",
      "Max_depth = 23\n",
      "Mean CV AUC: 0.5968\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-05f00e2a8144>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m                                 \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"auto\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                 class_weight = calc_cw(train_df.grade))\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation_RF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfive_folds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mauc_by_d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Max_depth =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-fb80a74de69f>\u001b[0m in \u001b[0;36mcross_validation_RF\u001b[1;34m(rf_model, folds)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mX_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0my_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0my_2_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mauc_by_fold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_2_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[1;32m--> 321\u001b[1;33m                                             random_state=random_state)\n\u001b[0m\u001b[0;32m    322\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[1;34m(self, append, random_state)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0m_set_random_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py\u001b[0m in \u001b[0;36m_set_random_states\u001b[1;34m(estimator, random_state)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mto_set\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mto_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mvalid_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mnested_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# grouped by prefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Using grid search to find the optimal maximum tree depth\n",
    "auc_by_d=[]\n",
    "for d in range(2,26):\n",
    "    rf = RandomForestClassifier(n_estimators=200, criterion=\"entropy\", \n",
    "                                max_depth=d,\n",
    "                                random_state=0, n_jobs=20, max_features=\"auto\",\n",
    "                                class_weight = calc_cw(train_df.grade))\n",
    "    auc = cross_validation_RF(rf, five_folds)\n",
    "    auc_by_d.append(auc)\n",
    "    print(\"Max_depth =\", d)\n",
    "    print(\"Mean CV AUC:\", auc)\n",
    "    print(\"\")\n",
    "plt.plot(range(2,26),auc_by_d)\n",
    "plt.xlabel(\"Maximum Depth\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trees = 100\n",
      "Mean CV AUC: 0.6225\n",
      "\n",
      "Number of Trees = 120\n",
      "Mean CV AUC: 0.6228\n",
      "\n",
      "Number of Trees = 140\n",
      "Mean CV AUC: 0.6229\n",
      "\n",
      "Number of Trees = 160\n",
      "Mean CV AUC: 0.6229\n",
      "\n",
      "Number of Trees = 180\n",
      "Mean CV AUC: 0.623\n",
      "\n",
      "Number of Trees = 200\n",
      "Mean CV AUC: 0.6229\n",
      "\n",
      "Number of Trees = 220\n",
      "Mean CV AUC: 0.6229\n",
      "\n",
      "Number of Trees = 240\n",
      "Mean CV AUC: 0.6229\n",
      "\n",
      "Number of Trees = 260\n",
      "Mean CV AUC: 0.6227\n",
      "\n",
      "Number of Trees = 280\n",
      "Mean CV AUC: 0.6227\n",
      "\n",
      "Number of Trees = 300\n",
      "Mean CV AUC: 0.6227\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGBERicT/A0UtGCKrifdBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Using grid search to find the optimal number of estimators (trees)\n",
    "auc_by_n = []\n",
    "for n in range(100,320,20):\n",
    "    rf = RandomForestClassifier(n_estimators=n, criterion=\"entropy\", \n",
    "                                max_depth=7,\n",
    "                                random_state=0, n_jobs=-1, max_features=\"auto\",\n",
    "                                class_weight = calc_cw(train_df.grade))\n",
    "    auc = cross_validation_RF(rf, five_folds)\n",
    "    auc_by_n.append(auc)\n",
    "    print(\"Number of Trees =\", n)\n",
    "    print(\"Mean CV AUC:\", auc)\n",
    "    print(\"\")\n",
    "plt.plot(range(100,320,20), auc_by_n)\n",
    "plt.xlabel(\"Number of Trees\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_features = 2\n",
      "Mean CV AUC: 0.6203\n",
      "\n",
      "Max_features = 3\n",
      "Mean CV AUC: 0.6229\n",
      "\n",
      "Max_features = 4\n",
      "Mean CV AUC: 0.622\n",
      "\n",
      "Max_features = 5\n",
      "Mean CV AUC: 0.6222\n",
      "\n",
      "Max_features = 6\n",
      "Mean CV AUC: 0.6216\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSjAiIhIKJRgREQmFEoyIiITi/wH1jhyPZqhI8QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Using grid search to find the optimal maximum number of features (trees)\n",
    "auc_by_nf = []\n",
    "max_nf = int(np.floor(2*np.sqrt(len(predictors))))\n",
    "for nf in range(2,max_nf+1):\n",
    "    rf = RandomForestClassifier(n_estimators=140, criterion=\"entropy\", \n",
    "                                max_depth=7,\n",
    "                                random_state=0, n_jobs=-1, max_features=nf,\n",
    "                                class_weight = calc_cw(train_df.grade))\n",
    "    auc = cross_validation_RF(rf, five_folds)\n",
    "    auc_by_nf.append(auc)\n",
    "    print(\"Max_features =\", nf)\n",
    "    print(\"Mean CV AUC:\", auc)\n",
    "    print(\"\")\n",
    "plt.plot(range(2,max_nf+1), auc_by_nf)\n",
    "plt.xlabel(\"Maximum Number of Features\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight={0: 1.6805598, 1: 1.0},\n",
       "            criterion='entropy', max_depth=7, max_features=3,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=140, n_jobs=-1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=140, criterion=\"entropy\",\n",
    "                            max_depth=7,\n",
    "                            random_state=0, n_jobs=-1, max_features=3,\n",
    "                            class_weight = calc_cw(train_df.grade))\n",
    "rf.fit(train_df.loc[:,predictors], train_df.grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Overall AUC = 0.6251\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest:\")\n",
    "print(\"Overall AUC = {}\".format(round(roc_auc_score(test_df.grade, rf.predict_proba(test_df.loc[:,predictors])[:,1]),4)))\n",
    "y_test_pred_rf = rf.predict_proba(test_df.loc[:,predictors])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Non-first AUC = 0.7256\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest:\")\n",
    "print(\"Non-first AUC = {}\".format(round(roc_auc_score(test_df[test_df.first_ind == 0].grade, rf.predict_proba(test_df[test_df.first_ind == 0].loc[:,predictors])[:,1]),4)))\n",
    "y_test_pred_rf_nonfirst = rf.predict_proba(test_df[test_df.first_ind == 0].loc[:,predictors])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "First AUC = 0.7676\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest:\")\n",
    "print(\"First AUC = {}\".format(round(roc_auc_score(test_df[test_df.first_ind == 1].grade, rf.predict_proba(test_df[test_df.first_ind == 1].loc[:,predictors])[:,1]),4)))\n",
    "y_test_pred_rf_first = rf.predict_proba(test_df[test_df.first_ind == 1].loc[:,predictors])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"ABC vs. DF\")\n",
    "# print(\"AUC = {}\".format(round(roc_auc_score(np.array(test_df.grade)[np.where(np.array(original_test_grade) != \"W\")[0]], \n",
    "#                                             rf.predict_proba(test_df.loc[:,predictors])[np.where(np.array(original_test_grade) != \"W\")[0],1]),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def find_optimal_threshold(p,r,t):\n",
    "#     to_drop = np.union1d(np.where(pd.isnull(p[:-1]) == True)[0], np.where(pd.isnull(r[:-1]) == True)[0])\n",
    "#     to_drop = np.union1d(to_drop, np.where(pd.isnull(t) == True)[0])\n",
    "#     to_keep = np.setdiff1d(np.array(list(range(len(p)-1))), to_drop)\n",
    "#     p,r,t = p[to_keep],r[to_keep],t[to_keep]\n",
    "#     to_keep_2 = np.where(t < 0.8)[0]\n",
    "#     p,r,t = p[to_keep_2],r[to_keep_2],t[to_keep_2]\n",
    "#     f1 = 2*p*r/(p+r)\n",
    "#     best_t = t[np.argmax(f1)]\n",
    "#     best_t\n",
    "#     return best_t\n",
    "\n",
    "# def cross_validation(train, model):\n",
    "#     threshold_list = []\n",
    "#     auc_list = []\n",
    "#     k_fold =  StratifiedKFold(n_splits = 10, random_state = 54321, shuffle=True)\n",
    "#     for train_indices, test_indices in k_fold.split(train, train.grade):\n",
    "#         train_part = train.iloc[train_indices,:]\n",
    "#         test_part = train.iloc[test_indices,:]\n",
    "#         X_1 = train_part.loc[:,predictors]\n",
    "#         y_1 = train_part.grade\n",
    "#         X_2 = test_part.loc[:,predictors]\n",
    "#         y_2 = test_part.grade\n",
    "#         model.fit(X_1,y_1)\n",
    "#         p,r,t = precision_recall_curve(1-np.array(y_2), model.predict_proba(X_2)[:,0])\n",
    "#         threshold_list.append(1-find_optimal_threshold(p,r,t))\n",
    "#         auc = roc_auc_score(y_2, model.predict_proba(X_2)[:,1])\n",
    "#         auc_list.append(auc)\n",
    "#     print(threshold_list)\n",
    "#     print(np.mean(auc_list), np.std(auc_list, ddof=1))\n",
    "#     return gmean(threshold_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best_threshold = cross_validation(train_df,rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_threshold = np.sort(y_test_pred_rf)[int(len(y_test_pred_rf) * (1-np.mean(train_df.grade)))-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_confusion_matrix_old(y_test_pred, threshold, fname):\n",
    "    cm_arr = confusion_matrix(y_test, np.where(y_test_pred > threshold, 1, 0))\n",
    "    cm_df = pd.DataFrame(cm_arr, columns=['Pred_DFW','Pred_ABC'], index=['Actual_DFW', 'Actual_ABC'])\n",
    "    cm_df.loc[:,''] = cm_df.sum(axis=1)\n",
    "    cm_df.loc['',:] = cm_df.sum(axis=0)\n",
    "    print(cm_df)\n",
    "    print(\"\")\n",
    "    p1 = cm_df.iloc[1,1]/cm_df.iloc[2,1]\n",
    "    r1 = cm_df.iloc[1,1]/cm_df.iloc[1,2]\n",
    "    p0 = cm_df.iloc[0,0]/cm_df.iloc[2,0]\n",
    "    r0 = cm_df.iloc[0,0]/cm_df.iloc[0,2]    \n",
    "    print(\"F1 score for A/B/C = {}\".format(round(2*p1*r1/(p1+r1),4)))\n",
    "    print(\"F1 score for D/F/W = {}\".format(round(2*p0*r0/(p0+r0),4))) \n",
    "    cm_df.to_csv(results_dir + fname + \".csv\")\n",
    "    y_test_pred_bin = np.where(y_test_pred > best_threshold, 1, 0)\n",
    "    cm_dict = {}\n",
    "    cm_dict['Pred_DFW'] = Counter(original_test_grade[np.where(y_test_pred_bin==0)[0]])\n",
    "    cm_dict['Pred_ABC'] = Counter(original_test_grade[np.where(y_test_pred_bin==1)[0]])\n",
    "    new_cm = pd.DataFrame.from_dict(cm_dict, orient='index').T.loc[['W','F','D','C','B','A'],['Pred_DFW','Pred_ABC']]\n",
    "    new_cm.index = [\"Actual_\"+e for e in new_cm.index]\n",
    "    new_cm.loc[:,''] = new_cm.sum(axis=1)\n",
    "    new_cm.loc['',:] = new_cm.sum(axis=0)\n",
    "    new_cm.to_csv(results_dir + fname + \"_6x2.csv\")\n",
    "    return round(p1,4),round(r1,4),round(p0,4),round(r0,4),round(2*p1*r1/(p1+r1),4),round(2*p0*r0/(p0+r0),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.5963:\n",
      "\n",
      "            Pred_DFW  Pred_ABC        \n",
      "Actual_DFW    1458.0    1086.0  2544.0\n",
      "Actual_ABC    1508.0    4829.0  6337.0\n",
      "              2966.0    5915.0  8881.0\n",
      "\n",
      "F1 score for A/B/C = 0.7883\n",
      "F1 score for D/F/W = 0.5292\n"
     ]
    }
   ],
   "source": [
    "y_test = np.array(test_df.grade)\n",
    "print(\"F1 threshold = {}:\\n\".format(str(round(best_threshold,4))))\n",
    "pr_rf = create_confusion_matrix_old(y_test_pred_rf, best_threshold, \"RF_BIO101_all_cm_lms_subcategory5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8164, 0.762, 0.4916, 0.5731, 0.7883, 0.5292)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_confusion_matrix(y_test_pred, threshold, fname, ind = 0):\n",
    "    cm_arr = confusion_matrix(y_test[np.array(test_df.first_ind == ind)], np.where(y_test_pred > threshold, 1, 0))\n",
    "    cm_df = pd.DataFrame(cm_arr, columns=['Pred_DFW','Pred_ABC'], index=['Actual_DFW', 'Actual_ABC'])\n",
    "    cm_df.loc[:,''] = cm_df.sum(axis=1)\n",
    "    cm_df.loc['',:] = cm_df.sum(axis=0)\n",
    "    print(cm_df)\n",
    "    print(\"\")\n",
    "    p1 = cm_df.iloc[1,1]/cm_df.iloc[2,1]\n",
    "    r1 = cm_df.iloc[1,1]/cm_df.iloc[1,2]\n",
    "    p0 = cm_df.iloc[0,0]/cm_df.iloc[2,0]\n",
    "    r0 = cm_df.iloc[0,0]/cm_df.iloc[0,2]    \n",
    "    print(\"F1 score for A/B/C = {}\".format(round(2*p1*r1/(p1+r1),4)))\n",
    "    print(\"F1 score for D/F/W = {}\".format(round(2*p0*r0/(p0+r0),4))) \n",
    "    cm_df.to_csv(results_dir + fname + \".csv\")\n",
    "    y_test_pred_bin = np.where(y_test_pred > best_threshold, 1, 0)\n",
    "    cm_dict = {}\n",
    "    cm_dict['Pred_DFW'] = Counter(original_test_grade[np.array(test_df.first_ind == ind)][np.where(y_test_pred_bin==0)[0]])\n",
    "    cm_dict['Pred_ABC'] = Counter(original_test_grade[np.array(test_df.first_ind == ind)][np.where(y_test_pred_bin==1)[0]])\n",
    "    new_cm = pd.DataFrame.from_dict(cm_dict, orient='index').T.loc[['W','F','D','C','B','A'],['Pred_DFW','Pred_ABC']]\n",
    "    new_cm.index = [\"Actual_\"+e for e in new_cm.index]\n",
    "    new_cm.loc[:,''] = new_cm.sum(axis=1)\n",
    "    new_cm.loc['',:] = new_cm.sum(axis=0)\n",
    "    new_cm.to_csv(results_dir + fname + \"_6x2.csv\")\n",
    "    return round(p1,4),round(r1,4),round(p0,4),round(r0,4),round(2*p1*r1/(p1+r1),4),round(2*p0*r0/(p0+r0),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.5963:\n",
      "\n",
      "            Pred_DFW  Pred_ABC        \n",
      "Actual_DFW    1338.0    1000.0  2338.0\n",
      "Actual_ABC    1440.0    4499.0  5939.0\n",
      "              2778.0    5499.0  8277.0\n",
      "\n",
      "F1 score for A/B/C = 0.7867\n",
      "F1 score for D/F/W = 0.5231\n"
     ]
    }
   ],
   "source": [
    "y_test = np.array(test_df.grade)\n",
    "print(\"F1 threshold = {}:\\n\".format(str(round(best_threshold,4))))\n",
    "pr_rf = create_confusion_matrix(y_test_pred_rf_nonfirst, best_threshold, \"RF_BIO101_full_cm_lms_subcategory5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8181, 0.7575, 0.4816, 0.5723, 0.7867, 0.5231)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.5963:\n",
      "\n",
      "            Pred_DFW  Pred_ABC       \n",
      "Actual_DFW     120.0      86.0  206.0\n",
      "Actual_ABC      68.0     330.0  398.0\n",
      "               188.0     416.0  604.0\n",
      "\n",
      "F1 score for A/B/C = 0.8108\n",
      "F1 score for D/F/W = 0.6091\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 threshold = {}:\\n\".format(str(round(best_threshold,4))))\n",
    "pr_rf = create_confusion_matrix(y_test_pred_rf_first, best_threshold, \"RF_BIO101_first_cm_lms_subcategory5\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7933, 0.8291, 0.6383, 0.5825, 0.8108, 0.6091)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi_df = pd.DataFrame({\"feature_importance\": rf.feature_importances_, \"predictor\": predictors})\\\n",
    ".loc[:,['predictor', 'feature_importance']].sort_values(['feature_importance'], ascending=False)\n",
    "fi_df.loc[:,'feature_ranking'] = np.arange(1, fi_df.shape[0] + 1) / fi_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_lms = [e for e in predictors if (e.endswith(\"_qtr1\") or e.endswith(\"_qrt1\")) and (e != \"has_concurrent_qtr1\") and (e.startswith(\"prior_\") == False)]\n",
    "concurrent_lms = [e for e in predictors if e.endswith(\"_qtr1c\") or e.endswith(\"_qrt1c\") or e == 'has_concurrent_qtr1']\n",
    "historical_early_lms = [e for e in predictors if e.startswith(\"prior\") and (e.endswith(\"_qrt1\") or e.endswith(\"_qtr1\"))]\n",
    "historical_full_lms = [e for e in predictors if e.startswith(\"prior\") and e.endswith(\"_qrt1\") == False and e.endswith(\"_qtr1\") == False]\n",
    "all_lms = early_lms + concurrent_lms + historical_early_lms + historical_full_lms\n",
    "assign_lms = [e for e in all_lms if \"assign\" in e]\n",
    "disc_lms = [e for e in all_lms if \"disc\" in e or \"word\" in e or \"post\" in e]\n",
    "click_lms = [e for e in all_lms if e not in assign_lms + disc_lms]\n",
    "all_admin = [e for e in predictors if e not in set(all_lms)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>predictor_type</th>\n",
       "      <th>ranking</th>\n",
       "      <th>feature_importance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>tot_click_cnt_qrt1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>pct_withdrawn</td>\n",
       "      <td>Admin</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cum_gpa</td>\n",
       "      <td>Admin</td>\n",
       "      <td>3</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>crnt_enrl_intensity</td>\n",
       "      <td>Admin</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>tot_time_qrt1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>5</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>term_gpa_1</td>\n",
       "      <td>Admin</td>\n",
       "      <td>6</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>assign_sub_cnt_qtr1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>7</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HUM_SCI_grade</td>\n",
       "      <td>Admin</td>\n",
       "      <td>8</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>term_gpa_2</td>\n",
       "      <td>Admin</td>\n",
       "      <td>9</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>overall_prop_comp</td>\n",
       "      <td>Admin</td>\n",
       "      <td>10</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>avg_g_concurrent</td>\n",
       "      <td>Admin</td>\n",
       "      <td>11</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>irreg_session_len_qrt1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>12</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>past_avg_grade</td>\n",
       "      <td>Admin</td>\n",
       "      <td>13</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>tot_click_cnt_qrt1c</td>\n",
       "      <td>LMS</td>\n",
       "      <td>14</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>on_time_assign_share_qtr1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>15</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>avg_session_len_qrt1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>16</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>tot_time_qrt1c</td>\n",
       "      <td>LMS</td>\n",
       "      <td>17</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>irreg_session_len_qrt1c</td>\n",
       "      <td>LMS</td>\n",
       "      <td>18</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>avg_session_len_qrt1c</td>\n",
       "      <td>LMS</td>\n",
       "      <td>19</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SOC_SCI_grade</td>\n",
       "      <td>Admin</td>\n",
       "      <td>20</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     predictor predictor_type  ranking  \\\n",
       "103         tot_click_cnt_qrt1            LMS        1   \n",
       "66               pct_withdrawn          Admin        2   \n",
       "31                     cum_gpa          Admin        3   \n",
       "29         crnt_enrl_intensity          Admin        4   \n",
       "105              tot_time_qrt1            LMS        5   \n",
       "101                 term_gpa_1          Admin        6   \n",
       "21         assign_sub_cnt_qtr1            LMS        7   \n",
       "9                HUM_SCI_grade          Admin        8   \n",
       "102                 term_gpa_2          Admin        9   \n",
       "61           overall_prop_comp          Admin       10   \n",
       "25            avg_g_concurrent          Admin       11   \n",
       "53      irreg_session_len_qrt1            LMS       12   \n",
       "62              past_avg_grade          Admin       13   \n",
       "104        tot_click_cnt_qrt1c            LMS       14   \n",
       "57   on_time_assign_share_qtr1            LMS       15   \n",
       "26        avg_session_len_qrt1            LMS       16   \n",
       "106             tot_time_qrt1c            LMS       17   \n",
       "54     irreg_session_len_qrt1c            LMS       18   \n",
       "27       avg_session_len_qrt1c            LMS       19   \n",
       "19               SOC_SCI_grade          Admin       20   \n",
       "\n",
       "     feature_importance_score  \n",
       "103                     0.033  \n",
       "66                      0.032  \n",
       "31                      0.031  \n",
       "29                      0.031  \n",
       "105                     0.028  \n",
       "101                     0.025  \n",
       "21                      0.022  \n",
       "9                       0.021  \n",
       "102                     0.019  \n",
       "61                      0.018  \n",
       "25                      0.018  \n",
       "53                      0.017  \n",
       "62                      0.017  \n",
       "104                     0.017  \n",
       "57                      0.017  \n",
       "26                      0.017  \n",
       "106                     0.016  \n",
       "54                      0.016  \n",
       "27                      0.016  \n",
       "19                      0.015  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_df_top20 = fi_df.iloc[:20,:]\n",
    "fi_df_top20.loc[:,'feature_ranking'] = np.arange(1,21)\n",
    "fi_df_top20 = fi_df_top20.round(3)\n",
    "fi_df_top20.loc[:,'predictor_type'] = fi_df_top20.predictor.apply(lambda x: \"LMS\" if x in set(all_lms) else \"Admin\")\n",
    "fi_df_top20 = fi_df_top20.rename(columns = {'feature_importance': 'feature_importance_score',\n",
    "                                            'feature_ranking': 'ranking'})\n",
    "fi_df_top20 = fi_df_top20.loc[:,['predictor', 'predictor_type', 'ranking', 'feature_importance_score']]\n",
    "fi_df_top20.to_csv(results_dir + \"top20_predictors_BIO101.csv\", index=False)\n",
    "fi_df_top20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('early_lms', 12, 0.006802721088435374, 0.19784580498866214),\n",
       " ('concurrent_lms', 9, 0.09523809523809523, 0.3121693121693122),\n",
       " ('historical_early_lms', 13, 0.272108843537415, 0.46624803767660905),\n",
       " ('historical_full_lms', 16, 0.2585034013605442, 0.4162414965986395),\n",
       " ('click_lms', 22, 0.006802721088435374, 0.30612244897959184),\n",
       " ('assign_lms', 16, 0.047619047619047616, 0.45875850340136054),\n",
       " ('disc_lms', 12, 0.20408163265306123, 0.31916099773242634),\n",
       " ('all_lms', 50, 0.006802721088435374, 0.3580952380952381),\n",
       " ('all_admin', 97, 0.013605442176870748, 0.5783014236622483)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_results = []\n",
    "for c in ['early_lms', 'concurrent_lms', 'historical_early_lms', 'historical_full_lms', 'click_lms', 'assign_lms', 'disc_lms', 'all_lms', 'all_admin']:\n",
    "    l = fi_df.merge(pd.DataFrame({'predictor': eval(c)}), how='inner', on=['predictor']).feature_ranking\n",
    "    fi_results.append((c, len(l), l.iloc[0], l.mean()))\n",
    "fi_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor_category</th>\n",
       "      <th>number_of_predictors</th>\n",
       "      <th>highest_normalized_ranking</th>\n",
       "      <th>average_normalized_ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Early-term LMS</td>\n",
       "      <td>12</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Early-term concurrent LMS</td>\n",
       "      <td>9</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Historical early-term LMS</td>\n",
       "      <td>13</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Historical full-term LMS</td>\n",
       "      <td>16</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LMS -- clicks/session/time</td>\n",
       "      <td>22</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LMS -- assignments</td>\n",
       "      <td>16</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LMS -- discussion forums</td>\n",
       "      <td>12</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>All LMS</td>\n",
       "      <td>50</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>All admin</td>\n",
       "      <td>97</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           predictor_category  number_of_predictors  \\\n",
       "0              Early-term LMS                    12   \n",
       "1   Early-term concurrent LMS                     9   \n",
       "2   Historical early-term LMS                    13   \n",
       "3    Historical full-term LMS                    16   \n",
       "4  LMS -- clicks/session/time                    22   \n",
       "5          LMS -- assignments                    16   \n",
       "6    LMS -- discussion forums                    12   \n",
       "7                     All LMS                    50   \n",
       "8                   All admin                    97   \n",
       "\n",
       "   highest_normalized_ranking  average_normalized_ranking  \n",
       "0                       0.007                       0.198  \n",
       "1                       0.095                       0.312  \n",
       "2                       0.272                       0.466  \n",
       "3                       0.259                       0.416  \n",
       "4                       0.007                       0.306  \n",
       "5                       0.048                       0.459  \n",
       "6                       0.204                       0.319  \n",
       "7                       0.007                       0.358  \n",
       "8                       0.014                       0.578  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_dict = {'early_lms': \"Early-term LMS\",\n",
    "                 'concurrent_lms': 'Early-term concurrent LMS',\n",
    "                 'historical_early_lms': 'Historical early-term LMS',\n",
    "                 'historical_full_lms': 'Historical full-term LMS',\n",
    "                 'click_lms': 'LMS -- clicks/session/time',\n",
    "                 'assign_lms': 'LMS -- assignments',\n",
    "                 'disc_lms': 'LMS -- discussion forums',\n",
    "                 'all_lms': 'All LMS',\n",
    "                 'all_admin': 'All admin'}\n",
    "fi_df = pd.DataFrame(fi_results, columns=['predictor_category', 'number_of_predictors', 'highest_normalized_ranking', 'average_normalized_ranking']).round(3)\n",
    "fi_df.loc[:,'predictor_category'] = fi_df.predictor_category.apply(lambda x: category_dict[x])\n",
    "fi_df.to_csv(results_dir + \"normalized_feature_ranking_BIO101.csv\", index=False)\n",
    "fi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
