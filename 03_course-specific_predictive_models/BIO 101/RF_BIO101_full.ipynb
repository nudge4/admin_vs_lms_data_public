{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script fits the random forest model for the course BIO 101, using the full set of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from scipy.stats.mstats import gmean\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_dir = \"~\\\\Box Sync\\\\Clickstream\\\\evaluation_results\\\\full\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sn_dict = {\"Blue Ridge\": \"BRCC\",\n",
    "           \"Central Virginia\": \"CVCC\",\n",
    "           \"Dabney S. Lancaster\": \"DSLCC\",\n",
    "           \"Danville\": \"DCC\",\n",
    "           \"Eastern Shore\": \"ESCC\",\n",
    "           \"Germanna\": \"GCC\",\n",
    "           'J. Sargeant Reynolds': \"JSRCC\",\n",
    "           'John Tyler': \"JTCC\",\n",
    "           \"Lord Fairfax\": \"LFCC\",\n",
    "           \"Mountain Empire\": \"MECC\",\n",
    "           \"New River\": \"NRCC\",\n",
    "           \"Northern Virginia\": \"NVCC\",\n",
    "           \"Patrick Henry\": \"PHCC\",\n",
    "           \"Paul D. Camp\": \"PDCCC\",\n",
    "           \"Piedmont Virginia\": \"PVCC\",\n",
    "           \"Rappahannock\": \"RCC\",\n",
    "           \"Southside Virginia\": \"SSVCC\",\n",
    "           \"Southwest Virginia\": \"SWVCC\",\n",
    "           \"Thomas Nelson\": \"TNCC\",\n",
    "           \"Tidewater\": \"TCC\",\n",
    "           \"Virginia Highlands\": \"VHCC\",\n",
    "           \"Virginia Western\": \"VWCC\",\n",
    "           \"Wytheville\": \"WCC\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\LMS_data_final_full_new.csv\")\n",
    "df1 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\course_specific_predictors_new.csv\")\n",
    "df2 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\term_specific_predictors_new.csv\")\n",
    "df3 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\cluster_specific_predictors.csv\")\n",
    "df3 = df3.loc[:,['vccsid','strm','college','course','section'] + [e for e in df3.columns.values if e.endswith(\"SCI\") or e.endswith(\"SCI_grade\")]]\n",
    "df4 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\instructor_related_predictors.dta\")\n",
    "df = df0.merge(df1, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df2, how='inner', on=['vccsid','strm'])\\\n",
    ".merge(df3, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df4, how='inner', on=['vccsid','strm','college','course','section'])\n",
    "df = df[df.course == \"BIO_101\"]\n",
    "df.loc[:,'first_ind'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df0 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\LMS_data_final.dta\")\n",
    "df1 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\course_specific_predictors_new.csv\")\n",
    "df2 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\term_specific_predictors_new.csv\")\n",
    "df4 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\instructor_related_predictors.dta\")\n",
    "df5 = df0.loc[:,['vccsid','strm','college','course','section']].copy()\n",
    "df_first = df0.merge(df1, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df2, how='inner', on=['vccsid','strm'])\\\n",
    ".merge(df4, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df5, how='inner', on=['vccsid','strm','college','course','section'])\n",
    "df_first = df_first[df_first.course == \"BIO_101\"]\n",
    "df_first.loc[:,'first_ind'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df, df_first], axis=0, join='outer').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 32208, 1: 6598})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df.first_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for v in [int(e) for e in np.unique(df.cip) if e != 0]:\n",
    "    df.loc[:,'cip_'+str(v)] = (df.cip == v).astype(int)\n",
    "for v in [int(e) for e in np.unique(df.degree_level) if e != 4]:\n",
    "    df.loc[:,'degree_level_'+str(v)] = (df.degree_level == v).astype(int)\n",
    "df = df.drop(['cip', 'degree_level'], axis=1)\n",
    "df.loc[:,'college_new'] = df.college.apply(lambda x: sn_dict[x])\n",
    "for sn in [e for e in sn_dict.values() if e != \"BRCC\"]:\n",
    "    df.loc[:,'college_'+sn] = (df.college_new == sn).astype(int)\n",
    "df = df.drop(['college_new'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>has_prereq_grade</th>\n",
       "      <td>38806.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lvl2_ind</th>\n",
       "      <td>38806.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prereq_grade</th>\n",
       "      <td>38806.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count  mean  std  min  25%  50%  75%  max\n",
       "has_prereq_grade  38806.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "lvl2_ind          38806.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "prereq_grade      38806.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.describe().T\n",
    "test[test['mean'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['lvl2_ind', 'has_prereq_grade', 'prereq_grade'], axis=1)\n",
    "predictors = [e for e in list(df.columns) if e not in {\"grade\",'vccsid','strm','college','course','section'}]\n",
    "len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert pd.isnull(df).any().any() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38806, 153)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29925, 153) (8881, 153)\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df.strm != 2212]\n",
    "test_df = df[df.strm == 2212]\n",
    "original_test_grade = np.array(test_df.grade)\n",
    "train_df.loc[:,'grade'] = train_df.apply(lambda x: 1 if x.loc['grade'] in {'A','B','C'} else 0, axis=1)\n",
    "test_df.loc[:,'grade'] = test_df.apply(lambda x: 1 if x.loc['grade'] in {'A','B','C'} else 0, axis=1)\n",
    "print(train_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "online_ind_df_1 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\updated_online_ind.dta\")\n",
    "online_ind_df_2 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\updated_online_ind.dta\")\n",
    "online_ind_df = pd.concat([online_ind_df_1, online_ind_df_2])\n",
    "test_df = test_df.merge(online_ind_df, how='inner', on=['vccsid','strm','college','course','section'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 8873, 1.0: 8})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(test_df.inperson_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[np.array(test_df.inperson_ind == 1) & np.array(test_df.first_ind == 1)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ART_SCI</th>\n",
       "      <th>ART_SCI_grade</th>\n",
       "      <th>BUS_SCI</th>\n",
       "      <th>BUS_SCI_grade</th>\n",
       "      <th>EGR_SCI</th>\n",
       "      <th>EGR_SCI_grade</th>\n",
       "      <th>FLA_SCI</th>\n",
       "      <th>FLA_SCI_grade</th>\n",
       "      <th>HUM_SCI</th>\n",
       "      <th>HUM_SCI_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>college_DSLCC</th>\n",
       "      <th>college_PHCC</th>\n",
       "      <th>college_RCC</th>\n",
       "      <th>college_VWCC</th>\n",
       "      <th>college_WCC</th>\n",
       "      <th>college_NRCC</th>\n",
       "      <th>college_JSRCC</th>\n",
       "      <th>college_CVCC</th>\n",
       "      <th>online_ind_y</th>\n",
       "      <th>inperson_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.538461</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.538461</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.437500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.437500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.769231</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.076923</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.076923</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8247</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8248</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8249</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.590909</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8250</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.789474</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.505796</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8251</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.538461</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8252</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8253</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8254</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8255</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8256</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.210526</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8257</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.214286</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8258</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8259</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8260</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8261</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8262</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8263</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.363726</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8264</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8265</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8266</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8267</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8268</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.850938</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8269</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8270</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8271</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.538461</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8272</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8273</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8274</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8275</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.052632</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8276</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8277 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ART_SCI  ART_SCI_grade  BUS_SCI  BUS_SCI_grade  EGR_SCI  EGR_SCI_grade  \\\n",
       "0         1.0            3.0      1.0            4.0      1.0       1.500000   \n",
       "1         1.0            3.0      1.0            4.0      1.0       1.500000   \n",
       "2         1.0            3.0      1.0            4.0      1.0       3.000000   \n",
       "3         1.0            3.0      1.0            4.0      1.0       3.000000   \n",
       "4         0.0            0.0      1.0            2.0      1.0       3.000000   \n",
       "5         0.0            0.0      1.0            2.0      1.0       3.000000   \n",
       "6         0.0            0.0      1.0            4.0      1.0       4.000000   \n",
       "7         0.0            0.0      1.0            4.0      1.0       4.000000   \n",
       "8         1.0            3.0      1.0            3.0      1.0       3.571429   \n",
       "9         1.0            3.0      1.0            3.0      1.0       3.571429   \n",
       "10        0.0            0.0      1.0            3.0      1.0       3.000000   \n",
       "11        1.0            4.0      1.0            3.0      1.0       2.000000   \n",
       "12        0.0            0.0      1.0            3.0      1.0       2.000000   \n",
       "13        0.0            0.0      1.0            4.0      0.0       0.000000   \n",
       "14        0.0            0.0      1.0            4.0      0.0       0.000000   \n",
       "15        0.0            0.0      1.0            3.0      1.0       4.000000   \n",
       "16        0.0            0.0      1.0            3.0      1.0       4.000000   \n",
       "17        0.0            0.0      1.0            3.0      1.0       2.000000   \n",
       "18        0.0            0.0      1.0            3.0      1.0       2.000000   \n",
       "19        1.0            3.0      1.0            3.0      1.0       3.000000   \n",
       "20        1.0            3.0      1.0            3.0      1.0       3.000000   \n",
       "21        1.0            2.0      1.0            2.0      1.0       3.000000   \n",
       "22        1.0            2.0      1.0            2.0      1.0       3.000000   \n",
       "23        0.0            0.0      1.0            1.0      1.0       2.000000   \n",
       "24        0.0            0.0      1.0            1.0      1.0       2.000000   \n",
       "25        0.0            0.0      1.0            2.0      1.0       4.000000   \n",
       "26        0.0            0.0      1.0            2.0      1.0       4.000000   \n",
       "27        0.0            0.0      1.0            3.0      0.0       0.000000   \n",
       "28        0.0            0.0      1.0            3.0      0.0       0.000000   \n",
       "29        0.0            0.0      1.0            2.0      0.0       0.000000   \n",
       "...       ...            ...      ...            ...      ...            ...   \n",
       "8247      1.0            4.0      0.0            0.0      1.0       4.000000   \n",
       "8248      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8249      1.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8250      0.0            0.0      0.0            0.0      1.0       3.000000   \n",
       "8251      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8252      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8253      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8254      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8255      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8256      1.0            2.0      1.0            3.0      1.0       1.000000   \n",
       "8257      1.0            2.0      0.0            0.0      1.0       3.500000   \n",
       "8258      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8259      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8260      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8261      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8262      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8263      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8264      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8265      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8266      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8267      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8268      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8269      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8270      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8271      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8272      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8273      0.0            0.0      0.0            0.0      0.0       0.000000   \n",
       "8274      0.0            0.0      0.0            0.0      1.0       2.500000   \n",
       "8275      1.0            3.0      0.0            0.0      1.0       2.000000   \n",
       "8276      1.0            4.0      1.0            4.0      0.0       0.000000   \n",
       "\n",
       "      FLA_SCI  FLA_SCI_grade  HUM_SCI  HUM_SCI_grade      ...       \\\n",
       "0         1.0       4.000000      1.0       3.500000      ...        \n",
       "1         1.0       4.000000      1.0       3.500000      ...        \n",
       "2         0.0       0.000000      1.0       3.700000      ...        \n",
       "3         0.0       0.000000      1.0       3.700000      ...        \n",
       "4         0.0       0.000000      1.0       3.000000      ...        \n",
       "5         0.0       0.000000      1.0       3.000000      ...        \n",
       "6         0.0       0.000000      1.0       2.538461      ...        \n",
       "7         0.0       0.000000      1.0       2.538461      ...        \n",
       "8         0.0       0.000000      1.0       3.437500      ...        \n",
       "9         0.0       0.000000      1.0       3.437500      ...        \n",
       "10        0.0       0.000000      1.0       3.700000      ...        \n",
       "11        0.0       0.000000      1.0       3.769231      ...        \n",
       "12        0.0       0.000000      1.0       4.000000      ...        \n",
       "13        0.0       0.000000      1.0       4.000000      ...        \n",
       "14        0.0       0.000000      1.0       4.000000      ...        \n",
       "15        0.0       0.000000      1.0       3.250000      ...        \n",
       "16        0.0       0.000000      1.0       3.250000      ...        \n",
       "17        0.0       0.000000      1.0       3.076923      ...        \n",
       "18        0.0       0.000000      1.0       3.076923      ...        \n",
       "19        0.0       0.000000      1.0       3.333333      ...        \n",
       "20        0.0       0.000000      1.0       3.333333      ...        \n",
       "21        0.0       0.000000      1.0       3.000000      ...        \n",
       "22        0.0       0.000000      1.0       3.000000      ...        \n",
       "23        0.0       0.000000      1.0       4.000000      ...        \n",
       "24        0.0       0.000000      1.0       4.000000      ...        \n",
       "25        0.0       0.000000      1.0       2.176471      ...        \n",
       "26        0.0       0.000000      1.0       2.176471      ...        \n",
       "27        0.0       0.000000      1.0       0.000000      ...        \n",
       "28        0.0       0.000000      1.0       0.000000      ...        \n",
       "29        0.0       0.000000      0.0       0.000000      ...        \n",
       "...       ...            ...      ...            ...      ...        \n",
       "8247      0.0       0.000000      1.0       4.000000      ...        \n",
       "8248      1.0       4.000000      1.0       4.000000      ...        \n",
       "8249      1.0       4.000000      1.0       2.590909      ...        \n",
       "8250      1.0       3.789474      1.0       2.505796      ...        \n",
       "8251      0.0       0.000000      1.0       3.538461      ...        \n",
       "8252      0.0       0.000000      1.0       2.500000      ...        \n",
       "8253      0.0       0.000000      1.0       3.700000      ...        \n",
       "8254      0.0       0.000000      1.0       3.000000      ...        \n",
       "8255      0.0       0.000000      1.0       1.000000      ...        \n",
       "8256      1.0       3.000000      1.0       3.210526      ...        \n",
       "8257      0.0       0.000000      1.0       3.214286      ...        \n",
       "8258      0.0       0.000000      1.0       1.153846      ...        \n",
       "8259      0.0       0.000000      1.0       1.000000      ...        \n",
       "8260      0.0       0.000000      0.0       0.000000      ...        \n",
       "8261      0.0       0.000000      1.0       2.400000      ...        \n",
       "8262      1.0       4.000000      1.0       3.000000      ...        \n",
       "8263      0.0       0.000000      1.0       3.363726      ...        \n",
       "8264      0.0       0.000000      1.0       3.400000      ...        \n",
       "8265      0.0       0.000000      1.0       3.428571      ...        \n",
       "8266      0.0       0.000000      1.0       2.090909      ...        \n",
       "8267      0.0       0.000000      1.0       0.428571      ...        \n",
       "8268      0.0       0.000000      1.0       2.850938      ...        \n",
       "8269      0.0       0.000000      1.0       4.000000      ...        \n",
       "8270      0.0       0.000000      1.0       3.000000      ...        \n",
       "8271      0.0       0.000000      1.0       3.538461      ...        \n",
       "8272      0.0       0.000000      1.0       4.000000      ...        \n",
       "8273      0.0       0.000000      1.0       4.000000      ...        \n",
       "8274      0.0       0.000000      1.0       2.500000      ...        \n",
       "8275      1.0       3.000000      1.0       3.052632      ...        \n",
       "8276      0.0       0.000000      1.0       3.700000      ...        \n",
       "\n",
       "      college_DSLCC  college_PHCC  college_RCC  college_VWCC  college_WCC  \\\n",
       "0                 0             0            0             0            0   \n",
       "1                 0             0            0             0            0   \n",
       "2                 0             0            0             0            0   \n",
       "3                 0             0            0             0            0   \n",
       "4                 0             0            0             0            0   \n",
       "5                 0             0            0             0            0   \n",
       "6                 0             0            0             0            0   \n",
       "7                 0             0            0             0            0   \n",
       "8                 0             0            0             0            0   \n",
       "9                 0             0            0             0            0   \n",
       "10                0             0            0             0            0   \n",
       "11                0             0            0             0            0   \n",
       "12                0             0            0             0            0   \n",
       "13                0             0            0             0            0   \n",
       "14                0             0            0             0            0   \n",
       "15                0             0            0             0            0   \n",
       "16                0             0            0             0            0   \n",
       "17                0             0            0             0            0   \n",
       "18                0             0            0             0            0   \n",
       "19                0             0            0             0            0   \n",
       "20                0             0            0             0            0   \n",
       "21                0             0            0             0            0   \n",
       "22                0             0            0             0            0   \n",
       "23                0             0            0             0            0   \n",
       "24                0             0            0             0            0   \n",
       "25                0             0            0             0            0   \n",
       "26                0             0            0             0            0   \n",
       "27                0             0            0             0            0   \n",
       "28                0             0            0             0            0   \n",
       "29                0             0            0             0            0   \n",
       "...             ...           ...          ...           ...          ...   \n",
       "8247              0             0            0             0            0   \n",
       "8248              0             0            0             0            0   \n",
       "8249              0             0            0             0            0   \n",
       "8250              0             0            0             0            0   \n",
       "8251              0             0            0             0            0   \n",
       "8252              0             0            0             0            0   \n",
       "8253              0             0            0             0            0   \n",
       "8254              0             0            0             0            0   \n",
       "8255              0             0            0             0            0   \n",
       "8256              0             0            0             0            0   \n",
       "8257              0             0            0             0            0   \n",
       "8258              0             0            0             0            0   \n",
       "8259              0             0            0             0            0   \n",
       "8260              0             0            0             0            0   \n",
       "8261              0             0            0             0            0   \n",
       "8262              0             0            0             0            0   \n",
       "8263              0             0            0             0            0   \n",
       "8264              0             0            0             0            0   \n",
       "8265              0             0            0             0            0   \n",
       "8266              0             0            0             0            0   \n",
       "8267              0             0            0             0            0   \n",
       "8268              0             0            0             0            0   \n",
       "8269              0             0            0             0            0   \n",
       "8270              0             0            0             0            0   \n",
       "8271              0             0            0             0            0   \n",
       "8272              0             0            0             0            0   \n",
       "8273              0             0            0             0            0   \n",
       "8274              0             0            0             0            0   \n",
       "8275              0             0            0             0            0   \n",
       "8276              0             0            0             0            0   \n",
       "\n",
       "      college_NRCC  college_JSRCC  college_CVCC  online_ind_y  inperson_ind  \n",
       "0                0              0             0           1.0           0.0  \n",
       "1                0              0             0           1.0           0.0  \n",
       "2                0              0             0           1.0           0.0  \n",
       "3                0              0             0           1.0           0.0  \n",
       "4                0              0             0           1.0           0.0  \n",
       "5                0              0             0           1.0           0.0  \n",
       "6                0              0             0           1.0           0.0  \n",
       "7                0              0             0           1.0           0.0  \n",
       "8                0              0             0           1.0           0.0  \n",
       "9                0              0             0           1.0           0.0  \n",
       "10               0              0             0           1.0           0.0  \n",
       "11               0              0             0           1.0           0.0  \n",
       "12               0              0             0           1.0           0.0  \n",
       "13               0              0             0           1.0           0.0  \n",
       "14               0              0             0           1.0           0.0  \n",
       "15               0              0             0           1.0           0.0  \n",
       "16               0              0             0           1.0           0.0  \n",
       "17               0              0             0           1.0           0.0  \n",
       "18               0              0             0           1.0           0.0  \n",
       "19               0              0             0           1.0           0.0  \n",
       "20               0              0             0           1.0           0.0  \n",
       "21               0              0             0           1.0           0.0  \n",
       "22               0              0             0           1.0           0.0  \n",
       "23               0              0             0           1.0           0.0  \n",
       "24               0              0             0           1.0           0.0  \n",
       "25               0              0             0           1.0           0.0  \n",
       "26               0              0             0           1.0           0.0  \n",
       "27               0              0             0           1.0           0.0  \n",
       "28               0              0             0           1.0           0.0  \n",
       "29               0              0             0           1.0           0.0  \n",
       "...            ...            ...           ...           ...           ...  \n",
       "8247             0              0             0           1.0           0.0  \n",
       "8248             0              0             0           1.0           0.0  \n",
       "8249             0              0             0           1.0           0.0  \n",
       "8250             0              0             0           1.0           0.0  \n",
       "8251             0              0             0           1.0           0.0  \n",
       "8252             0              0             0           1.0           0.0  \n",
       "8253             0              0             0           1.0           0.0  \n",
       "8254             0              0             0           1.0           0.0  \n",
       "8255             0              0             0           1.0           0.0  \n",
       "8256             0              0             0           1.0           0.0  \n",
       "8257             0              0             0           1.0           0.0  \n",
       "8258             0              0             0           1.0           0.0  \n",
       "8259             0              0             0           1.0           0.0  \n",
       "8260             0              0             0           1.0           0.0  \n",
       "8261             0              0             0           1.0           0.0  \n",
       "8262             0              0             0           1.0           0.0  \n",
       "8263             0              0             0           1.0           0.0  \n",
       "8264             0              0             0           1.0           0.0  \n",
       "8265             0              0             0           1.0           0.0  \n",
       "8266             0              0             0           1.0           0.0  \n",
       "8267             0              0             0           1.0           0.0  \n",
       "8268             0              0             0           1.0           0.0  \n",
       "8269             0              0             0           1.0           0.0  \n",
       "8270             0              0             0           1.0           0.0  \n",
       "8271             0              0             0           1.0           0.0  \n",
       "8272             0              0             0           1.0           0.0  \n",
       "8273             0              0             0           1.0           0.0  \n",
       "8274             0              0             0           1.0           0.0  \n",
       "8275             0              0             0           1.0           0.0  \n",
       "8276             0              0             0           1.0           0.0  \n",
       "\n",
       "[8277 rows x 155 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_ind = test_df.online_ind_y\n",
    "inperson_ind = test_df.inperson_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 8277, 1: 604})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(test_df.first_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cv_folds(train, n_fold = 5):\n",
    "    folds = []\n",
    "    k_fold = StratifiedKFold(n_splits = n_fold, random_state = 12345, shuffle=True)\n",
    "    for train_indices, test_indices in k_fold.split(train, train.grade):\n",
    "        train_part = train.iloc[train_indices,:]\n",
    "        test_part = train.iloc[test_indices,:]\n",
    "        X_1 = train_part.loc[:,predictors]\n",
    "        y_1 = train_part.grade\n",
    "        X_2 = test_part.loc[:,predictors]\n",
    "        y_2 = test_part.grade\n",
    "        folds.append([(X_1.copy(),y_1.copy()),(X_2.copy(),y_2.copy())])\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "five_folds = create_cv_folds(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_RF(rf_model, folds):\n",
    "    auc_by_fold = []\n",
    "    for f in folds:\n",
    "        X_1 = f[0][0]\n",
    "        y_1 = f[0][1]\n",
    "        X_2 = f[1][0]\n",
    "        y_2 = f[1][1]\n",
    "        rf_model.fit(X_1,y_1)\n",
    "        y_2_pred = rf_model.predict_proba(X_2)[:,1]\n",
    "        auc_by_fold.append(roc_auc_score(y_2,y_2_pred))\n",
    "    return round(np.mean(auc_by_fold),4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_cw(y):\n",
    "    # Calculate the weight of each letter grade to be used in the modeling fitting procedure: the weight is inversely proportional to the square root of the frequency of the letter grade in the training sample\n",
    "    cw = Counter(y)\n",
    "    class_weight = {k:np.sqrt(cw.most_common()[0][-1]/v, dtype=np.float32) for k,v in cw.items()}\n",
    "    return class_weight # The output is a dictionary mapping letter grade to the corresponding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_depth = 2\n",
      "Mean CV AUC: 0.7802\n",
      "\n",
      "Max_depth = 3\n",
      "Mean CV AUC: 0.7935\n",
      "\n",
      "Max_depth = 4\n",
      "Mean CV AUC: 0.8033\n",
      "\n",
      "Max_depth = 5\n",
      "Mean CV AUC: 0.8132\n",
      "\n",
      "Max_depth = 6\n",
      "Mean CV AUC: 0.8213\n",
      "\n",
      "Max_depth = 7\n",
      "Mean CV AUC: 0.829\n",
      "\n",
      "Max_depth = 8\n",
      "Mean CV AUC: 0.8367\n",
      "\n",
      "Max_depth = 9\n",
      "Mean CV AUC: 0.8448\n",
      "\n",
      "Max_depth = 10\n",
      "Mean CV AUC: 0.8525\n",
      "\n",
      "Max_depth = 11\n",
      "Mean CV AUC: 0.86\n",
      "\n",
      "Max_depth = 12\n",
      "Mean CV AUC: 0.8672\n",
      "\n",
      "Max_depth = 13\n",
      "Mean CV AUC: 0.874\n",
      "\n",
      "Max_depth = 14\n",
      "Mean CV AUC: 0.8791\n",
      "\n",
      "Max_depth = 15\n",
      "Mean CV AUC: 0.8841\n",
      "\n",
      "Max_depth = 16\n",
      "Mean CV AUC: 0.8877\n",
      "\n",
      "Max_depth = 17\n",
      "Mean CV AUC: 0.8913\n",
      "\n",
      "Max_depth = 18\n",
      "Mean CV AUC: 0.8944\n",
      "\n",
      "Max_depth = 19\n",
      "Mean CV AUC: 0.8963\n",
      "\n",
      "Max_depth = 20\n",
      "Mean CV AUC: 0.8984\n",
      "\n",
      "Max_depth = 21\n",
      "Mean CV AUC: 0.8993\n",
      "\n",
      "Max_depth = 22\n",
      "Mean CV AUC: 0.9012\n",
      "\n",
      "Max_depth = 23\n",
      "Mean CV AUC: 0.9018\n",
      "\n",
      "Max_depth = 24\n",
      "Mean CV AUC: 0.9032\n",
      "\n",
      "Max_depth = 25\n",
      "Mean CV AUC: 0.9028\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VPX1//HXIRACYSdh31dZZRlB\n1KrVopS27q2gqLRQtC79/qzWWqut2kVrF7tZKlIWEaTUFeuuVeuCkARk3/ewhGDYQiDr+f0xg8YY\nGJZMbiZ5Px8PHjP33s+dOblM5p37ufd+rrk7IiIix1Ir6AJERKTqU1iIiEhUCgsREYlKYSEiIlEp\nLEREJCqFhYiIRKWwEBGRqBQWIiISlcJCRESiqh10ARUlJSXFO3XqFHQZIiJxJSMjY7e7p0ZrV23C\nolOnTqSnpwddhohIXDGzzcfTTt1QIiISlcJCRESiUliIiEhUCgsREYlKYSEiIlEpLEREJCqFhYiI\nRFVtrrMQEYlHRcUlbM7JY23WAdZnH8QMkhNrk1y3NsmJCeHHugnUT6xNg7q1qR+ZV7d2Lcys0upU\nWIiIVIKSEmfb3kOs3nmANbsOsGbnAVZn5bI+O5eCopITfr2EWkb9xAQa1K3NxX1acf8lfWJQ9ecU\nFiIiFcDdySsoZu+hQvYcLCA7N591WbmsyTrAmqwDrN2VS15B8Wft2zROokerhnylewo9WjakR8sG\ndGvRgFpmHMwvIq+gmNz8IvIKisjNLyYvvygyXczBgiIO5hdxML+Yg/lFdE5JjvnPF9OwMLMRwJ+B\nBGCyuz9cZnlHYAqQCuQAY9w9M7LsBuDeSNNfufv0WNYqIlKWu7Nh90HWZuWyN6+APXmF7D1UwN6D\nhezJK2DvoUL25hWwN6+QvXmFFBR/eQ8htWFderRswNVntI+EQkO6t2xAo6Q6R33fpDoJNI/lD3YS\nYhYWZpYAPAYMBzKBNDOb6+4rSjX7PfCku083swuAh4DrzKwZ8AsgBDiQEVl3T6zqFRE5XFjMsm37\nSN+8h/RNe1i4ZQ85Bwu+0CYxoRZN6tehaf1EmtSvQ+eU5MjzxMj8OjSpn0iz5ES6pjagWXJiQD9N\nxYrlnsUQYJ27bwAws9nApUDpsOgN3B55/g7wQuT5xcCb7p4TWfdNYATwdAzrFZEa5tPcfDI27yFj\n8x7SN+9haea+z/YOOqckc8FpLQh1bEqfNo1p1iCRpvXrUK9OQqUeWK4qYhkWbYGtpaYzgaFl2iwG\nriTcVXU50NDMmh9l3bZl38DMJgATADp06FBhhYtI9VJS4uTkFbBz32FWbN9P2qYcMjbvYcPugwDU\nSTD6tm3MDWd1JNSpGYM7NiWlQd2Aq65aYhkW5UWvl5m+E/ibmY0F/gdsA4qOc13cfRIwCSAUCn1p\nuYhUf8Ulzu7cfHbsO8zOfYcij4c/f9x/iKx9+V84ntCkfh0Gd2jKVaF2hDo2o3+7xiTVSQjwp6j6\nYhkWmUD7UtPtgO2lG7j7duAKADNrAFzp7vvMLBM4v8y678awVhGJA4cLi1m0ZS/zNnzKgo2fsuXT\nPLIO5FNc8sW/FRMTatGqcRKtGicxqENTWjVOonWjJFo1rke3Fsl0SWlArVo1ryvpVMQyLNKA7mbW\nmfAewyjgmtINzCwFyHH3EuCnhM+MAngd+I2ZNY1MXxRZLiI1SGFxCUsy9/LRuk+Zt+FTMjbvIb+o\nhFoGfdo05syuzWndOBwC4TBIonXjJJolJ9bI4wqxFLOwcPciM7uV8Bd/AjDF3Zeb2YNAurvPJbz3\n8JCZOeFuqFsi6+aY2S8JBw7Ag0cOdotI9VVc4izbto95Gz7lo/Wfkr4p57NrE3q1bsS1QzsyrGtz\nhnRuRuN6Rz/1VCqeuVePrv5QKOS6rapIfCksLvnsgPPHGz5l/oYcDuQXAdC9RQOGdW3OsC7NGdql\nebU5BbWqMbMMdw9Fa6cruEWk0uw7VMjCLXvI2LSH9M05LN66j0OF4T2HzinJfPP0Ngzr2pwzuzSj\nRcOkgKuV0hQWIhIT7k7mnkOkbcohfXM4INbsOoB7eFyj3q0bcfUZ7Ql1akqoYzNaNVY4VGUKCxGp\nMFs+zePNlVlkbM4hfdMedh3IB6Bh3doM7NiUb/RvTahjU05v34Tkuvr6iSf63xKRU3Iwv4hXlu7g\nmYxM5m8Mn4fSrmk9zuranMGdmhHq2JQeLRuSoFNV45rCQkROWEmJs2BTDs9kZPLK0h3kFRTTOSWZ\nH1/ck0tOb0P7ZvWDLlEqmMJCRI7b1pw8nlu4jWcXZrIlJ48GdWtzyeltuGpwOwZ3bKprG6oxhYWI\nHFNeQRGvLdvJMxmZfLT+UwDO7tac24d35+I+raifqK+RmkD/yyJSrkVb9jB7wVZeXrqD3PwiOjSr\nz4+G9+CKQW1p11TdTDWNwkJEPlNYXMKry3Yy5YONfLJ1L/UTE/hGv9ZcNbgdQzo3UzdTDaawEBH2\nHCzg6bQtPPnRZnbuP0yn5vV54JI+XDm4HQ10iqugsBCp0dZmHWDqR5t4bmEmhwtLOKdbCr++vC9f\n7dlCo7LKFygsRGqYkhLnvbXZTP1wE/9bk01i7VpcMbAtY8/uxGmtGgVdnlRRCguRGiKvoIhnF25j\n6ocb2ZB9kBYN63LnRT0YPaQDzXVXOIlCYSFSzW3be4gn523i6flb2H+4iP7tGvOnqwcwsl9rEmvX\nCro8iRMKC5FqyN1ZuGUvUz7cyGvLduLuXNynFePO6ayL5+SkKCxEqpHC4hJeWbqDKR9uYvHWvTRM\nqs24czpz/bCOujZCTonCQqQa2HOwgFkLtjBjXvjU1y4pyfzy0j5cMaidRneVCqFPkUgcW5t1gCkf\nbuL5ReFTX7/SPYWHrujHeT1SdeqrVCiFhUicOXLq65QPNvL+2t3UrV2LKwa1ZexZnenZqmHQ5Uk1\npbAQiSP/XZXFr19eyfrsg7RsVJcfX9yT0UM66P7UEnMKC5E4kLknjwdfWsEbK7LomprMn0cN4Ot9\ndeqrVB6FhUgVVlBUwuQPNvCXt9diGD8ZcRrjzumskJBKp7AQqaI+Wreb+15cxvrsg1zUuyU//1Zv\nnf4qgYnpnydmNsLMVpvZOjO7u5zlHczsHTNbZGZLzGxkZH4dM5tuZkvNbKWZ/TSWdYpUJbv2H+aH\nTy/imsnzKSx2po49g0nXhxQUEqiY7VmYWQLwGDAcyATSzGyuu68o1exeYI67TzSz3sArQCfg20Bd\nd+9nZvWBFWb2tLtvilW9IkErKi7hyXmb+eObaygoKuGHF3bn5vO7klQnIejSRGLaDTUEWOfuGwDM\nbDZwKVA6LBw4MsxlY2B7qfnJZlYbqAcUAPtjWKtIoDI27+HeF5axcsd+zu2RygOX9KFzSnLQZYl8\nJpZh0RbYWmo6Exhaps39wBtmdhuQDHwtMv8ZwsGyA6gP3O7uOTGsVSQQOQcL+O2rq/hX+lZaNUpi\n4rWDGNG3lcZukionlmFR3qfdy0yPBqa5+x/MbBgww8z6Et4rKQbaAE2B983srSN7KZ+9gdkEYAJA\nhw4dKrp+kZgpKXHmpG/l4ddWkXu4iBvP7cIPL+yuoTmkyorlJzMTaF9quh2fdzMdMQ4YAeDu88ws\nCUgBrgFec/dCYJeZfQiEgC+EhbtPAiYBhEKhskEkUiWt3nmAnz2/lPTNexjSqRm/urwvPVrqymup\n2mJ5NlQa0N3MOptZIjAKmFumzRbgQgAz6wUkAdmR+RdYWDJwJrAqhrWKxNyhgmIefnUV3/jL+6zP\nzuV3V/XnXzeeqaCQuBCzPQt3LzKzW4HXgQRgirsvN7MHgXR3nwvcATxhZrcT7qIa6+5uZo8BU4Fl\nhLuzprr7kljVKhJr/12Vxc9fXE7mnkN8J9SOu7/eS0N0SFwx9+rRexMKhTw9PT3oMkS+YMe+Qzww\ndwWvLd9JtxYN+PVlfRnapXnQZYl8xswy3D0UrZ2OponEwJFrJv7wxmqKSpwfX9yT73+li4bpkLil\nsBCpYIu37uVnLyxl2bb9nN8zlQcv6UuH5rr6WuKbwkKkguw/XMgfXl/Nkx9vJrVBXR67ZhAj++ma\nCakeFBYiFeDtlVn89Lml7M7N54Zhnbjjoh40TKoTdFkiFUZhIXIK3J2/v7ue372+mt6tGzH5hhD9\n2zUJuiyRCqewEDlJhwuLueuZJcxdvJ1LB7Tht1f216B/Um0pLEROws59h5kwI52l2/Zx14ie/OC8\nrjo2IdWawkLkBH2ydS8TnkznYH4Rk64LMbx3y6BLEok5hYXICXjxk238+JkltGhYlyfHncVprRpF\nX0mkGlBYiByHkhLn92+s5u/vrmdI52ZMvHYQzRvUDboskUqjsBCJIje/iNv/9Qlvrshi9JD2PHBJ\nX12JLTWOwkLkGLbm5DF+ejrrsnO5/1u9ueGsTjqQLTWSwkLkKOZv+JQfzFxIUXEJ0757Bl/pnhp0\nSSKBUViIlOPpBVu474VldGhen8nXh+iS2iDokkQCpbAQKaW4xPnVyyuY+uEmzu2Ryl9HD6RxPQ3b\nIaKwEIk4VFDMD2cv4s0VWXzv7M7cM/I0aifoQLYIKCxEANidm8+46eksydzLA5f04YazOgVdkkiV\norCQGm99di7fnZrGrgOHeXzMYC7q0yrokkSqHIWF1Ghpm3L4/pPpJJgxe8IwBrTXiLEi5VFYSI31\n8pId3D7nE9o1qce07w7R3exEjkFhITWOu/PE+xv4zSurCHVsyhPXh2ianBh0WSJVmsJCapTiEueB\nl5bz5LzNfKNfa/7wndN1DwqR46CwkBojr6CIHz79CW+tzGLCuV24e8Rp1KqloTtEjkdMTyI3sxFm\nttrM1pnZ3eUs72Bm75jZIjNbYmYjSy3rb2bzzGy5mS01s6RY1irVW/aBfEZP+pj/rsriwUv7cM/I\nXgoKkRMQsz0LM0sAHgOGA5lAmpnNdfcVpZrdC8xx94lm1ht4BehkZrWBp4Dr3H2xmTUHCmNVq1Rv\n67NzGTt1AdkH8nlcNysSOSmx7IYaAqxz9w0AZjYbuBQoHRYOHLl7TGNge+T5RcASd18M4O6fxrBO\nqcbSNuUwfno6dRJ0aqzIqYhlN1RbYGup6czIvNLuB8aYWSbhvYrbIvN7AG5mr5vZQjO7K4Z1SjX1\n2rIdXDt5Ps0bJPLcD85WUIicgliGRXkdwl5mejQwzd3bASOBGWZWi/AezznAtZHHy83swi+9gdkE\nM0s3s/Ts7OyKrV7i2qz5W7h55kL6tmnEszedpWsoRE5RLMMiE2hfarodn3czHTEOmAPg7vOAJCAl\nsu577r7b3fMI73UMKvsG7j7J3UPuHkpN1b0GJHwNxV/eXss9zy/lvB6pzBx/pq6hEKkAsQyLNKC7\nmXU2s0RgFDC3TJstwIUAZtaLcFhkA68D/c2sfuRg93l88ViHyJeUlDi/mLucP765hisGtWXS9SHq\nJeoaCpGKELMD3O5eZGa3Ev7iTwCmuPtyM3sQSHf3ucAdwBNmdjvhLqqx7u7AHjP7I+HAceAVd385\nVrVK/MsvKuaOOYv5z5IduoZCJAYs/N0c/0KhkKenpwddhgQgN7+Im2Zk8MG63fz066dx43ldgy5J\nJG6YWYa7h6K10xXcEtd25+bzvWlpLN++n99/+3SuGtwu6JJEqiWFhcStrTl5XD9lATv2HWLSdYO5\nsJcuthOJFYWFxKWVO/Zzw5QFHC4sZub4oQzu2CzokkSqNYWFxJ0FG3MYNz2N+okJ/Pums+jZqmHQ\nJYlUewoLiStvrsji1lkLadu0Hk9+bwjtmupiO5HKoLCQuDEnbSt3P7eEfu2aMHXsGTTTxXYilUZh\nIXHh8ffW89Crqzi3RyoTrx1Ecl19dEUqk37jpEpzdx55fTUT313PN/u35o/fGUBi7ZjehkVEyqGw\nkCqrpMS578VlzJy/hdFDOvCry/qSoKuyRQKhsJAqqbC4hDv/vZgXP9nOTed15ScjemKmoBAJisJC\nqpzDhcXcMnMhb6/axV0jenLz+d2CLkmkxlNYSJVy4HAh46ens2BTDr+8rC/Xndkx6JJEBIWFVCE5\nBwu4YcoCVu7Yz5+uHsClA8reWFFEgqKwkCph577DjPnnfLbm5DHp+sFccJrGeRKpShQWErhNuw8y\n5p/z2ZtXyPTvDeHMLs2DLklEylBYSKBW7dzPmMkLKC4pYdb3h9K/XZOgSxKRchz16iYzu9jMripn\n/rVmNjy2ZUlNsHDLHq5+/GNq1zLm3DhMQSFShR3rUtgHgPfKmf828GBsypGa4oO1uxkzeT5N6tfh\n3zcNo3tLjRwrUpUdqxuqvrtnl53p7jvNLDmGNUk198byndw6axFdUpN58ntDaNEoKeiSRCSKY+1Z\nJJnZl8LEzOoA9WJXklRnryzdwc0zF9K7TSNmTzhTQSESJ44VFs8BT5Tei4g8/0dkmcgJeWnxdm57\nehGnt2/CjHFDaFJfQ4yLxItjhcW9QBaw2cwyzGwhsAnIjiwTOW4vfrKN/5u9iMEdmjL9e0NomFQn\n6JJE5AQc9ZiFuxcBd5vZA8CRwXnWufuhSqlMqo1nMzL58TOLGdq5Of8cG6J+os7YFok3xzp19goz\nuwL4OtCdcGCEzOy4T1sxsxFmttrM1pnZ3eUs72Bm75jZIjNbYmYjy1mea2Z3Hv+PJFXJnLSt3PnM\nYs7qmsKUsWcoKETi1LF+c79VzrxmQH8zG+fu/z3WC5tZAvAYMBzIBNLMbK67ryjV7F5gjrtPNLPe\nwCtAp1LLHwVejf5jSFU0a/4W7nl+Kef2SGXSdYNJqpMQdEkicpKO1Q313fLmm1lHYA4wNMprDyHc\nbbUhst5s4FKgdFg40CjyvDGwvdT7XAZsAA5GeR+pgmbM28R9Ly7nqz1TmThGQSES7074/pTuvhk4\nnqOTbYGtpaYzI/NKux8YY2aZhPcqboPPzrr6CeELAyXOTP1wI/e9uJyv9WrBP7RHIVItnHBYmNlp\nQP7xNC1nnpeZHg1Mc/d2wEhghpnVIhwSj7p7bpRaJphZupmlZ2d/6fpBCcDk9zfwwEsruKh3S/5+\n7WDq1lZQiFQHR+2GMrOX+PKXezOgNTDmOF47E2hfarodpbqZIsYBIwDcfZ6ZJQEphLu4rjKzR4Am\nQImZHXb3v5Ve2d0nAZMAQqFQ2Vqlkj3+3noeenUVI/u14s+jBlIn4YT/FhGRKupYB7h/X2bagRzC\ngTEGmBfltdOA7mbWGdgGjAKuKdNmC3AhMM3MegFJQLa7f+VIAzO7H8gtGxRStTz2zjp+9/pqvnV6\nGx79zunUVlCIVCvHOsD92SCCZjaA8Bf9d4CNwLPRXtjdi8zsVuB1IAGY4u7LzexBIN3d5wJ3EL5K\n/HbCYTTW3bWHEGf+/NZaHn1rDZcNaMPvv62gEKmO7GjfzWbWg/DewGjgU+BfwJ3uXiVvihwKhTw9\nPT3oMmoUd+ePb67hr/9dx5WD2vHIVf1JqFXeoSoRqarMLMPdQ9HaHasbahXwPvAtd18XedHbK6g+\niXMlJc6D/1nBtI82cXWoPQ9d0Y9aCgqRautY/QVXAjuBd8zsCTO7kPLPcJIapqi4hDufWcy0jzYx\n7pzOPHylgkKkujtqWLj78+5+NXAa8C5wO9DSzCaa2UWVVJ9UMYcLi7l55kKeW7iNHw3vwb3f6IWZ\ngkKkuot6JNLdD7r7THf/JuHTXz8BvjTOk1R/B/OLGDc9jTdWZHH/t3rzwwu7KyhEaogTGtXN3XOA\nxyP/pAbZm1fA2KlpLN22jz98+3SuHNwu6JJEpBJpCFCJatf+w1z3zwVs3H2Qv187iIv7tAq6JBGp\nZAoLOaatOXlcO3k+u3PzmfrdMzi7W0rQJYlIABQWclRrsw4w5p/zOVxYwszxQxnYoWnQJYlIQBQW\nUq7FW/cyduoCaifUYs6Nw+jZ6rjveSUi1ZDCQr5k3vpPGT89jWYNEnlq3FA6Nk8OuiQRCZjCQr7g\nrRVZ3DxrIR2b1WfGuKG0apwUdEkiUgUoLOQzLyzaxh3/XkyfNo2Y9t0hNEtODLokEakiFBYChG+D\n+vO5yxnauRlPXB+iYdLx3AxRRGoKhUUN5+78/d31/O711XytVwv+ds0g3QZVRL5EYVGDuTsPv7qK\nx/+3gcsGtOF33z5dd7cTkXIpLGqo4hLn3heW8vSCrVx3ZkceuKSPRo4VkaNSWNRABUUl3D7nE15e\nsoNbvtqVOy/qqQEBReSYFBY1zKGCYm56KoP31mRzz8jTmHBu16BLEpE4oLCoQfYfLmTctDTSN+/h\n4Sv6MWpIh6BLEpE4obCoIXbn5nPDlAWsyTrAX0cP5Jv92wRdkojEEYVFDbBt7yGumzyf7fsO8cT1\nIc7v2SLokkQkzigsqrkN2bmMmTyfA4eLmDFuKGd0ahZ0SSIShxQW1djy7fu4YcoC3OHpCWfSt23j\noEsSkTgV0yuwzGyEma02s3Vm9qX7dptZBzN7x8wWmdkSMxsZmT/czDLMbGnk8YJY1lkdpW/KYdSk\nj0lMqMWcm4YpKETklMRsz8LMEoDHgOFAJpBmZnPdfUWpZvcCc9x9opn1Bl4BOgG7gW+5+3Yz6wu8\nDrSNVa3VzQdrdzP+yTTaNK7HjPFDadukXtAliUici+WexRBgnbtvcPcCYDZwaZk2DjSKPG8MbAdw\n90Xuvj0yfzmQZGZ1Y1hrtfHemmzGTU+jU/Nk/nXjMAWFiFSIWB6zaAtsLTWdCQwt0+Z+4A0zuw1I\nBr5WzutcCSxy9/xYFFmdvLNqFzfOyKBbiwY8NX6ohhgXkQoTyz2L8saP8DLTo4Fp7t4OGAnMMLPP\najKzPsBvgRvLfQOzCWaWbmbp2dnZFVR2fHprRRYTZqTTo1UDZn1fQSEiFSuWYZEJtC813Y5IN1Mp\n44A5AO4+D0gCUgDMrB3wPHC9u68v7w3cfZK7h9w9lJqaWsHlx4/Xlu3kBzMz6N26ETPHnUmT+goK\nEalYsQyLNKC7mXU2s0RgFDC3TJstwIUAZtaLcFhkm1kT4GXgp+7+YQxrjHuvLN3BrbMW0rdtY2aM\nH0rj+rppkYhUvJiFhbsXAbcSPpNpJeGznpab2YNmdkmk2R3A981sMfA0MNbdPbJeN+A+M/sk8k+X\nHZfx0uLt3Pb0Iga0b8KT3xtCI93dTkRixMLfzfEvFAp5enp60GVUmhcWbeNHcz4h1KkZU8eeQXJd\nXV8pIifOzDLcPRStnW6LFoeeycjk9jmfMLRzc6Z9V0EhIrGnb5k4MydtKz95bglnd03hietD1EvU\n/bJFJPa0ZxFHZs3fwl3PLuEr3VOZfIOCQkQqj8IiTsyYt4l7nl/KV3umMum6wSTVUVCISOVRN1Qc\nmPrhRh54aQVf69WSx64dSN3aCgoRqVwKiyruqY8388BLK7i4T0v+OnoQibW1MygilU9hUYW9vzab\nX8xdzgWnteBv1wyiToKCQkSCoW+fKmpDdi63zFxIt9QG/GX0QAWFiARK30BV0L68QsZPT6d2Qi0m\n3xCiga6jEJGAKSyqmMLiEm6ZtZCte/J4/LrBtG9WP+iSRER0zKKq+dV/VvDBut08clV/zujULOhy\nREQA7VlUKU99vJnp8zbz/a905juh9tFXEBGpJAqLKuKjdbs/O/Pp7q/3CrocEZEvUFhUARt3H+QH\nMxfSNTWZP48aQEKt8m4yKCISHIVFwPYdKmTc9DRqGUy+/gwa6p4UIlIF6QB3gIqKS7h11kK25uTx\n1LihdGiuM59EpGpSWAToVy+v5P21u/ntlf0Y2qV50OWIiByVuqECMmv+FqZ9tIlx53Tm6jM6BF2O\niMgxKSwC8NH63fz8xWWc1yOVe0bqzCcRqfoUFpVs0+6D3DxzIZ1SkvnrNQN15pOIxAWFRSXaf7iQ\n8U+mA/DPG0I00plPIhInFBaVpKi4hNtmLWLT7oNMvHYwHZsnB12SiMhx09lQleRXL6/kvTXZPHRF\nP4Z11ZlPIhJfYrpnYWYjzGy1ma0zs7vLWd7BzN4xs0VmtsTMRpZa9tPIeqvN7OJY1hlrMz7e/NmZ\nT6OH6MwnEYk/MduzMLME4DFgOJAJpJnZXHdfUarZvcAcd59oZr2BV4BOkeejgD5AG+AtM+vh7sWx\nqjdW3l+bzf2RMZ905pOIxKtY7lkMAda5+wZ3LwBmA5eWaeNAo8jzxsD2yPNLgdnunu/uG4F1kdeL\nK+t25XJz5G53GvNJROJZLMOiLbC11HRmZF5p9wNjzCyT8F7FbSewbpW252AB46ankRi5253GfBKR\neBbLsCjvz2gvMz0amObu7YCRwAwzq3Wc62JmE8ws3czSs7OzT7ngilJQVMJNT2WwY+9hJl2vu92J\nSPyLZVhkAqXv4NOOz7uZjhgHzAFw93lAEpBynOvi7pPcPeTuodTU1Aos/eS5O/e9sIz5G3N45Kr+\nDO6ou92JSPyLZVikAd3NrLOZJRI+YD23TJstwIUAZtaLcFhkR9qNMrO6ZtYZ6A4siGGtFWby+xv5\nV/pWbv1qNy4bGFc9ZyIiRxWzs6HcvcjMbgVeBxKAKe6+3MweBNLdfS5wB/CEmd1OuJtprLs7sNzM\n5gArgCLglng4E+qtFVn85tWVjOzXih8N7xF0OSIiFcbC383xLxQKeXp6emDvv3LHfq6a+BFdUhsw\n58Zh1EtMCKwWEZHjZWYZ7h6K1k7DfVSA7AP5jJ+eToOk2jxxfUhBISLVjob7OEWHC4uZMCOdnIMF\n/PumYbRqnBR0SSIiFU5hcQrcnbueWcKiLXv5x5hB9G3bOOiSRERiQt1Qp+Avb69j7uLt/Pjinozo\n2zrockREYkZhcZL+s2Q7j761hisGteXm87sGXY6ISEwpLE5C5p48fvzvJYQ6NuWhK/phpjGfRKR6\nU1icIHfnFy8uxwz+MnogdWvrzCcRqf4UFifo9eVZvL1qFz8a3oM2TeoFXY6ISKVQWJyA3Pwi7p+7\nnF6tGzH2rE5BlyMiUmkUFifgj2+sIevAYX5zeV9qJ2jTiUjNoW+847Rs2z6mfbSRa4Z0YGCHpkGX\nIyJSqRQWx6G4xPnZ80tplpzIXSNOC7ocEZFKp7A4DrPmb2Zx5j7u+2ZvGtfTHe9EpOZRWESxa/9h\nHnltNed0S+GS09sEXY6ISCD8SywbAAAIlElEQVQUFlH88uWV5BeX8MvL+uriOxGpsRQWx/C/Ndm8\ntHg7t5zfjc4pyUGXIyISGIXFURwuLOa+F5fRJSWZm87vEnQ5IiKB0hDlR/HYO+vY/Gkes8YP1ZAe\nIlLjac+iHOt25fKP99Zz+cC2nNUtJehyREQCp7Aowz18TUW9Ogn87Bu9gi5HRKRKUFiU8dzCbczf\nmMPdX+9FSoO6QZcjIlIlKCxK2XOwgF+/spJBHZow6oz2QZcjIlJlKCxK+e1rq9h3qJBfX96PWrV0\nTYWIyBEKi4i0TTnMTtvK+HM606t1o6DLERGpUmIaFmY2wsxWm9k6M7u7nOWPmtknkX9rzGxvqWWP\nmNlyM1tpZn+xGF4+XVhcws+eX0rbJvX4v691j9XbiIjErZhdZ2FmCcBjwHAgE0gzs7nuvuJIG3e/\nvVT724CBkednAWcD/SOLPwDOA96NRa2T39/ImqxcJl8fon6iLj0RESkrlnsWQ4B17r7B3QuA2cCl\nx2g/Gng68tyBJCARqAvUAbJiUeTWnDz+/PYaLurdkq/1bhmLtxARiXuxDIu2wNZS05mReV9iZh2B\nzsB/Adx9HvAOsCPy73V3X1nOehPMLN3M0rOzs0+qyKIS54xOzbj/kj4ntb6ISE0Qy7Ao7xiDH6Xt\nKOAZdy8GMLNuQC+gHeGAucDMzv3Si7lPcveQu4dSU1NPqsjOKcnMGDeUNk3qndT6IiI1QSzDIhMo\nfbFCO2D7UdqO4vMuKIDLgY/dPdfdc4FXgTNjUqWIiEQVy7BIA7qbWWczSyQcCHPLNjKznkBTYF6p\n2VuA88ystpnVIXxw+0vdUCIiUjliFhbuXgTcCrxO+It+jrsvN7MHzeySUk1HA7PdvXQX1TPAemAp\nsBhY7O4vxapWERE5Nvvid3T8CoVCnp6eHnQZIiJxxcwy3D0UrZ2u4BYRkagUFiIiEpXCQkREolJY\niIhIVNXmALeZZQObg64jRlKA3UEXUQVoO3xO2yJM2yHsVLZDR3ePelVztQmL6szM0o/nbIXqTtvh\nc9oWYdoOYZWxHdQNJSIiUSksREQkKoVFfJgUdAFVhLbD57QtwrQdwmK+HXTMQkREotKehYiIRKWw\nqOLMbJOZLY3cp7zGDH5lZlPMbJeZLSs1r5mZvWlmayOPTYOssTIcZTvcb2bbSt2/fmSQNVYGM2tv\nZu+Y2UozW25m/xeZX6M+E8fYDjH/TKgbqoozs01AyN1r1LnkkZtd5QJPunvfyLxHgBx3f9jM7gaa\nuvtPgqwz1o6yHe4Hct3990HWVpnMrDXQ2t0XmllDIAO4DBhLDfpMHGM7fIcYfya0ZyFVkrv/D8gp\nM/tSYHrk+XTCvyTV2lG2Q43j7jvcfWHk+QHCtz1oSw37TBxjO8ScwqLqc+ANM8swswlBFxOwlu6+\nA8K/NECLgOsJ0q1mtiTSTVWtu17KMrNOwEBgPjX4M1FmO0CMPxMKi6rvbHcfBHwduKW8e5FLjTMR\n6AoMAHYAfwi2nMpjZg2AZ4H/5+77g64nKOVsh5h/JhQWVZy7b4887gKeB4YEW1GgsiJ9tkf6bncF\nXE8g3D3L3YvdvQR4ghrymYjcYvlZYKa7PxeZXeM+E+Vth8r4TCgsqjAzS44cxMLMkoGLgGXHXqta\nmwvcEHl+A/BigLUE5siXY8Tl1IDPhJkZ8E9gpbv/sdSiGvWZONp2qIzPhM6GqsLMrAvhvQmA2sAs\nd/91gCVVGjN7Gjif8GiaWcAvgBeAOUAHYAvwbXev1gd/j7Idzifc3eDAJuDGI/321ZWZnQO8DywF\nSiKz7yHcX19jPhPH2A6jifFnQmEhIiJRqRtKRESiUliIiEhUCgsREYlKYSEiIlEpLEREJCqFhcQ9\nM3Mzm1FquraZZZvZf07y9S6JDEoXCDN718xWR4ZuWGVmfzOzJqfwemPNrE2p6U1mllIx1UpNobCQ\n6uAg0NfM6kWmhwPbTvbF3H2uuz9cIZWdvGvdvT/QH8jn1C42Gwu0idZI5FgUFlJdvAp8I/J8NPD0\nkQVmNsTMPjKzRZHHnpH5PzKzKZHn/cxsmZnVj/wl/rfI/GlmNjFyD4ENZnZeZKC2lWY2rdR75JZ6\nftWRZce7/tG4ewFwF9DBzE6PvOYYM1sQuW/B42aWcKQGM/uDmS00s7fNLNXMrgJCwMxI+yOBeluk\n3VIzO+0ktrfUMAoLqS5mA6PMLInwX+PzSy1bBZzr7gOBnwO/icz/E9DNzC4HphK+6jWvnNduClwA\n3A68BDwK9AH6mdmA46jtlNZ392JgMXCamfUCriY8wOQAoBi4NtI0GVgYGXjyPeAX7v4MkE54T2WA\nux+KtN0daTcRuPM4fgap4WoHXYBIRXD3JZEhm0cDr5RZ3BiYbmbdCQ+HUCeyTomZjQWWAI+7+4dH\nefmX3N3NbCmQ5e5LAcxsOdAJ+CRKeae6PoBFHi8EBgNp4WGCqMfng+eVAP+KPH8KeI6jO7IsA7ji\nON5fajiFhVQnc4HfEx47qXmp+b8E3nH3yyOB8m6pZd0J34nuWH36+ZHHklLPj0wf+R0qPW5O0kms\nf1SRbqZ+hG900wKY7u4/jbZemZrKOlJH8fHUIKJuKKlOpgAPHvnLvZTGfH7Ae+yRmWbWGPgzcC7Q\nPNK/f7KyzKyXmdUiPOpnhYgMR/0QsNXdlwBvA1eZWYvI8mZm1jHSvBZw5Ge4Bvgg8vwA0LCiapKa\nSX9RSLXh7pmEv/zLeoRwN9SPgP+Wmv8o8Hd3X2Nm44B3zOx/J/n2dwP/AbYSHh66wUm+zhEzzSwf\nqAu8Rfj2obj7CjO7l/DdE2sBhcAtwGbCZ4X1MbMMYB/hYxsA04B/mNkhYNgp1iU1lEadFakmzCzX\n3U81pETKpW4oERGJSnsWIiISlfYsREQkKoWFiIhEpbAQEZGoFBYiIhKVwkJERKJSWIiISFT/H20W\nWd/iqsihAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Using grid search to find the optimal maximum tree depth\n",
    "auc_by_d=[]\n",
    "for d in range(2,26):\n",
    "    rf = RandomForestClassifier(n_estimators=200, criterion=\"entropy\", \n",
    "                                max_depth=d,\n",
    "                                random_state=0, n_jobs=20, max_features=\"auto\",\n",
    "                                class_weight = calc_cw(train_df.grade))\n",
    "    auc = cross_validation_RF(rf, five_folds)\n",
    "    auc_by_d.append(auc)\n",
    "    print(\"Max_depth =\", d)\n",
    "    print(\"Mean CV AUC:\", auc)\n",
    "    print(\"\")\n",
    "plt.plot(range(2,26),auc_by_d)\n",
    "plt.xlabel(\"Maximum Depth\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trees = 100\n",
      "Mean CV AUC: 0.9014\n",
      "\n",
      "Number of Trees = 120\n",
      "Mean CV AUC: 0.9019\n",
      "\n",
      "Number of Trees = 140\n",
      "Mean CV AUC: 0.9025\n",
      "\n",
      "Number of Trees = 160\n",
      "Mean CV AUC: 0.9028\n",
      "\n",
      "Number of Trees = 180\n",
      "Mean CV AUC: 0.9032\n",
      "\n",
      "Number of Trees = 200\n",
      "Mean CV AUC: 0.9032\n",
      "\n",
      "Number of Trees = 220\n",
      "Mean CV AUC: 0.9034\n",
      "\n",
      "Number of Trees = 240\n",
      "Mean CV AUC: 0.9035\n",
      "\n",
      "Number of Trees = 260\n",
      "Mean CV AUC: 0.9036\n",
      "\n",
      "Number of Trees = 280\n",
      "Mean CV AUC: 0.9036\n",
      "\n",
      "Number of Trees = 300\n",
      "Mean CV AUC: 0.9037\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Using grid search to find the optimal number of estimators (trees)\n",
    "auc_by_n = []\n",
    "for n in range(100,320,20):\n",
    "    rf = RandomForestClassifier(n_estimators=n, criterion=\"entropy\", \n",
    "                                max_depth=24,\n",
    "                                random_state=0, n_jobs=-1, max_features=\"auto\",\n",
    "                                class_weight = calc_cw(train_df.grade))\n",
    "    auc = cross_validation_RF(rf, five_folds)\n",
    "    auc_by_n.append(auc)\n",
    "    print(\"Number of Trees =\", n)\n",
    "    print(\"Mean CV AUC:\", auc)\n",
    "    print(\"\")\n",
    "plt.plot(range(100,320,20), auc_by_n)\n",
    "plt.xlabel(\"Number of Trees\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_features = 2\n",
      "Mean CV AUC: 0.8942\n",
      "\n",
      "Max_features = 3\n",
      "Mean CV AUC: 0.8969\n",
      "\n",
      "Max_features = 4\n",
      "Mean CV AUC: 0.9006\n",
      "\n",
      "Max_features = 5\n",
      "Mean CV AUC: 0.9007\n",
      "\n",
      "Max_features = 6\n",
      "Mean CV AUC: 0.9011\n",
      "\n",
      "Max_features = 7\n",
      "Mean CV AUC: 0.9015\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-95ec9e7d3aaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m                                 \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                 class_weight = calc_cw(train_df.grade))\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation_RF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfive_folds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mauc_by_nf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Max_features =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-fb80a74de69f>\u001b[0m in \u001b[0;36mcross_validation_RF\u001b[1;34m(rf_model, folds)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mX_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0my_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0my_2_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mauc_by_fold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_2_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    333\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 335\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 996\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    997\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    900\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 602\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Using grid search to find the optimal maximum number of features (trees)\n",
    "auc_by_nf = []\n",
    "max_nf = int(np.floor(2*np.sqrt(len(predictors))))\n",
    "for nf in range(2,max_nf+1):\n",
    "    rf = RandomForestClassifier(n_estimators=180, criterion=\"entropy\", \n",
    "                                max_depth=24,\n",
    "                                random_state=0, n_jobs=-1, max_features=nf,\n",
    "                                class_weight = calc_cw(train_df.grade))\n",
    "    auc = cross_validation_RF(rf, five_folds)\n",
    "    auc_by_nf.append(auc)\n",
    "    print(\"Max_features =\", nf)\n",
    "    print(\"Mean CV AUC:\", auc)\n",
    "    print(\"\")\n",
    "plt.plot(range(2,max_nf+1), auc_by_nf)\n",
    "plt.xlabel(\"Maximum Number of Features\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight={0: 1.6805598, 1: 1.0},\n",
       "            criterion='entropy', max_depth=24, max_features=4,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=180, n_jobs=-1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=180, criterion=\"entropy\",\n",
    "                            max_depth=24,\n",
    "                            random_state=0, n_jobs=-1, max_features=4,\n",
    "                            class_weight = calc_cw(train_df.grade))\n",
    "rf.fit(train_df.loc[:,predictors], train_df.grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Overall AUC = 0.8426\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest:\")\n",
    "print(\"Overall AUC = {}\".format(round(roc_auc_score(test_df.grade, rf.predict_proba(test_df.loc[:,predictors])[:,1]),4)))\n",
    "y_test_pred_rf = rf.predict_proba(test_df.loc[:,predictors])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Non-first AUC = 0.8461\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest:\")\n",
    "print(\"Non-first AUC = {}\".format(round(roc_auc_score(test_df[test_df.first_ind == 0].grade, rf.predict_proba(test_df[test_df.first_ind == 0].loc[:,predictors])[:,1]),4)))\n",
    "y_test_pred_rf_nonfirst = rf.predict_proba(test_df[test_df.first_ind == 0].loc[:,predictors])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "First AUC = 0.8123\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest:\")\n",
    "print(\"First AUC = {}\".format(round(roc_auc_score(test_df[test_df.first_ind == 1].grade, rf.predict_proba(test_df[test_df.first_ind == 1].loc[:,predictors])[:,1]),4)))\n",
    "y_test_pred_rf_first = rf.predict_proba(test_df[test_df.first_ind == 1].loc[:,predictors])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Online AUC = 0.8504\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest:\")\n",
    "print(\"Online AUC = {}\".format(round(roc_auc_score(test_df[test_df.online_ind == 1].grade, rf.predict_proba(test_df[test_df.online_ind == 1].loc[:,predictors])[:,1]),4)))\n",
    "y_test_pred_rf_first = rf.predict_proba(test_df[test_df.online_ind == 1].loc[:,predictors])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "In-person AUC = 0.8384\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest:\")\n",
    "print(\"In-person AUC = {}\".format(round(roc_auc_score(test_df[test_df.online_ind == 0].grade, rf.predict_proba(test_df[test_df.online_ind == 0].loc[:,predictors])[:,1]),4)))\n",
    "y_test_pred_rf_first = rf.predict_proba(test_df[test_df.online_ind == 0].loc[:,predictors])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"ABC vs. DF\")\n",
    "# print(\"AUC = {}\".format(round(roc_auc_score(np.array(test_df.grade)[np.where(np.array(original_test_grade) != \"W\")[0]], \n",
    "#                                             rf.predict_proba(test_df.loc[:,predictors])[np.where(np.array(original_test_grade) != \"W\")[0],1]),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def find_optimal_threshold(p,r,t):\n",
    "#     to_drop = np.union1d(np.where(pd.isnull(p[:-1]) == True)[0], np.where(pd.isnull(r[:-1]) == True)[0])\n",
    "#     to_drop = np.union1d(to_drop, np.where(pd.isnull(t) == True)[0])\n",
    "#     to_keep = np.setdiff1d(np.array(list(range(len(p)-1))), to_drop)\n",
    "#     p,r,t = p[to_keep],r[to_keep],t[to_keep]\n",
    "#     to_keep_2 = np.where(t < 0.8)[0]\n",
    "#     p,r,t = p[to_keep_2],r[to_keep_2],t[to_keep_2]\n",
    "#     f1 = 2*p*r/(p+r)\n",
    "#     best_t = t[np.argmax(f1)]\n",
    "#     best_t\n",
    "#     return best_t\n",
    "\n",
    "# def cross_validation(train, model):\n",
    "#     threshold_list = []\n",
    "#     auc_list = []\n",
    "#     k_fold =  StratifiedKFold(n_splits = 10, random_state = 54321, shuffle=True)\n",
    "#     for train_indices, test_indices in k_fold.split(train, train.grade):\n",
    "#         train_part = train.iloc[train_indices,:]\n",
    "#         test_part = train.iloc[test_indices,:]\n",
    "#         X_1 = train_part.loc[:,predictors]\n",
    "#         y_1 = train_part.grade\n",
    "#         X_2 = test_part.loc[:,predictors]\n",
    "#         y_2 = test_part.grade\n",
    "#         model.fit(X_1,y_1)\n",
    "#         p,r,t = precision_recall_curve(1-np.array(y_2), model.predict_proba(X_2)[:,0])\n",
    "#         threshold_list.append(1-find_optimal_threshold(p,r,t))\n",
    "#         auc = roc_auc_score(y_2, model.predict_proba(X_2)[:,1])\n",
    "#         auc_list.append(auc)\n",
    "#     print(threshold_list)\n",
    "#     print(np.mean(auc_list), np.std(auc_list, ddof=1))\n",
    "#     return gmean(threshold_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best_threshold = cross_validation(train_df,rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_threshold = np.sort(y_test_pred_rf)[int(len(y_test_pred_rf) * (1-np.mean(train_df.grade)))-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_confusion_matrix_old(y_test_pred, threshold, fname):\n",
    "    cm_arr = confusion_matrix(y_test, np.where(y_test_pred > threshold, 1, 0))\n",
    "    cm_df = pd.DataFrame(cm_arr, columns=['Pred_DFW','Pred_ABC'], index=['Actual_DFW', 'Actual_ABC'])\n",
    "    cm_df.loc[:,''] = cm_df.sum(axis=1)\n",
    "    cm_df.loc['',:] = cm_df.sum(axis=0)\n",
    "    print(cm_df)\n",
    "    print(\"\")\n",
    "    p1 = cm_df.iloc[1,1]/cm_df.iloc[2,1]\n",
    "    r1 = cm_df.iloc[1,1]/cm_df.iloc[1,2]\n",
    "    p0 = cm_df.iloc[0,0]/cm_df.iloc[2,0]\n",
    "    r0 = cm_df.iloc[0,0]/cm_df.iloc[0,2]    \n",
    "    print(\"F1 score for A/B/C = {}\".format(round(2*p1*r1/(p1+r1),4)))\n",
    "    print(\"F1 score for D/F/W = {}\".format(round(2*p0*r0/(p0+r0),4))) \n",
    "    cm_df.to_csv(results_dir + fname + \".csv\")\n",
    "    y_test_pred_bin = np.where(y_test_pred > best_threshold, 1, 0)\n",
    "    cm_dict = {}\n",
    "    cm_dict['Pred_DFW'] = Counter(original_test_grade[np.where(y_test_pred_bin==0)[0]])\n",
    "    cm_dict['Pred_ABC'] = Counter(original_test_grade[np.where(y_test_pred_bin==1)[0]])\n",
    "    new_cm = pd.DataFrame.from_dict(cm_dict, orient='index').T.loc[['W','F','D','C','B','A'],['Pred_DFW','Pred_ABC']]\n",
    "    new_cm.index = [\"Actual_\"+e for e in new_cm.index]\n",
    "    new_cm.loc[:,''] = new_cm.sum(axis=1)\n",
    "    new_cm.loc['',:] = new_cm.sum(axis=0)\n",
    "    new_cm.to_csv(results_dir + fname + \"_6x2.csv\")\n",
    "    return round(p1,4),round(r1,4),round(p0,4),round(r0,4),round(2*p1*r1/(p1+r1),4),round(2*p0*r0/(p0+r0),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.6188:\n",
      "\n",
      "            Pred_DFW  Pred_ABC        \n",
      "Actual_DFW    1548.0     996.0  2544.0\n",
      "Actual_ABC     774.0    5563.0  6337.0\n",
      "              2322.0    6559.0  8881.0\n",
      "\n",
      "F1 score for A/B/C = 0.8627\n",
      "F1 score for D/F/W = 0.6363\n"
     ]
    }
   ],
   "source": [
    "y_test = np.array(test_df.grade)\n",
    "print(\"F1 threshold = {}:\\n\".format(str(round(best_threshold,4))))\n",
    "pr_rf = create_confusion_matrix_old(y_test_pred_rf, best_threshold, \"RF_BIO101_all_cm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8481, 0.8779, 0.6667, 0.6085, 0.8627, 0.6363)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_confusion_matrix(y_test_pred, threshold, fname, ind = 0):\n",
    "    cm_arr = confusion_matrix(y_test[np.array(test_df.first_ind == ind)], np.where(y_test_pred > threshold, 1, 0))\n",
    "    cm_df = pd.DataFrame(cm_arr, columns=['Pred_DFW','Pred_ABC'], index=['Actual_DFW', 'Actual_ABC'])\n",
    "    cm_df.loc[:,''] = cm_df.sum(axis=1)\n",
    "    cm_df.loc['',:] = cm_df.sum(axis=0)\n",
    "    print(cm_df)\n",
    "    print(\"\")\n",
    "    p1 = cm_df.iloc[1,1]/cm_df.iloc[2,1]\n",
    "    r1 = cm_df.iloc[1,1]/cm_df.iloc[1,2]\n",
    "    p0 = cm_df.iloc[0,0]/cm_df.iloc[2,0]\n",
    "    r0 = cm_df.iloc[0,0]/cm_df.iloc[0,2]    \n",
    "    print(\"F1 score for A/B/C = {}\".format(round(2*p1*r1/(p1+r1),4)))\n",
    "    print(\"F1 score for D/F/W = {}\".format(round(2*p0*r0/(p0+r0),4))) \n",
    "    cm_df.to_csv(results_dir + fname + \".csv\")\n",
    "    y_test_pred_bin = np.where(y_test_pred > best_threshold, 1, 0)\n",
    "    cm_dict = {}\n",
    "    cm_dict['Pred_DFW'] = Counter(original_test_grade[np.array(test_df.first_ind == ind)][np.where(y_test_pred_bin==0)[0]])\n",
    "    cm_dict['Pred_ABC'] = Counter(original_test_grade[np.array(test_df.first_ind == ind)][np.where(y_test_pred_bin==1)[0]])\n",
    "    new_cm = pd.DataFrame.from_dict(cm_dict, orient='index').T.loc[['W','F','D','C','B','A'],['Pred_DFW','Pred_ABC']]\n",
    "    new_cm.index = [\"Actual_\"+e for e in new_cm.index]\n",
    "    new_cm.loc[:,''] = new_cm.sum(axis=1)\n",
    "    new_cm.loc['',:] = new_cm.sum(axis=0)\n",
    "    new_cm.to_csv(results_dir + fname + \"_6x2.csv\")\n",
    "    return round(p1,4),round(r1,4),round(p0,4),round(r0,4),round(2*p1*r1/(p1+r1),4),round(2*p0*r0/(p0+r0),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.6188:\n",
      "\n",
      "            Pred_DFW  Pred_ABC        \n",
      "Actual_DFW    1405.0     933.0  2338.0\n",
      "Actual_ABC     670.0    5269.0  5939.0\n",
      "              2075.0    6202.0  8277.0\n",
      "\n",
      "F1 score for A/B/C = 0.868\n",
      "F1 score for D/F/W = 0.6368\n"
     ]
    }
   ],
   "source": [
    "y_test = np.array(test_df.grade)\n",
    "print(\"F1 threshold = {}:\\n\".format(str(round(best_threshold,4))))\n",
    "pr_rf = create_confusion_matrix(y_test_pred_rf_nonfirst, best_threshold, \"RF_BIO101_full_cm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8496, 0.8872, 0.6771, 0.6009, 0.868, 0.6368)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.6188:\n",
      "\n",
      "            Pred_DFW  Pred_ABC       \n",
      "Actual_DFW     143.0      63.0  206.0\n",
      "Actual_ABC     104.0     294.0  398.0\n",
      "               247.0     357.0  604.0\n",
      "\n",
      "F1 score for A/B/C = 0.7788\n",
      "F1 score for D/F/W = 0.6313\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 threshold = {}:\\n\".format(str(round(best_threshold,4))))\n",
    "pr_rf = create_confusion_matrix(y_test_pred_rf_first, best_threshold, \"RF_BIO101_first_cm\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8235, 0.7387, 0.5789, 0.6942, 0.7788, 0.6313)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi_df = pd.DataFrame({\"feature_importance\": rf.feature_importances_, \"predictor\": predictors})\\\n",
    ".loc[:,['predictor', 'feature_importance']].sort_values(['feature_importance'], ascending=False)\n",
    "fi_df.loc[:,'feature_ranking'] = np.arange(1, fi_df.shape[0] + 1) / fi_df.shape[0]\n",
    "cw_df = pd.read_csv(results_dir + \"predictor_crosswalk.csv\").iloc[:,[0,3,4]]\n",
    "fi_df = fi_df.merge(cw_df, on=['predictor'], how='left')\n",
    "fi_df.loc[:,'predictor_category'] = fi_df.predictor_category.apply(lambda x: \"Admin\" if pd.isnull(x) else x)\n",
    "fi_df.loc[:,'predictor_subcategory'] = fi_df.predictor_subcategory.apply(lambda x: \"Non-course-specific academic records\" if pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>predictor_type</th>\n",
       "      <th>predictor_subcategory</th>\n",
       "      <th>ranking</th>\n",
       "      <th>feature_importance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pct_withdrawn</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tot_click_cnt_qrt1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cum_gpa</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>3</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crnt_enrl_intensity</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tot_time_qrt1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>5</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>term_gpa_1</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>6</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>assign_sub_cnt_qtr1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>7</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HUM_SCI_grade</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Course-subject-specific</td>\n",
       "      <td>8</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>term_gpa_2</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>9</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>overall_prop_comp</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>10</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>on_time_assign_share_qtr1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>11</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>irreg_session_len_qrt1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>12</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>avg_g_concurrent</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Course-specific</td>\n",
       "      <td>13</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tot_click_cnt_qrt1c</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term concurrent</td>\n",
       "      <td>14</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>past_avg_grade</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Instructor-related</td>\n",
       "      <td>15</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>avg_session_len_qrt1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>16</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tot_time_qrt1c</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term concurrent</td>\n",
       "      <td>17</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>irreg_session_len_qrt1c</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term concurrent</td>\n",
       "      <td>18</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gpa_trend</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>19</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>avg_session_len_qrt1c</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term concurrent</td>\n",
       "      <td>20</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SOC_SCI_grade</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Course-subject-specific</td>\n",
       "      <td>21</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>avg_g</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Course-specific</td>\n",
       "      <td>22</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>prop_comp_sd</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>23</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>age</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>24</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>assign_sub_cnt_qtr1c</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term concurrent</td>\n",
       "      <td>25</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cum_cred_earn</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>26</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>enrl_intensity_trend</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>27</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>enrl_intensity</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>28</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pct_dev</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>29</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>disc_post_cnt_qtr1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>30</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    predictor predictor_type  \\\n",
       "0               pct_withdrawn          Admin   \n",
       "1          tot_click_cnt_qrt1            LMS   \n",
       "2                     cum_gpa          Admin   \n",
       "3         crnt_enrl_intensity          Admin   \n",
       "4               tot_time_qrt1            LMS   \n",
       "5                  term_gpa_1          Admin   \n",
       "6         assign_sub_cnt_qtr1            LMS   \n",
       "7               HUM_SCI_grade          Admin   \n",
       "8                  term_gpa_2          Admin   \n",
       "9           overall_prop_comp          Admin   \n",
       "10  on_time_assign_share_qtr1            LMS   \n",
       "11     irreg_session_len_qrt1            LMS   \n",
       "12           avg_g_concurrent          Admin   \n",
       "13        tot_click_cnt_qrt1c            LMS   \n",
       "14             past_avg_grade          Admin   \n",
       "15       avg_session_len_qrt1            LMS   \n",
       "16             tot_time_qrt1c            LMS   \n",
       "17    irreg_session_len_qrt1c            LMS   \n",
       "18                  gpa_trend          Admin   \n",
       "19      avg_session_len_qrt1c            LMS   \n",
       "20              SOC_SCI_grade          Admin   \n",
       "21                      avg_g          Admin   \n",
       "22               prop_comp_sd          Admin   \n",
       "23                        age          Admin   \n",
       "24       assign_sub_cnt_qtr1c            LMS   \n",
       "25              cum_cred_earn          Admin   \n",
       "26       enrl_intensity_trend          Admin   \n",
       "27             enrl_intensity          Admin   \n",
       "28                    pct_dev          Admin   \n",
       "29         disc_post_cnt_qtr1            LMS   \n",
       "\n",
       "                   predictor_subcategory  ranking  feature_importance_score  \n",
       "0   Non-course-specific academic records        1                     0.033  \n",
       "1                             Early-term        2                     0.032  \n",
       "2   Non-course-specific academic records        3                     0.031  \n",
       "3   Non-course-specific academic records        4                     0.031  \n",
       "4                             Early-term        5                     0.028  \n",
       "5   Non-course-specific academic records        6                     0.028  \n",
       "6                             Early-term        7                     0.022  \n",
       "7                Course-subject-specific        8                     0.021  \n",
       "8   Non-course-specific academic records        9                     0.019  \n",
       "9   Non-course-specific academic records       10                     0.018  \n",
       "10                            Early-term       11                     0.018  \n",
       "11                            Early-term       12                     0.018  \n",
       "12                       Course-specific       13                     0.018  \n",
       "13                 Early-term concurrent       14                     0.017  \n",
       "14                    Instructor-related       15                     0.017  \n",
       "15                            Early-term       16                     0.016  \n",
       "16                 Early-term concurrent       17                     0.016  \n",
       "17                 Early-term concurrent       18                     0.015  \n",
       "18  Non-course-specific academic records       19                     0.015  \n",
       "19                 Early-term concurrent       20                     0.015  \n",
       "20               Course-subject-specific       21                     0.015  \n",
       "21                       Course-specific       22                     0.015  \n",
       "22  Non-course-specific academic records       23                     0.014  \n",
       "23                           Demographic       24                     0.014  \n",
       "24                 Early-term concurrent       25                     0.014  \n",
       "25  Non-course-specific academic records       26                     0.014  \n",
       "26  Non-course-specific academic records       27                     0.012  \n",
       "27  Non-course-specific academic records       28                     0.012  \n",
       "28  Non-course-specific academic records       29                     0.011  \n",
       "29                            Early-term       30                     0.011  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_df.loc[:,'predictor_subcategory'] = fi_df.predictor_subcategory.apply(lambda x: x.split(\" & \")[0])\n",
    "fi_df_top30 = fi_df.iloc[:30,:].drop(['feature_ranking'], axis=1)\n",
    "fi_df_top30.loc[:,'feature_ranking'] = np.arange(1,31)\n",
    "fi_df_top30 = fi_df_top30.round(3)\n",
    "fi_df_top30 = fi_df_top30.rename(columns = {'feature_importance': 'feature_importance_score',\n",
    "                                            'feature_ranking': 'ranking',\n",
    "                                            'predictor_category': 'predictor_type'})\n",
    "fi_df_top30 = fi_df_top30.loc[:,['predictor', 'predictor_type', 'predictor_subcategory', 'ranking', 'feature_importance_score']]\n",
    "fi_df_top30.to_csv(results_dir + \"top30_predictors_BIO101.csv\", index=False)\n",
    "fi_df_top30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor_subcategory</th>\n",
       "      <th>number_of_predictors</th>\n",
       "      <th>highest_normalized_ranking</th>\n",
       "      <th>average_normalized_ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Admin -- Course-specific</td>\n",
       "      <td>31</td>\n",
       "      <td>0.088435</td>\n",
       "      <td>0.732499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Admin -- Course-subject-specific</td>\n",
       "      <td>20</td>\n",
       "      <td>0.054422</td>\n",
       "      <td>0.520408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Admin -- Demographic</td>\n",
       "      <td>1</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.163265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Admin -- Instructor-related</td>\n",
       "      <td>4</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.482993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Admin -- Non-course-specific academic records</td>\n",
       "      <td>41</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.509706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LMS -- Early-term</td>\n",
       "      <td>12</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>0.199546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LMS -- Early-term concurrent</td>\n",
       "      <td>9</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.310658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LMS -- Prior early-term</td>\n",
       "      <td>13</td>\n",
       "      <td>0.278912</td>\n",
       "      <td>0.466771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LMS -- Prior full-term</td>\n",
       "      <td>16</td>\n",
       "      <td>0.258503</td>\n",
       "      <td>0.414541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All Admin</td>\n",
       "      <td>97</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.578442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All LMS</td>\n",
       "      <td>50</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>0.357823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           predictor_subcategory  number_of_predictors  \\\n",
       "0                       Admin -- Course-specific                    31   \n",
       "1               Admin -- Course-subject-specific                    20   \n",
       "2                           Admin -- Demographic                     1   \n",
       "3                    Admin -- Instructor-related                     4   \n",
       "4  Admin -- Non-course-specific academic records                    41   \n",
       "5                              LMS -- Early-term                    12   \n",
       "6                   LMS -- Early-term concurrent                     9   \n",
       "7                        LMS -- Prior early-term                    13   \n",
       "8                         LMS -- Prior full-term                    16   \n",
       "0                                      All Admin                    97   \n",
       "1                                        All LMS                    50   \n",
       "\n",
       "   highest_normalized_ranking  average_normalized_ranking  \n",
       "0                    0.088435                    0.732499  \n",
       "1                    0.054422                    0.520408  \n",
       "2                    0.163265                    0.163265  \n",
       "3                    0.102041                    0.482993  \n",
       "4                    0.006803                    0.509706  \n",
       "5                    0.013605                    0.199546  \n",
       "6                    0.095238                    0.310658  \n",
       "7                    0.278912                    0.466771  \n",
       "8                    0.258503                    0.414541  \n",
       "0                    0.006803                    0.578442  \n",
       "1                    0.013605                    0.357823  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_part1 = fi_df.iloc[:,:-1]\n",
    "fi_part1.loc[:,'predictor_category'] = fi_part1.predictor_category.apply(lambda x: \"All \" + x)\n",
    "fi_part2 = fi_df.copy()\n",
    "fi_part2.loc[:,'predictor_subcategory'] = fi_part2.predictor_subcategory.apply(lambda x: x.split(\" & \")[0])\n",
    "fi_part2.loc[:,'predictor_subcategory'] = fi_part2.predictor_category + \" -- \" + fi_part2.predictor_subcategory\n",
    "fi_part2 = fi_part2.groupby(['predictor_subcategory']).agg({'feature_ranking': ['count','first','mean']}).reset_index()\n",
    "fi_part2.columns = ['predictor_subcategory', 'number_of_predictors', 'highest_normalized_ranking', 'average_normalized_ranking']\n",
    "fi_part1 = fi_part1.groupby(['predictor_category']).agg({'feature_ranking': ['count','first','mean']}).reset_index()\n",
    "fi_part1.columns = ['predictor_subcategory', 'number_of_predictors', 'highest_normalized_ranking', 'average_normalized_ranking']\n",
    "fi_all_parts = pd.concat([fi_part2, fi_part1])\n",
    "fi_all_parts.round(3).to_csv(results_dir + \"normalized_feature_ranking_BIO101.csv\", index=False)\n",
    "fi_all_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
