{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is used to find out how model performance changes with number of predictors for the lms-only, first-term model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from scipy.stats.mstats import gmean\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_dir = \"~\\\\Box Sync\\\\Clickstream\\\\evaluation_results\\\\first\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\LMS_data_final.dta\")\n",
    "predictors = [e for e in list(df.columns)[5:] if e != \"grade\"]\n",
    "len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert pd.isnull(df).any().any() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204853, 27)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181673, 27) (23180, 27)\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df.strm != 2212]\n",
    "test_df = df[df.strm == 2212]\n",
    "original_test_grade = np.array(test_df.grade)\n",
    "train_df.loc[:,'grade'] = train_df.apply(lambda x: 1 if x.loc['grade'] in {'A','B','C'} else 0, axis=1)\n",
    "test_df.loc[:,'grade'] = test_df.apply(lambda x: 1 if x.loc['grade'] in {'A','B','C'} else 0, axis=1)\n",
    "print(train_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_predictors = {\\\n",
    "5: 'tot_click_cnt_qrt1, tot_time_qrt1, disc_reply_cnt_qtr1, assign_sub_cnt_qtr1, has_assign_sub_cnt_qtr1',\n",
    "10: 'disc_post_cnt_qtr1, on_time_assign_share_qtr1, has_on_time_assign_share_qtr1, has_concurrent_qtr1, tot_click_cnt_qrt1c',\n",
    "15: 'avg_depth_post_qtr1, tot_time_qrt1c, avg_word_tot_qtr1, irreg_session_len_qrt1, avg_session_len_qrt1',\n",
    "21: 'irreg_session_len_qrt1c, assign_sub_cnt_qtr1c, avg_session_len_qrt1c, on_time_assign_share_qtr1c, has_on_time_assign_share_qtr1c, has_assign_sub_cnt_qtr1c'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_predictors = {}\n",
    "for k,v in raw_predictors.items():\n",
    "    clean_predictors[k] = [p.strip() for p in v.split(\",\")]\n",
    "num_of_predictors = sorted(list(clean_predictors.keys()))\n",
    "clean_predictors_2 = {}\n",
    "for k,v in clean_predictors.items():\n",
    "    clean_predictors_2[k] = []\n",
    "    for n in num_of_predictors:\n",
    "        if n <= k:\n",
    "            clean_predictors_2[k] += clean_predictors[n]\n",
    "    assert len(clean_predictors_2[k]) == k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cv_folds(train, predictors, n_fold = 5):\n",
    "    folds = []\n",
    "    k_fold = StratifiedKFold(n_splits = n_fold, random_state = 12345, shuffle=True)\n",
    "    for train_indices, test_indices in k_fold.split(train, train.grade):\n",
    "        train_part = train.iloc[train_indices,:]\n",
    "        test_part = train.iloc[test_indices,:]\n",
    "        X_1 = train_part.loc[:,predictors]\n",
    "        y_1 = train_part.grade\n",
    "        X_2 = test_part.loc[:,predictors]\n",
    "        y_2 = test_part.grade\n",
    "        folds.append([(X_1.copy(),y_1.copy()),(X_2.copy(),y_2.copy())])\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_RF(rf_model, folds):\n",
    "    auc_by_fold = []\n",
    "    for f in folds:\n",
    "        X_1 = f[0][0]\n",
    "        y_1 = f[0][1]\n",
    "        X_2 = f[1][0]\n",
    "        y_2 = f[1][1]\n",
    "        rf_model.fit(X_1,y_1)\n",
    "        y_2_pred = rf_model.predict_proba(X_2)[:,1]\n",
    "        auc_by_fold.append(roc_auc_score(y_2,y_2_pred))\n",
    "    return round(np.mean(auc_by_fold),4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_cw(y):\n",
    "    # Calculate the weight of each letter grade to be used in the modeling fitting procedure: the weight is inversely proportional to the square root of the frequency of the letter grade in the training sample\n",
    "    cw = Counter(y)\n",
    "    class_weight = {k:np.sqrt(cw.most_common()[0][-1]/v, dtype=np.float32) for k,v in cw.items()}\n",
    "    return class_weight # The output is a dictionary mapping letter grade to the corresponding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 5:\n",
      "\n",
      "max_depth = 2: 0.7024\n",
      "max_depth = 3: 0.7082\n",
      "max_depth = 4: 0.7104\n",
      "max_depth = 5: 0.7121\n",
      "max_depth = 6: 0.713\n",
      "\n",
      "C-statistic = 0.7297\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "n = 10:\n",
      "\n",
      "max_depth = 2: 0.7157\n",
      "max_depth = 3: 0.7217\n",
      "max_depth = 4: 0.7292\n",
      "max_depth = 5: 0.7363\n",
      "max_depth = 6: 0.7416\n",
      "max_depth = 7: 0.7459\n",
      "max_depth = 8: 0.7488\n",
      "max_depth = 9: 0.7512\n",
      "max_depth = 10: 0.7527\n",
      "max_depth = 11: 0.7538\n",
      "max_depth = 12: 0.7546\n",
      "\n",
      "C-statistic = 0.7683\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "n = 15:\n",
      "\n",
      "max_depth = 2: 0.7158\n",
      "max_depth = 3: 0.7212\n",
      "max_depth = 4: 0.7293\n",
      "max_depth = 5: 0.7365\n",
      "max_depth = 6: 0.7415\n",
      "max_depth = 7: 0.7459\n",
      "max_depth = 8: 0.7495\n",
      "max_depth = 9: 0.7519\n",
      "max_depth = 10: 0.7541\n",
      "max_depth = 11: 0.7557\n",
      "max_depth = 12: 0.7571\n",
      "max_depth = 13: 0.758\n",
      "\n",
      "C-statistic = 0.773\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "n = 21:\n",
      "\n",
      "max_depth = 2: 0.7151\n",
      "max_depth = 3: 0.7223\n",
      "max_depth = 4: 0.7297\n",
      "max_depth = 5: 0.7366\n",
      "max_depth = 6: 0.7419\n",
      "max_depth = 7: 0.7459\n",
      "max_depth = 8: 0.7497\n",
      "max_depth = 9: 0.7524\n",
      "max_depth = 10: 0.7547\n",
      "max_depth = 11: 0.7565\n",
      "max_depth = 12: 0.7582\n",
      "max_depth = 13: 0.7595\n",
      "max_depth = 14: 0.7603\n",
      "\n",
      "C-statistic = 0.7755\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cstat_by_num = []\n",
    "for n in sorted(list(clean_predictors_2.keys())):\n",
    "    print(\"n = {}:\\n\".format(n))\n",
    "    predictors_list = clean_predictors_2[n]\n",
    "    five_folds = create_cv_folds(train_df, predictors_list)\n",
    "    auc_by_d=[]\n",
    "    for d in range(2,36):\n",
    "        rf = RandomForestClassifier(n_estimators=200, criterion=\"entropy\", \n",
    "                                    max_depth=d,\n",
    "                                    random_state=0, n_jobs=20, max_features=\"auto\",\n",
    "                                    class_weight = calc_cw(train_df.grade))\n",
    "        auc = cross_validation_RF(rf, five_folds)\n",
    "        auc_by_d.append(auc)\n",
    "        print(\"max_depth = {0}: {1}\".format(d, auc))\n",
    "        if d > 2:\n",
    "            if auc - auc_by_d[-2] < 0.001:\n",
    "                break\n",
    "            else:\n",
    "                best_d = d\n",
    "        else:\n",
    "            best_d = d\n",
    "    rf = RandomForestClassifier(n_estimators=200, criterion=\"entropy\",\n",
    "                                max_depth=best_d,\n",
    "                                random_state=0, n_jobs=-1, max_features=\"auto\",\n",
    "                                class_weight = calc_cw(train_df.grade))\n",
    "    rf.fit(train_df.loc[:,predictors_list], train_df.grade)\n",
    "    cstat_by_num.append(round(roc_auc_score(test_df.grade, rf.predict_proba(test_df.loc[:,predictors_list])[:,1]),4))\n",
    "    print(\"\\nC-statistic = {}\".format(cstat_by_num[-1]))\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7297, 0.7683, 0.773, 0.7755]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cstat_by_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
