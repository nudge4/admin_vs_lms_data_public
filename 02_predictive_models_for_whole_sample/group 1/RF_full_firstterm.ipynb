{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script runs the random forest model using the full set of predictors, for all first-term courses. It also creates the data set that contains all predicted scores for all first-term observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from scipy.stats.mstats import gmean\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_dir = \"~\\\\Box Sync\\\\Clickstream\\\\evaluation_results\\\\first\\\\updated\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sn_dict = {\"Blue Ridge\": \"BRCC\",\n",
    "           \"Central Virginia\": \"CVCC\",\n",
    "           \"Dabney S. Lancaster\": \"DSLCC\",\n",
    "           \"Danville\": \"DCC\",\n",
    "           \"Eastern Shore\": \"ESCC\",\n",
    "           \"Germanna\": \"GCC\",\n",
    "           'J. Sargeant Reynolds': \"JSRCC\",\n",
    "           'John Tyler': \"JTCC\",\n",
    "           \"Lord Fairfax\": \"LFCC\",\n",
    "           \"Mountain Empire\": \"MECC\",\n",
    "           \"New River\": \"NRCC\",\n",
    "           \"Northern Virginia\": \"NVCC\",\n",
    "           \"Patrick Henry\": \"PHCC\",\n",
    "           \"Paul D. Camp\": \"PDCCC\",\n",
    "           \"Piedmont Virginia\": \"PVCC\",\n",
    "           \"Rappahannock\": \"RCC\",\n",
    "           \"Southside Virginia\": \"SSVCC\",\n",
    "           \"Southwest Virginia\": \"SWVCC\",\n",
    "           \"Thomas Nelson\": \"TNCC\",\n",
    "           \"Tidewater\": \"TCC\",\n",
    "           \"Virginia Highlands\": \"VHCC\",\n",
    "           \"Virginia Western\": \"VWCC\",\n",
    "           \"Wytheville\": \"WCC\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\updated\\\\LMS_data_final.dta\")\n",
    "df1 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\updated\\\\course_specific_predictors_new.csv\")\n",
    "df2 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\updated\\\\term_specific_predictors_new.csv\")\n",
    "for v in [int(e) for e in np.unique(df2.cip) if e != 0]:\n",
    "    df2.loc[:,'cip_'+str(v)] = (df2.cip == v).astype(int)\n",
    "for v in [int(e) for e in np.unique(df2.degree_level) if e != 4]:\n",
    "    df2.loc[:,'degree_level_'+str(v)] = (df2.degree_level == v).astype(int)\n",
    "df2 = df2.drop(['cip', 'degree_level'], axis=1)\n",
    "df4 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\updated\\\\instructor_related_predictors.dta\")\n",
    "df5 = df0.loc[:,['vccsid','strm','college','course','section']].copy()\n",
    "df5.loc[:,'college_new'] = df5.college.apply(lambda x: sn_dict[x])\n",
    "for sn in [e for e in sn_dict.values() if e != \"BRCC\"]:\n",
    "    df5.loc[:,'college_'+sn] = (df5.college_new == sn).astype(int)\n",
    "df5 = df5.drop(['college_new'], axis=1)\n",
    "df = df0.merge(df1, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df2, how='inner', on=['vccsid','strm'])\\\n",
    ".merge(df4, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df5, how='inner', on=['vccsid','strm','college','course','section'])\n",
    "predictors = [e for e in list(df.columns)[5:] if e != \"grade\"]\n",
    "len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert pd.isnull(df).any().any() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204853, 86)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181673, 86) (23180, 86)\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df.strm != 2212]\n",
    "test_df = df[df.strm == 2212]\n",
    "original_test_grade = np.array(test_df.grade)\n",
    "train_df.loc[:,'grade'] = train_df.apply(lambda x: 1 if x.loc['grade'] in {'A','B','C'} else 0, axis=1)\n",
    "test_df.loc[:,'grade'] = test_df.apply(lambda x: 1 if x.loc['grade'] in {'A','B','C'} else 0, axis=1)\n",
    "print(train_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tune and fit RF models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cv_folds(train, n_fold = 5):\n",
    "    folds = []\n",
    "    k_fold = StratifiedKFold(n_splits = n_fold, random_state = 12345, shuffle=True)\n",
    "    for train_indices, test_indices in k_fold.split(train, train.grade):\n",
    "        train_part = train.iloc[train_indices,:]\n",
    "        test_part = train.iloc[test_indices,:]\n",
    "        X_1 = train_part.loc[:,predictors]\n",
    "        y_1 = train_part.grade\n",
    "        X_2 = test_part.loc[:,predictors]\n",
    "        y_2 = test_part.grade\n",
    "        folds.append([(X_1.copy(),y_1.copy()),(X_2.copy(),y_2.copy())])\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "five_folds = create_cv_folds(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_RF(rf_model, folds):\n",
    "    auc_by_fold = []\n",
    "    for f in folds:\n",
    "        X_1 = f[0][0]\n",
    "        y_1 = f[0][1]\n",
    "        X_2 = f[1][0]\n",
    "        y_2 = f[1][1]\n",
    "        rf_model.fit(X_1,y_1)\n",
    "        y_2_pred = rf_model.predict_proba(X_2)[:,1]\n",
    "        auc_by_fold.append(roc_auc_score(y_2,y_2_pred))\n",
    "    return round(np.mean(auc_by_fold),4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_cw(y):\n",
    "    # Calculate the weight of each letter grade to be used in the modeling fitting procedure: the weight is inversely proportional to the square root of the frequency of the letter grade in the training sample\n",
    "    cw = Counter(y)\n",
    "    class_weight = {k:np.sqrt(cw.most_common()[0][-1]/v, dtype=np.float32) for k,v in cw.items()}\n",
    "    return class_weight # The output is a dictionary mapping letter grade to the corresponding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_depth = 11\n",
      "Mean CV AUC: 0.8104\n",
      "\n",
      "Max_depth = 12\n",
      "Mean CV AUC: 0.8136\n",
      "\n",
      "Max_depth = 13\n",
      "Mean CV AUC: 0.8165\n",
      "\n",
      "Max_depth = 14\n",
      "Mean CV AUC: 0.8188\n",
      "\n",
      "Max_depth = 15\n",
      "Mean CV AUC: 0.821\n",
      "\n",
      "Max_depth = 16\n",
      "Mean CV AUC: 0.8228\n",
      "\n",
      "Max_depth = 17\n",
      "Mean CV AUC: 0.8239\n",
      "\n",
      "Max_depth = 18\n",
      "Mean CV AUC: 0.8248\n",
      "\n",
      "Max_depth = 19\n",
      "Mean CV AUC: 0.826\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-963c6b1def5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m                                 \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"auto\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                 class_weight = calc_cw(train_df.grade))\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation_RF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfive_folds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mauc_by_d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Max_depth =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-fb80a74de69f>\u001b[0m in \u001b[0;36mcross_validation_RF\u001b[1;34m(rf_model, folds)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mX_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0my_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0my_2_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mauc_by_fold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_2_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    333\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 335\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 996\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    997\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    900\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 602\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Using grid search to find the optimal maximum tree depth\n",
    "auc_by_d=[]\n",
    "for d in range(11,31):\n",
    "    rf = RandomForestClassifier(n_estimators=200, criterion=\"entropy\", \n",
    "                                max_depth=d,\n",
    "                                random_state=0, n_jobs=20, max_features=\"auto\",\n",
    "                                class_weight = calc_cw(train_df.grade))\n",
    "    auc = cross_validation_RF(rf, five_folds)\n",
    "    auc_by_d.append(auc)\n",
    "    print(\"Max_depth =\", d)\n",
    "    print(\"Mean CV AUC:\", auc)\n",
    "    print(\"\")\n",
    "plt.plot(range(11,31),auc_by_d)\n",
    "plt.xlabel(\"Maximum Depth\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trees = 100\n",
      "Mean CV AUC: 0.8228\n",
      "\n",
      "Number of Trees = 120\n",
      "Mean CV AUC: 0.8231\n",
      "\n",
      "Number of Trees = 140\n",
      "Mean CV AUC: 0.8232\n",
      "\n",
      "Number of Trees = 160\n",
      "Mean CV AUC: 0.8235\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-907e725a6d83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m                                 \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"auto\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                 class_weight = calc_cw(train_df.grade))\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation_RF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfive_folds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mauc_by_n\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of Trees =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-fb80a74de69f>\u001b[0m in \u001b[0;36mcross_validation_RF\u001b[1;34m(rf_model, folds)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mX_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0my_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0my_2_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mauc_by_fold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_2_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    333\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 335\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 996\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    997\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    900\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 602\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Using grid search to find the optimal number of estimators (trees)\n",
    "auc_by_n = []\n",
    "for n in range(100,320,20):\n",
    "    rf = RandomForestClassifier(n_estimators=n, criterion=\"entropy\", \n",
    "                                max_depth=17,\n",
    "                                random_state=0, n_jobs=-1, max_features=\"auto\",\n",
    "                                class_weight = calc_cw(train_df.grade))\n",
    "    auc = cross_validation_RF(rf, five_folds)\n",
    "    auc_by_n.append(auc)\n",
    "    print(\"Number of Trees =\", n)\n",
    "    print(\"Mean CV AUC:\", auc)\n",
    "    print(\"\")\n",
    "plt.plot(range(100,320,20), auc_by_n)\n",
    "plt.xlabel(\"Number of Trees\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_features = 2\n",
      "Mean CV AUC: 0.8076\n",
      "\n",
      "Max_features = 3\n",
      "Mean CV AUC: 0.8145\n",
      "\n",
      "Max_features = 4\n",
      "Mean CV AUC: 0.8177\n",
      "\n",
      "Max_features = 5\n",
      "Mean CV AUC: 0.82\n",
      "\n",
      "Max_features = 6\n",
      "Mean CV AUC: 0.8215\n",
      "\n",
      "Max_features = 7\n",
      "Mean CV AUC: 0.8224\n",
      "\n",
      "Max_features = 8\n",
      "Mean CV AUC: 0.8231\n",
      "\n",
      "Max_features = 9\n",
      "Mean CV AUC: 0.8232\n",
      "\n",
      "Max_features = 10\n",
      "Mean CV AUC: 0.8235\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-25a334ca195b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m                                 \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                 class_weight = calc_cw(train_df.grade))\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation_RF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfive_folds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mauc_by_nf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Max_features =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-fb80a74de69f>\u001b[0m in \u001b[0;36mcross_validation_RF\u001b[1;34m(rf_model, folds)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mX_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0my_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0my_2_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mauc_by_fold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_2_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    333\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 335\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 996\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    997\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    900\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 602\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Using grid search to find the optimal maximum number of features (trees)\n",
    "auc_by_nf = []\n",
    "max_nf = int(np.floor(2*np.sqrt(len(predictors))))\n",
    "for nf in range(2,max_nf+1):\n",
    "    rf = RandomForestClassifier(n_estimators=120, criterion=\"entropy\", \n",
    "                                max_depth=17,\n",
    "                                random_state=0, n_jobs=-1, max_features=nf,\n",
    "                                class_weight = calc_cw(train_df.grade))\n",
    "    auc = cross_validation_RF(rf, five_folds)\n",
    "    auc_by_nf.append(auc)\n",
    "    print(\"Max_features =\", nf)\n",
    "    print(\"Mean CV AUC:\", auc)\n",
    "    print(\"\")\n",
    "plt.plot(range(2,max_nf+1), auc_by_nf)\n",
    "plt.xlabel(\"Maximum Number of Features\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight={0: 1.6198435, 1: 1.0},\n",
       "            criterion='entropy', max_depth=17, max_features=8,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=120, n_jobs=-1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=120, criterion=\"entropy\",\n",
    "                            max_depth=17,\n",
    "                            random_state=0, n_jobs=-1, max_features=8,\n",
    "                            class_weight = calc_cw(train_df.grade))\n",
    "rf.fit(train_df.loc[:,predictors], train_df.grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "AUC = 0.8245\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest:\")\n",
    "print(\"AUC = {}\".format(round(roc_auc_score(test_df.grade, rf.predict_proba(test_df.loc[:,predictors])[:,1]),4)))\n",
    "y_test_pred_rf = rf.predict_proba(test_df.loc[:,predictors])[:,1]\n",
    "y_train_pred_rf = rf.predict_proba(train_df.loc[:,predictors])[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the data set for storing the predicted scores of admin+lms, admin_only, lms_only RF models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_threshold = np.sort(y_test_pred_rf)[int(len(y_test_pred_rf) * (1-np.mean(train_df.grade)))-1]\n",
    "y_test_pred_rf_bin = np.where(y_test_pred_rf > best_threshold, 1, 0)\n",
    "threshold_train = np.sort(y_train_pred_rf)[int(len(y_train_pred_rf) * (1-np.mean(train_df.grade)))-1]\n",
    "y_train_pred_rf_bin = np.where(y_train_pred_rf > threshold_train, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "info_df_test = test_df.loc[:,['vccsid', 'strm', 'college', 'course', 'section'] + predictors]\n",
    "info_df_test.loc[:,'actual_grade'] = original_test_grade\n",
    "info_df_test.loc[:,'predicted_binary_outcome_full_predictor'] = y_test_pred_rf_bin\n",
    "info_df_test.loc[:,'predicted_score_full_predictor'] = y_test_pred_rf\n",
    "info_df_test = info_df_test.loc[:, ['vccsid', 'strm', 'college', 'course', 'section', 'predicted_score_full_predictor', 'predicted_binary_outcome_full_predictor', 'actual_grade'] + predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lms_1 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\updated\\\\LMS_data_updated.dta\").drop(['grade'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(info_df_test.shape)\n",
    "info_df_test = info_df_test.merge(lms_1, on=['vccsid', 'strm', 'college', 'course', 'section'], how='left')\n",
    "print(info_df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for cn in info_df_test.columns.values:\n",
    "    if cn.endswith(\"_x\"):\n",
    "        info_df_test.rename(columns = {cn: cn[:-2]}, inplace=True)\n",
    "    if cn.endswith(\"_y\"):\n",
    "        info_df_test.rename(columns = {cn: cn[:-1] + \"raw\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "info_df_train = train_df.loc[:,['vccsid', 'strm', 'college', 'course', 'section'] + predictors]\n",
    "info_df_train.loc[:,'actual_grade'] = original_train_grade\n",
    "info_df_train.loc[:,'predicted_binary_outcome_full_predictor'] = y_train_pred_rf_bin\n",
    "info_df_train.loc[:,'predicted_score_full_predictor'] = y_train_pred_rf\n",
    "info_df_train = info_df_train.loc[:, ['vccsid', 'strm', 'college', 'course', 'section', 'predicted_score_full_predictor', 'predicted_binary_outcome_full_predictor', 'actual_grade'] + predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(info_df_train.shape)\n",
    "info_df_train = info_df_train.merge(lms_1, on=['vccsid', 'strm', 'college', 'course', 'section'], how='left')\n",
    "print(info_df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for cn in info_df_train.columns.values:\n",
    "    if cn.endswith(\"_x\"):\n",
    "        info_df_train.rename(columns = {cn: cn[:-2]}, inplace=True)\n",
    "    if cn.endswith(\"_y\"):\n",
    "        info_df_train.rename(columns = {cn: cn[:-1] + \"raw\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "info_df_train.loc[:,'is_validation'] = 0\n",
    "info_df_test.loc[:,'is_validation'] = 1\n",
    "info_df = pd.concat([info_df_train, info_df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(info_df.shape)\n",
    "info_df = info_df.merge(pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\updated\\\\first_info_df_admin_only.csv\"), on=['vccsid', 'strm', 'college', 'course', 'section']).merge(pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\updated\\\\first_info_df_lms_only.csv\"), on=['vccsid', 'strm', 'college', 'course', 'section'])\n",
    "print(info_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_list_1 = ['vccsid', 'strm', 'college', 'course', 'section', 'is_validation', 'predicted_score_full_predictor', 'predicted_binary_outcome_full_predictor', 'predicted_score_admin_only', 'predicted_binary_outcome_admin_only', 'predicted_score_lms_only', 'predicted_binary_outcome_lms_only']\n",
    "var_list_2 = [p for p in info_df.columns.values if p not in set(var_list_1)]\n",
    "var_list = var_list_1 + var_list_2\n",
    "info_df = info_df.loc[:,var_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "info_df.to_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\updated\\\\first_term_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare online vs. in-person courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "online_ind_df = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\updated\\\\updated_online_ind.dta\")\n",
    "online_ind = test_df.merge(online_ind_df, how='inner', on=['vccsid','strm','college','course','section']).online_ind_y\n",
    "inperson_ind = test_df.merge(online_ind_df, how='inner', on=['vccsid','strm','college','course','section']).inperson_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Onine AUC = 0.8235\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest:\")\n",
    "print(\"Onine AUC = {}\".format(round(roc_auc_score(test_df[np.array(online_ind == 1)].grade, np.array(y_test_pred_rf)[np.array(online_ind == 1)]),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "In-person AUC = 0.8085\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest:\")\n",
    "print(\"In-person AUC = {}\".format(round(roc_auc_score(test_df[np.array(inperson_ind == 1)].grade, np.array(y_test_pred_rf)[np.array(inperson_ind == 1)]),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi_df = pd.DataFrame({\"feature_importance\": rf.feature_importances_, \"predictor\": predictors})\\\n",
    ".loc[:,['predictor', 'feature_importance']].sort_values(['feature_importance'], ascending=False)\n",
    "fi_df.loc[:,'feature_ranking'] = np.arange(1, fi_df.shape[0] + 1) / fi_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi_df.loc[:,['predictor', 'feature_importance']].to_csv(results_dir + \"feature_importance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ENG_111 8979\n",
      "AUC = 0.8535\n",
      "\n",
      "ENG_112 11471\n",
      "AUC = 0.8652\n",
      "\n",
      "MTH_154 5738\n",
      "AUC = 0.8189\n",
      "\n",
      "MTH_161 4080\n",
      "AUC = 0.7994\n",
      "\n",
      "BIO_101 8881\n",
      "AUC = 0.8552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in ['ENG_111', 'ENG_112', 'MTH_154', 'MTH_161', 'BIO_101']:\n",
    "    pred_new = pred_df[pred_df.course == c]\n",
    "    print(c, pred_new.shape[0])\n",
    "    print(\"AUC = {}\".format(round(roc_auc_score(pred_new.real_y, pred_new.pred_y), 4)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance over all observations (non-first-term + first-term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred_full = pickle.load(open(\"~\\\\Box Sync\\\\Clickstream\\\\evaluation_results\\\\full\\\\y_test_pred_full.p\", \"rb\"))\n",
    "y_test_full = pickle.load(open(\"~\\\\Box Sync\\\\Clickstream\\\\evaluation_results\\\\full\\\\y_test_full.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8684"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(roc_auc_score(list(test_df.grade) + y_test_full, list(rf.predict_proba(test_df.loc[:,predictors])[:,1]) + y_test_pred_full),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENG_111\n",
      "AUC = 0.812\n",
      "\n",
      "ENG_112\n",
      "AUC = 0.8279\n",
      "\n",
      "MTH_154\n",
      "AUC = 0.7841\n",
      "\n",
      "MTH_161\n",
      "AUC = 0.7844\n",
      "\n",
      "BIO_101\n",
      "AUC = 0.8461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in ['ENG_111', 'ENG_112', 'MTH_154', 'MTH_161', 'BIO_101']:\n",
    "    test_new = test_df[test_df.course == c]\n",
    "    print(c)\n",
    "    print(\"AUC = {}\".format(round(roc_auc_score(test_new.grade, rf.predict_proba(test_new.loc[:,predictors])[:,1]),4)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC vs. DF\n",
      "AUC = 0.7955\n"
     ]
    }
   ],
   "source": [
    "print(\"ABC vs. DF\")\n",
    "print(\"AUC = {}\".format(round(roc_auc_score(np.array(test_df.grade)[np.where(np.array(original_test_grade) != \"W\")[0]], \n",
    "                                            rf.predict_proba(test_df.loc[:,predictors])[np.where(np.array(original_test_grade) != \"W\")[0],1]),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi_df = pd.DataFrame({\"feature_importance\": rf.feature_importances_, \"predictor\": predictors})\\\n",
    ".loc[:,['predictor', 'feature_importance']].sort_values(['feature_importance'], ascending=False)\n",
    "fi_df.loc[:,'feature_ranking'] = np.arange(1, fi_df.shape[0] + 1) / fi_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cw_df = pd.read_csv(results_dir + \"predictor_category_table.csv\")\n",
    "fi_df = fi_df.merge(cw_df, on=['predictor'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi_df.loc[:,'predictor_category'] = fi_df.predictor_category.apply(lambda x: \"Admin\" if pd.isnull(x) else x)\n",
    "fi_df.loc[:,'predictor_subcategory'] = fi_df.predictor_subcategory.apply(lambda x: \"Non-course-specific academic records\" if pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_lms = [e for e in predictors if (e.endswith(\"_qtr1\") or e.endswith(\"_qrt1\")) and (e != \"has_concurrent_qtr1\")]\n",
    "concurrent_lms = [e for e in predictors if e.endswith(\"_qtr1c\") or e.endswith(\"_qrt1c\") or e == 'has_concurrent_qtr1']\n",
    "all_lms = early_lms + concurrent_lms\n",
    "assign_lms = [e for e in all_lms if \"assign\" in e]\n",
    "disc_lms = [e for e in all_lms if \"disc\" in e or \"word\" in e or \"post\" in e]\n",
    "click_lms = [e for e in all_lms if e not in assign_lms + disc_lms]\n",
    "all_admin = [e for e in predictors if e not in set(all_lms)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>predictor_type</th>\n",
       "      <th>predictor_subcategory</th>\n",
       "      <th>ranking</th>\n",
       "      <th>feature_importance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tot_click_cnt_qrt1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>1</td>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crnt_enrl_intensity</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>2</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tot_time_qrt1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>3</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disc_reply_cnt_qtr1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>4</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_g</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Course-specific</td>\n",
       "      <td>5</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>disc_post_cnt_qtr1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>6</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>assign_sub_cnt_qtr1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>7</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>past_avg_grade</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Instructor-related</td>\n",
       "      <td>8</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>avg_depth_post_qtr1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>9</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tot_click_cnt_qrt1c</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term concurrent</td>\n",
       "      <td>10</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>on_time_assign_share_qtr1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>11</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>avg_word_tot_qtr1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>12</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tot_time_qrt1c</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term concurrent</td>\n",
       "      <td>13</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>irreg_session_len_qrt1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>14</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>summer_ind</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Course-specific</td>\n",
       "      <td>15</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>avg_g_concurrent</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Course-specific</td>\n",
       "      <td>16</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>avg_session_len_qrt1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term</td>\n",
       "      <td>17</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>irreg_session_len_qrt1c</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term concurrent</td>\n",
       "      <td>18</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>age</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>19</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>avg_session_len_qrt1c</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term concurrent</td>\n",
       "      <td>20</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>section_size</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Course-specific</td>\n",
       "      <td>21</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>assign_sub_cnt_qtr1c</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term concurrent</td>\n",
       "      <td>22</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>lvl2_share</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>23</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>on_time_assign_share_qtr1c</td>\n",
       "      <td>LMS</td>\n",
       "      <td>Early-term concurrent</td>\n",
       "      <td>24</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>online_share</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>25</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dev</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>26</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>degree_level_1</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>27</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>eve_share</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Non-course-specific academic records</td>\n",
       "      <td>28</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>has_avg_g_concurrent</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Course-specific</td>\n",
       "      <td>29</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>online_ind</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Course-specific</td>\n",
       "      <td>30</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     predictor predictor_type  \\\n",
       "0           tot_click_cnt_qrt1            LMS   \n",
       "1          crnt_enrl_intensity          Admin   \n",
       "2                tot_time_qrt1            LMS   \n",
       "3          disc_reply_cnt_qtr1            LMS   \n",
       "4                        avg_g          Admin   \n",
       "5           disc_post_cnt_qtr1            LMS   \n",
       "6          assign_sub_cnt_qtr1            LMS   \n",
       "7               past_avg_grade          Admin   \n",
       "8          avg_depth_post_qtr1            LMS   \n",
       "9          tot_click_cnt_qrt1c            LMS   \n",
       "10   on_time_assign_share_qtr1            LMS   \n",
       "11           avg_word_tot_qtr1            LMS   \n",
       "12              tot_time_qrt1c            LMS   \n",
       "13      irreg_session_len_qrt1            LMS   \n",
       "14                  summer_ind          Admin   \n",
       "15            avg_g_concurrent          Admin   \n",
       "16        avg_session_len_qrt1            LMS   \n",
       "17     irreg_session_len_qrt1c            LMS   \n",
       "18                         age          Admin   \n",
       "19       avg_session_len_qrt1c            LMS   \n",
       "20                section_size          Admin   \n",
       "21        assign_sub_cnt_qtr1c            LMS   \n",
       "22                  lvl2_share          Admin   \n",
       "23  on_time_assign_share_qtr1c            LMS   \n",
       "24                online_share          Admin   \n",
       "25                         dev          Admin   \n",
       "26              degree_level_1          Admin   \n",
       "27                   eve_share          Admin   \n",
       "28        has_avg_g_concurrent          Admin   \n",
       "29                  online_ind          Admin   \n",
       "\n",
       "                   predictor_subcategory  ranking  feature_importance_score  \n",
       "0                             Early-term        1                     0.109  \n",
       "1   Non-course-specific academic records        2                     0.079  \n",
       "2                             Early-term        3                     0.073  \n",
       "3                             Early-term        4                     0.049  \n",
       "4                        Course-specific        5                     0.048  \n",
       "5                             Early-term        6                     0.047  \n",
       "6                             Early-term        7                     0.044  \n",
       "7                     Instructor-related        8                     0.040  \n",
       "8                             Early-term        9                     0.037  \n",
       "9                  Early-term concurrent       10                     0.035  \n",
       "10                            Early-term       11                     0.035  \n",
       "11                            Early-term       12                     0.030  \n",
       "12                 Early-term concurrent       13                     0.028  \n",
       "13                            Early-term       14                     0.028  \n",
       "14                       Course-specific       15                     0.028  \n",
       "15                       Course-specific       16                     0.026  \n",
       "16                            Early-term       17                     0.024  \n",
       "17                 Early-term concurrent       18                     0.022  \n",
       "18                           Demographic       19                     0.022  \n",
       "19                 Early-term concurrent       20                     0.021  \n",
       "20                       Course-specific       21                     0.019  \n",
       "21                 Early-term concurrent       22                     0.017  \n",
       "22  Non-course-specific academic records       23                     0.014  \n",
       "23                 Early-term concurrent       24                     0.011  \n",
       "24  Non-course-specific academic records       25                     0.011  \n",
       "25  Non-course-specific academic records       26                     0.009  \n",
       "26  Non-course-specific academic records       27                     0.008  \n",
       "27  Non-course-specific academic records       28                     0.008  \n",
       "28                       Course-specific       29                     0.004  \n",
       "29                       Course-specific       30                     0.004  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_df.loc[:,'predictor_subcategory'] = fi_df.predictor_subcategory.apply(lambda x: x.split(\" & \")[0])\n",
    "fi_df_top30 = fi_df.iloc[:30,:].drop(['feature_ranking'], axis=1)\n",
    "fi_df_top30.loc[:,'feature_ranking'] = np.arange(1,31)\n",
    "fi_df_top30 = fi_df_top30.round(3)\n",
    "fi_df_top30 = fi_df_top30.rename(columns = {'feature_importance': 'feature_importance_score',\n",
    "                                            'feature_ranking': 'ranking',\n",
    "                                            'predictor_category': 'predictor_type'})\n",
    "fi_df_top30 = fi_df_top30.loc[:,['predictor', 'predictor_type', 'predictor_subcategory', 'ranking', 'feature_importance_score']]\n",
    "fi_df_top30.to_csv(results_dir + \"top30_predictors.csv\", index=False)\n",
    "fi_df_top30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fi_results = []\n",
    "# for c in ['early_lms', 'concurrent_lms', 'click_lms', 'assign_lms', 'disc_lms', 'all_lms', 'all_admin']:\n",
    "#     l = fi_df.merge(pd.DataFrame({'predictor': eval(c)}), how='inner', on=['predictor']).feature_ranking\n",
    "#     fi_results.append((c, len(l), l.iloc[0], l.mean()))\n",
    "# fi_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# category_dict = {'early_lms': \"Early-term LMS\",\n",
    "#                  'concurrent_lms': 'Early-term concurrent LMS',\n",
    "#                  'historical_early_lms': 'Historical early-term LMS',\n",
    "#                  'historical_full_lms': 'Historical full-term LMS',\n",
    "#                  'click_lms': 'LMS -- clicks/session/time',\n",
    "#                  'assign_lms': 'LMS -- assignments',\n",
    "#                  'disc_lms': 'LMS -- discussion forums',\n",
    "#                  'all_lms': 'All LMS',\n",
    "#                  'all_admin': 'All admin'}\n",
    "# fi_df = pd.DataFrame(fi_results, columns=['predictor_category', 'number_of_predictors', 'highest_normalized_ranking', 'average_normalized_ranking']).round(3)\n",
    "# fi_df.loc[:,'predictor_category'] = fi_df.predictor_category.apply(lambda x: category_dict[x])\n",
    "# fi_df.to_csv(results_dir + \"normalized_feature_ranking.csv\", index=False)\n",
    "# fi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi_part1 = fi_df.iloc[:,:-1]\n",
    "fi_part1.loc[:,'predictor_category'] = fi_part1.predictor_category.apply(lambda x: \"All \" + x)\n",
    "fi_part2 = fi_df.copy()\n",
    "fi_part2.loc[:,'predictor_subcategory'] = fi_part2.predictor_subcategory.apply(lambda x: x.split(\" & \")[0])\n",
    "fi_part2.loc[:,'predictor_subcategory'] = fi_part2.predictor_category + \" -- \" + fi_part2.predictor_subcategory\n",
    "# fi_part3 = fi_df.copy()\n",
    "# fi_part3.loc[:,'predictor_subcategory'] = fi_part3.predictor_subcategory.apply(lambda x: x.split(\" & \")[-1])\n",
    "# fi_part3 = fi_part3[fi_part3.predictor_category == \"LMS\"]\n",
    "# fi_part3.loc[:,'predictor_subcategory'] = fi_part3.predictor_category + \" -- \" + fi_part3.predictor_subcategory\n",
    "fi_part2 = fi_part2.groupby(['predictor_subcategory']).agg({'feature_ranking': ['count','first','mean']}).reset_index()\n",
    "fi_part2.columns = ['predictor_subcategory', 'number_of_predictors', 'highest_normalized_ranking', 'average_normalized_ranking']\n",
    "# fi_part3 = fi_part3.groupby(['predictor_subcategory']).agg({'feature_ranking': ['count','first','mean']}).reset_index()\n",
    "# fi_part3.columns = ['predictor_subcategory', 'number_of_predictors', 'highest_normalized_ranking', 'average_normalized_ranking']\n",
    "# fi_part3\n",
    "fi_part1 = fi_part1.groupby(['predictor_category']).agg({'feature_ranking': ['count','first','mean']}).reset_index()\n",
    "fi_part1.columns = ['predictor_subcategory', 'number_of_predictors', 'highest_normalized_ranking', 'average_normalized_ranking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi_all_parts = pd.concat([fi_part2, fi_part1])\n",
    "fi_all_parts.round(3).to_csv(results_dir + \"normalized_feature_ranking.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor_subcategory</th>\n",
       "      <th>number_of_predictors</th>\n",
       "      <th>highest_normalized_ranking</th>\n",
       "      <th>average_normalized_ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Admin -- Course-specific</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.654583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Admin -- Demographic</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.237500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Admin -- Instructor-related</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.362500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Admin -- Non-course-specific academic records</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.595313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LMS -- Early-term</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.164583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LMS -- Early-term concurrent</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.323611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All Admin</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.603602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All LMS</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.232738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           predictor_subcategory  number_of_predictors  \\\n",
       "0                       Admin -- Course-specific                    30   \n",
       "1                           Admin -- Demographic                     1   \n",
       "2                    Admin -- Instructor-related                     4   \n",
       "3  Admin -- Non-course-specific academic records                    24   \n",
       "4                              LMS -- Early-term                    12   \n",
       "5                   LMS -- Early-term concurrent                     9   \n",
       "0                                      All Admin                    59   \n",
       "1                                        All LMS                    21   \n",
       "\n",
       "   highest_normalized_ranking  average_normalized_ranking  \n",
       "0                      0.0625                    0.654583  \n",
       "1                      0.2375                    0.237500  \n",
       "2                      0.1000                    0.362500  \n",
       "3                      0.0250                    0.595313  \n",
       "4                      0.0125                    0.164583  \n",
       "5                      0.1250                    0.323611  \n",
       "0                      0.0250                    0.603602  \n",
       "1                      0.0125                    0.232738  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_all_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_threshold = np.sort(y_test_pred_rf)[int(len(y_test_pred_rf) * (1-np.mean(train_df.grade)))-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_confusion_matrix(y_test_pred, threshold, fname):\n",
    "    cm_arr = confusion_matrix(y_test, np.where(y_test_pred > threshold, 1, 0))\n",
    "    cm_df = pd.DataFrame(cm_arr, columns=['Pred_DFW','Pred_ABC'], index=['Actual_DFW', 'Actual_ABC'])\n",
    "    cm_df.loc[:,''] = cm_df.sum(axis=1)\n",
    "    cm_df.loc['',:] = cm_df.sum(axis=0)\n",
    "    print(cm_df)\n",
    "    print(\"\")\n",
    "    p1 = cm_df.iloc[1,1]/cm_df.iloc[2,1]\n",
    "    r1 = cm_df.iloc[1,1]/cm_df.iloc[1,2]\n",
    "    p0 = cm_df.iloc[0,0]/cm_df.iloc[2,0]\n",
    "    r0 = cm_df.iloc[0,0]/cm_df.iloc[0,2]    \n",
    "    print(\"F1 score for A/B/C = {}\".format(round(2*p1*r1/(p1+r1),4)))\n",
    "    print(\"F1 score for D/F/W = {}\".format(round(2*p0*r0/(p0+r0),4))) \n",
    "    cm_df.to_csv(results_dir + fname + \".csv\")\n",
    "    y_test_pred_bin = np.where(y_test_pred > best_threshold, 1, 0)\n",
    "    cm_dict = {}\n",
    "    cm_dict['Pred_DFW'] = Counter(original_test_grade[np.where(y_test_pred_bin==0)[0]])\n",
    "    cm_dict['Pred_ABC'] = Counter(original_test_grade[np.where(y_test_pred_bin==1)[0]])\n",
    "    new_cm = pd.DataFrame.from_dict(cm_dict, orient='index').T.loc[['W','F','D','C','B','A'],['Pred_DFW','Pred_ABC']]\n",
    "    new_cm.index = [\"Actual_\"+e for e in new_cm.index]\n",
    "    new_cm.loc[:,''] = new_cm.sum(axis=1)\n",
    "    new_cm.loc['',:] = new_cm.sum(axis=0)\n",
    "    new_cm.to_csv(results_dir + fname + \"_6x2.csv\")\n",
    "    return round(p1,4),round(r1,4),round(p0,4),round(r0,4),round(2*p1*r1/(p1+r1),4),round(2*p0*r0/(p0+r0),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 threshold = 0.5942:\n",
      "\n",
      "            Pred_DFW  Pred_ABC         \n",
      "Actual_DFW    4131.0    2614.0   6745.0\n",
      "Actual_ABC    2265.0   14170.0  16435.0\n",
      "              6396.0   16784.0  23180.0\n",
      "\n",
      "F1 score for A/B/C = 0.8531\n",
      "F1 score for D/F/W = 0.6287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = np.array(test_df.grade)\n",
    "print(\"F1 threshold = {}:\\n\".format(str(round(best_threshold,4))))\n",
    "pr_rf = create_confusion_matrix(y_test_pred_rf, best_threshold, \"RF_1_full_cm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8443, 0.8622, 0.6459, 0.6125, 0.8531, 0.6287)\n"
     ]
    }
   ],
   "source": [
    "pr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
