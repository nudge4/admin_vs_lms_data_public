{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is used to find out how model performance changes with number of predictors for the full-predictor, first-term model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from scipy.stats.mstats import gmean\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_dir = \"~\\\\Box Sync\\\\Clickstream\\\\evaluation_results\\\\first\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sn_dict = {\"Blue Ridge\": \"BRCC\",\n",
    "           \"Central Virginia\": \"CVCC\",\n",
    "           \"Dabney S. Lancaster\": \"DSLCC\",\n",
    "           \"Danville\": \"DCC\",\n",
    "           \"Eastern Shore\": \"ESCC\",\n",
    "           \"Germanna\": \"GCC\",\n",
    "           'J. Sargeant Reynolds': \"JSRCC\",\n",
    "           'John Tyler': \"JTCC\",\n",
    "           \"Lord Fairfax\": \"LFCC\",\n",
    "           \"Mountain Empire\": \"MECC\",\n",
    "           \"New River\": \"NRCC\",\n",
    "           \"Northern Virginia\": \"NVCC\",\n",
    "           \"Patrick Henry\": \"PHCC\",\n",
    "           \"Paul D. Camp\": \"PDCCC\",\n",
    "           \"Piedmont Virginia\": \"PVCC\",\n",
    "           \"Rappahannock\": \"RCC\",\n",
    "           \"Southside Virginia\": \"SSVCC\",\n",
    "           \"Southwest Virginia\": \"SWVCC\",\n",
    "           \"Thomas Nelson\": \"TNCC\",\n",
    "           \"Tidewater\": \"TCC\",\n",
    "           \"Virginia Highlands\": \"VHCC\",\n",
    "           \"Virginia Western\": \"VWCC\",\n",
    "           \"Wytheville\": \"WCC\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\LMS_data_final.dta\")\n",
    "df1 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\course_specific_predictors_new.csv\")\n",
    "df2 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\term_specific_predictors_new.csv\")\n",
    "for v in [int(e) for e in np.unique(df2.cip) if e != 0]:\n",
    "    df2.loc[:,'cip_'+str(v)] = (df2.cip == v).astype(int)\n",
    "for v in [int(e) for e in np.unique(df2.degree_level) if e != 4]:\n",
    "    df2.loc[:,'degree_level_'+str(v)] = (df2.degree_level == v).astype(int)\n",
    "df2 = df2.drop(['cip', 'degree_level'], axis=1)\n",
    "df4 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\first\\\\instructor_related_predictors.dta\")\n",
    "df5 = df0.loc[:,['vccsid','strm','college','course','section']].copy()\n",
    "df5.loc[:,'college_new'] = df5.college.apply(lambda x: sn_dict[x])\n",
    "for sn in [e for e in sn_dict.values() if e != \"BRCC\"]:\n",
    "    df5.loc[:,'college_'+sn] = (df5.college_new == sn).astype(int)\n",
    "df5 = df5.drop(['college_new'], axis=1)\n",
    "df = df0.merge(df1, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df2, how='inner', on=['vccsid','strm'])\\\n",
    ".merge(df4, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df5, how='inner', on=['vccsid','strm','college','course','section'])\n",
    "predictors = [e for e in list(df.columns)[5:] if e != \"grade\"]\n",
    "len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert pd.isnull(df).any().any() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204853, 86)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181673, 86) (23180, 86)\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df.strm != 2212]\n",
    "test_df = df[df.strm == 2212]\n",
    "original_test_grade = np.array(test_df.grade)\n",
    "train_df.loc[:,'grade'] = train_df.apply(lambda x: 1 if x.loc['grade'] in {'A','B','C'} else 0, axis=1)\n",
    "test_df.loc[:,'grade'] = test_df.apply(lambda x: 1 if x.loc['grade'] in {'A','B','C'} else 0, axis=1)\n",
    "print(train_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# raw_predictors = {\\\n",
    "# 10: 'tot_click_cnt_qrt1, crnt_enrl_intensity, tot_time_qrt1, disc_reply_cnt_qtr1, disc_post_cnt_qtr1, avg_g, assign_sub_cnt_qtr1, has_assign_sub_cnt_qtr1, past_avg_grade, past_avg_grade',\n",
    "# 20: 'avg_depth_post_qtr1, on_time_assign_share_qtr1, has_on_time_assign_share_qtr1, has_concurrent_qtr1, tot_click_cnt_qrt1c, avg_word_tot_qtr1, tot_time_qrt1c, irreg_session_len_qrt1, summer_ind, avg_session_len_qrt1',\n",
    "# 30: 'irreg_session_len_qrt1c, has_avg_g_concurrent, avg_g_concurrent, age, avg_session_len_qrt1c, section_size, assign_sub_cnt_qtr1c, has_assign_sub_cnt_qtr1c, lvl2_share, online_share',\n",
    "# 40: 'has_on_time_assign_share_qtr1c, on_time_assign_share_qtr1c, dev, eve_share, degree_level_1, online_ind, full_time, tenure, college_NVCC, degree_level_2',\n",
    "# 50: 'lvl2_ind, college_TCC, cip_24, cip_52, degree_level_3, college_JTCC, cip_51, cip_11, eve_ind, cip_30',\n",
    "# 60: 'college_JSRCC, college_GCC, college_TNCC, cip_45, college_LFCC, college_VWCC, cip_43, college_SWVCC, cip_14, cip_50',\n",
    "# 70: 'cip_15, cip_99, college_CVCC, college_NRCC, college_PVCC, cip_47, college_PHCC, cip_19, college_VHCC, cip_42',\n",
    "# 80: 'college_MECC, college_DCC, college_RCC, college_WCC, college_PDCCC, college_SSVCC, cip_48, college_DSLCC, cip_46, college_ESCC'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_predictors = {\\\n",
    "5: 'tot_click_cnt_qrt1, crnt_enrl_intensity, tot_time_qrt1, disc_reply_cnt_qtr1, disc_post_cnt_qtr1',\n",
    "15: 'avg_g, assign_sub_cnt_qtr1, has_assign_sub_cnt_qtr1, past_avg_grade, has_past_avg_grade, avg_depth_post_qtr1, on_time_assign_share_qtr1, has_on_time_assign_share_qtr1, has_concurrent_qtr1, tot_click_cnt_qrt1c',\n",
    "25: 'avg_word_tot_qtr1, tot_time_qrt1c, irreg_session_len_qrt1, summer_ind, avg_session_len_qrt1, avg_g_concurrent, has_avg_g_concurrent, irreg_session_len_qrt1c, age, avg_session_len_qrt1c',\n",
    "35: 'section_size, assign_sub_cnt_qtr1c, has_assign_sub_cnt_qtr1c, lvl2_share, on_time_assign_share_qtr1c, has_on_time_assign_share_qtr1c, online_share, dev, eve_share, degree_level_1',\n",
    "45: 'online_ind, full_time, tenure, college_NVCC, degree_level_2, lvl2_ind, college_TCC, cip_24, cip_52, degree_level_3'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_predictors = {}\n",
    "for k,v in raw_predictors.items():\n",
    "    clean_predictors[k] = [p.strip() for p in v.split(\",\")]\n",
    "num_of_predictors = sorted(list(clean_predictors.keys()))\n",
    "clean_predictors_2 = {}\n",
    "for k,v in clean_predictors.items():\n",
    "    clean_predictors_2[k] = []\n",
    "    for n in num_of_predictors:\n",
    "        if n <= k:\n",
    "            clean_predictors_2[k] += clean_predictors[n]\n",
    "    assert len(clean_predictors_2[k]) == k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cv_folds(train, predictors, n_fold = 5):\n",
    "    folds = []\n",
    "    k_fold = StratifiedKFold(n_splits = n_fold, random_state = 12345, shuffle=True)\n",
    "    for train_indices, test_indices in k_fold.split(train, train.grade):\n",
    "        train_part = train.iloc[train_indices,:]\n",
    "        test_part = train.iloc[test_indices,:]\n",
    "        X_1 = train_part.loc[:,predictors]\n",
    "        y_1 = train_part.grade\n",
    "        X_2 = test_part.loc[:,predictors]\n",
    "        y_2 = test_part.grade\n",
    "        folds.append([(X_1.copy(),y_1.copy()),(X_2.copy(),y_2.copy())])\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_RF(rf_model, folds):\n",
    "    auc_by_fold = []\n",
    "    for f in folds:\n",
    "        X_1 = f[0][0]\n",
    "        y_1 = f[0][1]\n",
    "        X_2 = f[1][0]\n",
    "        y_2 = f[1][1]\n",
    "        rf_model.fit(X_1,y_1)\n",
    "        y_2_pred = rf_model.predict_proba(X_2)[:,1]\n",
    "        auc_by_fold.append(roc_auc_score(y_2,y_2_pred))\n",
    "    return round(np.mean(auc_by_fold),4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_cw(y):\n",
    "    # Calculate the weight of each letter grade to be used in the modeling fitting procedure: the weight is inversely proportional to the square root of the frequency of the letter grade in the training sample\n",
    "    cw = Counter(y)\n",
    "    class_weight = {k:np.sqrt(cw.most_common()[0][-1]/v, dtype=np.float32) for k,v in cw.items()}\n",
    "    return class_weight # The output is a dictionary mapping letter grade to the corresponding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 5:\n",
      "\n",
      "max_depth = 5: 0.7225\n",
      "max_depth = 6: 0.7264\n",
      "max_depth = 7: 0.7295\n",
      "max_depth = 8: 0.7317\n",
      "max_depth = 9: 0.7334\n",
      "max_depth = 10: 0.7354\n",
      "max_depth = 11: 0.737\n",
      "max_depth = 12: 0.7379\n",
      "\n",
      "C-statistic = 0.7523\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "n = 15:\n",
      "\n",
      "max_depth = 5: 0.7585\n",
      "max_depth = 6: 0.7664\n",
      "max_depth = 7: 0.7742\n",
      "max_depth = 8: 0.7807\n",
      "max_depth = 9: 0.7855\n",
      "max_depth = 10: 0.7895\n",
      "max_depth = 11: 0.7926\n",
      "max_depth = 12: 0.7954\n",
      "max_depth = 13: 0.7974\n",
      "max_depth = 14: 0.7989\n",
      "max_depth = 15: 0.8002\n",
      "max_depth = 16: 0.801\n",
      "\n",
      "C-statistic = 0.8114\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "n = 25:\n",
      "\n",
      "max_depth = 5: 0.7741\n",
      "max_depth = 6: 0.7818\n",
      "max_depth = 7: 0.7905\n",
      "max_depth = 8: 0.7968\n",
      "max_depth = 9: 0.8014\n",
      "max_depth = 10: 0.8055\n",
      "max_depth = 11: 0.8089\n",
      "max_depth = 12: 0.8114\n",
      "max_depth = 13: 0.8137\n",
      "max_depth = 14: 0.8149\n",
      "max_depth = 15: 0.8162\n",
      "max_depth = 16: 0.817\n",
      "\n",
      "C-statistic = 0.8199\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "n = 35:\n",
      "\n",
      "max_depth = 5: 0.7775\n",
      "max_depth = 6: 0.7853\n",
      "max_depth = 7: 0.7923\n",
      "max_depth = 8: 0.7986\n",
      "max_depth = 9: 0.8038\n",
      "max_depth = 10: 0.8083\n",
      "max_depth = 11: 0.8118\n",
      "max_depth = 12: 0.8146\n",
      "max_depth = 13: 0.8171\n",
      "max_depth = 14: 0.8191\n",
      "max_depth = 15: 0.8209\n",
      "max_depth = 16: 0.8218\n",
      "\n",
      "C-statistic = 0.8237\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "n = 45:\n",
      "\n",
      "max_depth = 5: 0.7773\n",
      "max_depth = 6: 0.7864\n",
      "max_depth = 7: 0.7927\n",
      "max_depth = 8: 0.799\n",
      "max_depth = 9: 0.8038\n",
      "max_depth = 10: 0.8085\n",
      "max_depth = 11: 0.812\n",
      "max_depth = 12: 0.8151\n",
      "max_depth = 13: 0.8176\n",
      "max_depth = 14: 0.8198\n",
      "max_depth = 15: 0.8219\n",
      "max_depth = 16: 0.823\n",
      "max_depth = 17: 0.8243\n",
      "max_depth = 18: 0.8249\n",
      "\n",
      "C-statistic = 0.8263\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cstat_by_num = []\n",
    "for n in sorted(list(clean_predictors_2.keys())):\n",
    "    print(\"n = {}:\\n\".format(n))\n",
    "    predictors_list = clean_predictors_2[n]\n",
    "    five_folds = create_cv_folds(train_df, predictors_list)\n",
    "    auc_by_d=[]\n",
    "    for d in range(5,36):\n",
    "        rf = RandomForestClassifier(n_estimators=200, criterion=\"entropy\", \n",
    "                                    max_depth=d,\n",
    "                                    random_state=0, n_jobs=20, max_features=\"auto\",\n",
    "                                    class_weight = calc_cw(train_df.grade))\n",
    "        auc = cross_validation_RF(rf, five_folds)\n",
    "        auc_by_d.append(auc)\n",
    "        print(\"max_depth = {0}: {1}\".format(d, auc))\n",
    "        if d > 5:\n",
    "            if auc - auc_by_d[-2] < 0.001:\n",
    "                break\n",
    "            else:\n",
    "                best_d = d\n",
    "        else:\n",
    "            best_d = d\n",
    "    rf = RandomForestClassifier(n_estimators=200, criterion=\"entropy\",\n",
    "                                max_depth=best_d,\n",
    "                                random_state=0, n_jobs=-1, max_features=\"auto\",\n",
    "                                class_weight = calc_cw(train_df.grade))\n",
    "    rf.fit(train_df.loc[:,predictors_list], train_df.grade)\n",
    "    cstat_by_num.append(round(roc_auc_score(test_df.grade, rf.predict_proba(test_df.loc[:,predictors_list])[:,1]),4))\n",
    "    print(\"\\nC-statistic = {}\".format(cstat_by_num[-1]))\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7523, 0.8114, 0.8199, 0.8237, 0.8263]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cstat_by_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
