{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is used to find out how model performance changes with number of predictors for the admin-only, non-first-term model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from scipy.stats.mstats import gmean\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_dir = \"~\\\\Box Sync\\\\Clickstream\\\\evaluation_results\\\\full\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sn_dict = {\"Blue Ridge\": \"BRCC\",\n",
    "           \"Central Virginia\": \"CVCC\",\n",
    "           \"Dabney S. Lancaster\": \"DSLCC\",\n",
    "           \"Danville\": \"DCC\",\n",
    "           \"Eastern Shore\": \"ESCC\",\n",
    "           \"Germanna\": \"GCC\",\n",
    "           'J. Sargeant Reynolds': \"JSRCC\",\n",
    "           'John Tyler': \"JTCC\",\n",
    "           \"Lord Fairfax\": \"LFCC\",\n",
    "           \"Mountain Empire\": \"MECC\",\n",
    "           \"New River\": \"NRCC\",\n",
    "           \"Northern Virginia\": \"NVCC\",\n",
    "           \"Patrick Henry\": \"PHCC\",\n",
    "           \"Paul D. Camp\": \"PDCCC\",\n",
    "           \"Piedmont Virginia\": \"PVCC\",\n",
    "           \"Rappahannock\": \"RCC\",\n",
    "           \"Southside Virginia\": \"SSVCC\",\n",
    "           \"Southwest Virginia\": \"SWVCC\",\n",
    "           \"Thomas Nelson\": \"TNCC\",\n",
    "           \"Tidewater\": \"TCC\",\n",
    "           \"Virginia Highlands\": \"VHCC\",\n",
    "           \"Virginia Western\": \"VWCC\",\n",
    "           \"Wytheville\": \"WCC\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\LMS_data_final.dta\").loc[:,['vccsid','strm', 'college', 'course','section','grade']]\n",
    "df1 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\course_specific_predictors_new.csv\")\n",
    "df2 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\term_specific_predictors_new.csv\")\n",
    "for v in [int(e) for e in np.unique(df2.cip) if e != 0]:\n",
    "    df2.loc[:,'cip_'+str(v)] = (df2.cip == v).astype(int)\n",
    "for v in [int(e) for e in np.unique(df2.degree_level) if e != 4]:\n",
    "    df2.loc[:,'degree_level_'+str(v)] = (df2.degree_level == v).astype(int)\n",
    "df2 = df2.drop(['cip', 'degree_level'], axis=1)\n",
    "df3 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\cluster_specific_predictors.csv\")\n",
    "df4 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\instructor_related_predictors.dta\")\n",
    "df5 = df0.iloc[:,:5].copy()\n",
    "df5.loc[:,'college_new'] = df5.college.apply(lambda x: sn_dict[x])\n",
    "for sn in [e for e in sn_dict.values() if e != \"BRCC\"]:\n",
    "    df5.loc[:,'college_'+sn] = (df5.college_new == sn).astype(int)\n",
    "df5 = df5.drop(['college_new'], axis=1)\n",
    "df = df0.merge(df1, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df2, how='inner', on=['vccsid','strm'])\\\n",
    ".merge(df3, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df4, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df5, how='inner', on=['vccsid','strm','college','course','section'])\n",
    "predictors = list(df.columns)[6:]\n",
    "len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert pd.isnull(df).any().any() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(969025, 285)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(698361, 285) (270664, 285)\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df.strm != 2212]\n",
    "test_df = df[df.strm == 2212]\n",
    "original_test_grade = np.array(test_df.grade)\n",
    "train_df.loc[:,'grade'] = train_df.apply(lambda x: 1 if x.loc['grade'] in {'A','B','C'} else 0, axis=1)\n",
    "test_df.loc[:,'grade'] = test_df.apply(lambda x: 1 if x.loc['grade'] in {'A','B','C'} else 0, axis=1)\n",
    "print(train_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164245 87022\n"
     ]
    }
   ],
   "source": [
    "# Number of unique students in the sample\n",
    "print(len(np.unique(train_df.vccsid)), len(np.unique(test_df.vccsid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246 1989\n"
     ]
    }
   ],
   "source": [
    "print(len(np.unique(train_df.course)), len(np.unique(test_df.course)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7061 6037\n"
     ]
    }
   ],
   "source": [
    "# Number of unique college x course observations in the sample\n",
    "print(train_df.loc[:,['college', 'course']].drop_duplicates().shape[0],\n",
    "      test_df.loc[:,['college', 'course']].drop_duplicates().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9098\n"
     ]
    }
   ],
   "source": [
    "# Total number of unique college x course observations in the entire sample (training + test)\n",
    "print(pd.concat([train_df.loc[:,['college', 'course']], test_df.loc[:,['college', 'course']]]).drop_duplicates().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2639"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.union1d(np.unique(train_df.course), np.unique(test_df.course)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# raw_predictors = {\\\n",
    "# 10: 'pct_withdrawn, crnt_enrl_intensity, cum_gpa, term_gpa_1, has_term_gpa_1, past_avg_grade, has_past_avg_grade, avg_g, term_gpa_2, has_term_gpa_2',\n",
    "# 20: 'overall_prop_comp, avg_g_concurrent, has_avg_g_concurrent, gpa_trend, cum_cred_earn, prop_comp_sd, section_size, enrl_intensity_trend, enrl_intensity, age',\n",
    "# 30: 'pct_stopped, lvl2_share, pct_dev, num_of_prior_terms, online_share, eve_share, HUM_SOC_grade, HUM_SOC, HUM_HUM_grade, HUM_HUM',\n",
    "# 40: 'prereq_grade, has_prereq_grade, pct_incomplete, SOC_SOC_grade, SOC_SOC, full_time, HUM_SCI_grade, HUM_SCI, online_ind, summer_ind',\n",
    "# 50: 'tenure, college_NVCC, SOC_HUM_grade, SOC_HUM, HUM_MTH_grade, HUM_MTH, SOC_SCI_grade, SOC_SCI, lvl2_ind, cip_24',\n",
    "# 60: 'ever_dual, degree_level_1, SCI_SCI_grade, SCI_SCI, MTH_SCI_grade, MTH_SCI, MTH_SOC_grade, MTH_SOC, MTH_HUM_grade, MTH_HUM',\n",
    "# 70: 'HUM_EGR_grade, HUM_EGR, has_repeat_grade, repeat_grade, college_TCC, HUM_MED_grade, HUM_MED, EGR_EGR_grade, EGR_EGR, degree_level_2',\n",
    "# 80: 'SOC_MTH_grade, SOC_MTH, SCI_SOC_grade, SCI_SOC, SCI_MED_grade, SCI_MED, MTH_MTH_grade, MTH_MTH, EGR_SOC_grade, EGR_SOC',\n",
    "# 90: 'cip_52, EGR_HUM_grade, EGR_HUM, SCI_HUM_grade, SCI_HUM, MED_MED_grade, MED_MED, cip_30, MTH_EGR_grade, MTH_EGR',\n",
    "# 100: 'SOC_EGR_grade, SOC_EGR, SOC_MED_grade, SOC_MED, eve_ind, EGR_SCI_grade, EGR_SCI, MED_SCI_grade, MED_SCI, dev',\n",
    "# 110: 'MED_SOC_grade, MED_SOC, cip_11, MED_HUM_grade, MED_HUM, SCI_MTH_grade, SCI_MTH, cip_45, cip_51, college_JSRCC',\n",
    "# 120: 'EGR_MTH_grade, EGR_MTH, HUM_BUS_grade, HUM_BUS, college_TNCC, college_JTCC, college_GCC, degree_level_3, MTH_MED_grade, MTH_MED',\n",
    "# 130: 'HUM_ART_grade, HUM_ART, BUS_BUS_grade, BUS_BUS, ART_SOC_grade, ART_SOC, SOC_BUS_grade, SOC_BUS, ART_SCI_grade, ART_SCI',\n",
    "# 140: 'BUS_SOC_grade, BUS_SOC, college_LFCC, SCI_EGR_grade, SCI_EGR, BUS_HUM_grade, BUS_HUM, ART_HUM_grade, ART_HUM, college_VWCC',\n",
    "# 150: 'MTH_BUS_grade, MTH_BUS, cip_14, MED_EGR_grade, MED_EGR, college_PVCC, MED_MTH_grade, MED_MTH, EGR_BUS_grade, EGR_BUS',\n",
    "# 160: 'SOC_ART_grade, SOC_ART, BUS_SCI_grade, BUS_SCI, FLA_HUM_grade, FLA_HUM, cip_43, BUS_EGR_grade, BUS_EGR, college_NRCC',\n",
    "# 170: 'ART_EGR_grade, ART_EGR, ART_MTH_grade, ART_MTH, BUS_MTH_grade, BUS_MTH, EGR_MED_grade, EGR_MED, FLA_SCI_grade, FLA_SCI',\n",
    "# 180: 'FLA_SOC_grade, FLA_SOC, MTH_ART_grade, MTH_ART, college_SWVCC, cip_50, college_CVCC, cip_99, college_PHCC, college_DCC',\n",
    "# 190: 'SCI_BUS_grade, SCI_BUS, OCC_OCC_grade, OCC_OCC, ART_ART_grade, ART_ART, cip_15, college_SSVCC, FLA_MTH_grade, FLA_MTH',\n",
    "# 200: 'MED_BUS_grade, MED_BUS, college_MECC, college_RCC, college_VHCC, college_WCC, EGR_ART_grade, EGR_ART, HUM_OCC_grade, HUM_OCC',\n",
    "# 210: 'SCI_ART_grade, SCI_ART, FLA_EGR_grade, FLA_EGR, OCC_HUM_grade, OCC_HUM, cip_19, HUM_FLA_grade, HUM_FLA, cip_47',\n",
    "# 220: 'ART_BUS_grade, ART_BUS, MED_ART_grade, MED_ART, OCC_EGR_grade, OCC_EGR, ART_MED_grade, ART_MED, SOC_FLA_grade, SOC_FLA',\n",
    "# 230: 'BUS_MED_grade, BUS_MED, OCC_SOC_grade, OCC_SOC, college_PDCCC, cip_42, OCC_SCI_grade, OCC_SCI, MTH_OCC_grade, MTH_OCC',\n",
    "# 240: 'MTH_FLA_grade, MTH_FLA, BUS_ART_grade, BUS_ART, SOC_OCC_grade, SOC_OCC, EGR_OCC_grade, EGR_OCC, college_DSLCC, college_ESCC',\n",
    "# 250: 'OCC_MTH_grade, OCC_MTH, FLA_BUS_grade, FLA_BUS, FLA_MED_grade, FLA_MED, SCI_FLA_grade, SCI_FLA, FLA_FLA_grade, FLA_FLA',\n",
    "# 259: 'cip_48, EGR_FLA_grade, EGR_FLA, FLA_ART_grade, FLA_ART, MED_FLA_grade, MED_FLA, SCI_OCC_grade, SCI_OCC',\n",
    "# 269: 'OCC_MED_grade, OCC_MED, MED_OCC_grade, MED_OCC, OCC_BUS_grade, OCC_BUS, ART_FLA_grade, ART_FLA, OCC_ART_grade, OCC_ART',\n",
    "# 279: 'BUS_FLA_grade, BUS_FLA, BUS_OCC_grade, BUS_OCC, ART_OCC_grade, ART_OCC, FLA_OCC_grade, FLA_OCC, OCC_FLA_grade, OCC_FLA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_predictors = {\\\n",
    "5: 'pct_withdrawn, crnt_enrl_intensity, cum_gpa, term_gpa_1, has_term_gpa_1',\n",
    "15: 'past_avg_grade, has_past_avg_grade, avg_g, term_gpa_2, has_term_gpa_2, overall_prop_comp, avg_g_concurrent, has_avg_g_concurrent, gpa_trend, cum_cred_earn',\n",
    "25: 'prop_comp_sd, section_size, enrl_intensity_trend, enrl_intensity, age, pct_stopped, lvl2_share, pct_dev, num_of_prior_terms, online_share',\n",
    "35: 'eve_share, HUM_SOC_grade, HUM_SOC, HUM_HUM_grade, HUM_HUM, prereq_grade, has_prereq_grade, pct_incomplete, SOC_SOC_grade, SOC_SOC',\n",
    "45: 'full_time, HUM_SCI_grade, HUM_SCI, online_ind, summer_ind, tenure, college_NVCC, SOC_HUM_grade, SOC_HUM, lvl2_ind'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_predictors = {}\n",
    "for k,v in raw_predictors.items():\n",
    "    clean_predictors[k] = [p.strip() for p in v.split(\",\")]\n",
    "num_of_predictors = sorted(list(clean_predictors.keys()))\n",
    "clean_predictors_2 = {}\n",
    "for k,v in clean_predictors.items():\n",
    "    clean_predictors_2[k] = []\n",
    "    for n in num_of_predictors:\n",
    "        if n <= k:\n",
    "            clean_predictors_2[k] += clean_predictors[n]\n",
    "    assert len(clean_predictors_2[k]) == k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cv_folds(train, predictors, n_fold = 5):\n",
    "    folds = []\n",
    "    k_fold = StratifiedKFold(n_splits = n_fold, random_state = 12345, shuffle=True)\n",
    "    for train_indices, test_indices in k_fold.split(train, train.grade):\n",
    "        train_part = train.iloc[train_indices,:]\n",
    "        test_part = train.iloc[test_indices,:]\n",
    "        X_1 = train_part.loc[:,predictors]\n",
    "        y_1 = train_part.grade\n",
    "        X_2 = test_part.loc[:,predictors]\n",
    "        y_2 = test_part.grade\n",
    "        folds.append([(X_1.copy(),y_1.copy()),(X_2.copy(),y_2.copy())])\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_RF(rf_model, folds):\n",
    "    auc_by_fold = []\n",
    "    for f in folds:\n",
    "        X_1 = f[0][0]\n",
    "        y_1 = f[0][1]\n",
    "        X_2 = f[1][0]\n",
    "        y_2 = f[1][1]\n",
    "        rf_model.fit(X_1,y_1)\n",
    "        y_2_pred = rf_model.predict_proba(X_2)[:,1]\n",
    "        auc_by_fold.append(roc_auc_score(y_2,y_2_pred))\n",
    "    return round(np.mean(auc_by_fold),4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_cw(y):\n",
    "    # Calculate the weight of each letter grade to be used in the modeling fitting procedure: the weight is inversely proportional to the square root of the frequency of the letter grade in the training sample\n",
    "    cw = Counter(y)\n",
    "    class_weight = {k:np.sqrt(cw.most_common()[0][-1]/v, dtype=np.float32) for k,v in cw.items()}\n",
    "    return class_weight # The output is a dictionary mapping letter grade to the corresponding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 5:\n",
      "\n",
      "max_depth = 5: 0.7997\n",
      "max_depth = 6: 0.8017\n",
      "max_depth = 7: 0.8037\n",
      "max_depth = 8: 0.8055\n",
      "max_depth = 9: 0.8074\n",
      "max_depth = 10: 0.8094\n",
      "max_depth = 11: 0.8118\n",
      "max_depth = 12: 0.8147\n",
      "max_depth = 13: 0.818\n",
      "max_depth = 14: 0.8217\n",
      "max_depth = 15: 0.8257\n",
      "max_depth = 16: 0.8298\n",
      "max_depth = 17: 0.8336\n",
      "max_depth = 18: 0.837\n",
      "max_depth = 19: 0.8399\n",
      "max_depth = 20: 0.8418\n",
      "max_depth = 21: 0.8431\n",
      "max_depth = 22: 0.8438\n",
      "\n",
      "C-statistic = 0.8216\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "n = 15:\n",
      "\n",
      "max_depth = 5: 0.8104\n",
      "max_depth = 6: 0.815\n",
      "max_depth = 7: 0.8188\n",
      "max_depth = 8: 0.8225\n",
      "max_depth = 9: 0.8256\n",
      "max_depth = 10: 0.8283\n",
      "max_depth = 11: 0.831\n",
      "max_depth = 12: 0.8334\n",
      "max_depth = 13: 0.836\n",
      "max_depth = 14: 0.8389\n",
      "max_depth = 15: 0.8418\n",
      "max_depth = 16: 0.845\n",
      "max_depth = 17: 0.848\n",
      "max_depth = 18: 0.851\n",
      "max_depth = 19: 0.8541\n",
      "max_depth = 20: 0.857\n",
      "max_depth = 21: 0.8593\n",
      "max_depth = 22: 0.8613\n",
      "max_depth = 23: 0.863\n",
      "max_depth = 24: 0.8646\n",
      "max_depth = 25: 0.8657\n",
      "max_depth = 26: 0.8667\n",
      "max_depth = 27: 0.8675\n",
      "\n",
      "C-statistic = 0.8437\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "n = 25:\n",
      "\n",
      "max_depth = 5: 0.8101\n",
      "max_depth = 6: 0.8154\n",
      "max_depth = 7: 0.821\n",
      "max_depth = 8: 0.8253\n",
      "max_depth = 9: 0.8293\n",
      "max_depth = 10: 0.833\n",
      "max_depth = 11: 0.8366\n",
      "max_depth = 12: 0.84\n",
      "max_depth = 13: 0.8439\n",
      "max_depth = 14: 0.8479\n",
      "max_depth = 15: 0.852\n",
      "max_depth = 16: 0.8561\n",
      "max_depth = 17: 0.8601\n",
      "max_depth = 18: 0.864\n",
      "max_depth = 19: 0.8673\n",
      "max_depth = 20: 0.8703\n",
      "max_depth = 21: 0.8728\n",
      "max_depth = 22: 0.8748\n",
      "max_depth = 23: 0.8763\n",
      "max_depth = 24: 0.8775\n",
      "max_depth = 25: 0.8785\n",
      "max_depth = 26: 0.8791\n",
      "\n",
      "C-statistic = 0.8513\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "n = 35:\n",
      "\n",
      "max_depth = 5: 0.8058\n",
      "max_depth = 6: 0.8128\n",
      "max_depth = 7: 0.8173\n",
      "max_depth = 8: 0.8221\n",
      "max_depth = 9: 0.8264\n",
      "max_depth = 10: 0.8302\n",
      "max_depth = 11: 0.8339\n",
      "max_depth = 12: 0.8375\n",
      "max_depth = 13: 0.8414\n",
      "max_depth = 14: 0.845\n",
      "max_depth = 15: 0.8489\n",
      "max_depth = 16: 0.8529\n",
      "max_depth = 17: 0.8567\n",
      "max_depth = 18: 0.8606\n",
      "max_depth = 19: 0.864\n",
      "max_depth = 20: 0.8672\n",
      "max_depth = 21: 0.8699\n",
      "max_depth = 22: 0.8724\n",
      "max_depth = 23: 0.8744\n",
      "max_depth = 24: 0.8761\n",
      "max_depth = 25: 0.8776\n",
      "max_depth = 26: 0.8789\n",
      "max_depth = 27: 0.8797\n",
      "\n",
      "C-statistic = 0.8529\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "n = 45:\n",
      "\n",
      "max_depth = 5: 0.8065\n",
      "max_depth = 6: 0.8121\n",
      "max_depth = 7: 0.8174\n",
      "max_depth = 8: 0.8223\n",
      "max_depth = 9: 0.8265\n",
      "max_depth = 10: 0.8306\n",
      "max_depth = 11: 0.8344\n",
      "max_depth = 12: 0.8383\n",
      "max_depth = 13: 0.842\n",
      "max_depth = 14: 0.8459\n",
      "max_depth = 15: 0.8499\n",
      "max_depth = 16: 0.8539\n",
      "max_depth = 17: 0.8579\n",
      "max_depth = 18: 0.8616\n",
      "max_depth = 19: 0.8652\n",
      "max_depth = 20: 0.8682\n",
      "max_depth = 21: 0.8712\n",
      "max_depth = 22: 0.8737\n",
      "max_depth = 23: 0.8758\n",
      "max_depth = 24: 0.8775\n",
      "max_depth = 25: 0.8789\n",
      "max_depth = 26: 0.8799\n",
      "max_depth = 27: 0.8807\n",
      "\n",
      "C-statistic = 0.854\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cstat_by_num = []\n",
    "for n in sorted(list(clean_predictors_2.keys())):\n",
    "    print(\"n = {}:\\n\".format(n))\n",
    "    predictors_list = clean_predictors_2[n]\n",
    "    five_folds = create_cv_folds(train_df, predictors_list)\n",
    "    auc_by_d=[]\n",
    "    for d in range(5,36):\n",
    "        rf = RandomForestClassifier(n_estimators=200, criterion=\"entropy\", \n",
    "                                    max_depth=d,\n",
    "                                    random_state=0, n_jobs=20, max_features=\"auto\",\n",
    "                                    class_weight = calc_cw(train_df.grade))\n",
    "        auc = cross_validation_RF(rf, five_folds)\n",
    "        auc_by_d.append(auc)\n",
    "        print(\"max_depth = {0}: {1}\".format(d, auc))\n",
    "        if d > 5:\n",
    "            if auc - auc_by_d[-2] < 0.001:\n",
    "                break\n",
    "            else:\n",
    "                best_d = d\n",
    "        else:\n",
    "            best_d = d\n",
    "    rf = RandomForestClassifier(n_estimators=200, criterion=\"entropy\",\n",
    "                                max_depth=best_d,\n",
    "                                random_state=0, n_jobs=-1, max_features=\"auto\",\n",
    "                                class_weight = calc_cw(train_df.grade))\n",
    "    rf.fit(train_df.loc[:,predictors_list], train_df.grade)\n",
    "    cstat_by_num.append(round(roc_auc_score(test_df.grade, rf.predict_proba(test_df.loc[:,predictors_list])[:,1]),4))\n",
    "    print(\"\\nC-statistic = {}\".format(cstat_by_num[-1]))\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8216, 0.8437, 0.8513, 0.8529, 0.854]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cstat_by_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
