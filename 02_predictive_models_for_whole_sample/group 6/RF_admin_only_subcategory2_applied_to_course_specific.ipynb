{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script applies the models  which only include the term-specific and demographic admin predictors constructed using the non-first-term observations to the 5 selected courses at VCCS, and generates the key evaluation metrics for each course-specific validation sample (including both first-term and non-first-term ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from scipy.stats.mstats import gmean\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_dir = \"~\\\\Box Sync\\\\Clickstream\\\\evaluation_results\\\\full\\\\updated\\\\\"\n",
    "results_dir_2 = \"~\\\\Box Sync\\\\Clickstream\\\\evaluation_results\\\\first\\\\updated\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sn_dict = {\"Blue Ridge\": \"BRCC\",\n",
    "           \"Central Virginia\": \"CVCC\",\n",
    "           \"Dabney S. Lancaster\": \"DSLCC\",\n",
    "           \"Danville\": \"DCC\",\n",
    "           \"Eastern Shore\": \"ESCC\",\n",
    "           \"Germanna\": \"GCC\",\n",
    "           'J. Sargeant Reynolds': \"JSRCC\",\n",
    "           'John Tyler': \"JTCC\",\n",
    "           \"Lord Fairfax\": \"LFCC\",\n",
    "           \"Mountain Empire\": \"MECC\",\n",
    "           \"New River\": \"NRCC\",\n",
    "           \"Northern Virginia\": \"NVCC\",\n",
    "           \"Patrick Henry\": \"PHCC\",\n",
    "           \"Paul D. Camp\": \"PDCCC\",\n",
    "           \"Piedmont Virginia\": \"PVCC\",\n",
    "           \"Rappahannock\": \"RCC\",\n",
    "           \"Southside Virginia\": \"SSVCC\",\n",
    "           \"Southwest Virginia\": \"SWVCC\",\n",
    "           \"Thomas Nelson\": \"TNCC\",\n",
    "           \"Tidewater\": \"TCC\",\n",
    "           \"Virginia Highlands\": \"VHCC\",\n",
    "           \"Virginia Western\": \"VWCC\",\n",
    "           \"Wytheville\": \"WCC\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\updated\\\\LMS_data_final.dta\").loc[:,['vccsid','strm', 'college', 'course','section','grade']]\n",
    "df1 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\updated\\\\course_specific_predictors_new.csv\")\n",
    "df2 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\updated\\\\term_specific_predictors_new.csv\")\n",
    "for v in [int(e) for e in np.unique(df2.cip) if e != 0]:\n",
    "    df2.loc[:,'cip_'+str(v)] = (df2.cip == v).astype(int)\n",
    "for v in [int(e) for e in np.unique(df2.degree_level) if e != 4]:\n",
    "    df2.loc[:,'degree_level_'+str(v)] = (df2.degree_level == v).astype(int)\n",
    "df2 = df2.drop(['cip', 'degree_level'], axis=1)\n",
    "df3 = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\updated\\\\cluster_specific_predictors.csv\")\n",
    "df4 = pd.read_stata(\"~\\\\Box Sync\\\\Clickstream\\\\data\\\\full\\\\updated\\\\instructor_related_predictors.dta\")\n",
    "df5 = df0.iloc[:,:5].copy()\n",
    "df5.loc[:,'college_new'] = df5.college.apply(lambda x: sn_dict[x])\n",
    "for sn in [e for e in sn_dict.values() if e != \"BRCC\"]:\n",
    "    df5.loc[:,'college_'+sn] = (df5.college_new == sn).astype(int)\n",
    "df5 = df5.drop(['college_new'], axis=1)\n",
    "df = df0.merge(df1, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df2, how='inner', on=['vccsid','strm'])\\\n",
    ".merge(df3, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df4, how='inner', on=['vccsid','strm','college','course','section'])\\\n",
    ".merge(df5, how='inner', on=['vccsid','strm','college','course','section'])\n",
    "predictors = list(df.columns)[6:]\n",
    "len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert pd.isnull(df).any().any() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(969025, 285)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(698361, 285) (270664, 285)\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df.strm != 2212]\n",
    "test_df = df[df.strm == 2212]\n",
    "original_test_grade = np.array(test_df.grade)\n",
    "train_df.loc[:,'grade'] = train_df.apply(lambda x: 1 if x.loc['grade'] in {'A','B','C'} else 0, axis=1)\n",
    "test_df.loc[:,'grade'] = test_df.apply(lambda x: 1 if x.loc['grade'] in {'A','B','C'} else 0, axis=1)\n",
    "print(train_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_category = pd.read_csv(\"~\\\\Box Sync\\\\Clickstream\\\\evaluation_results\\\\first\\\\updated\\\\predictor_category_table.csv\")\n",
    "predictor_df = pd.DataFrame({'predictor': predictors}).merge(predictor_category, how='inner', on=['predictor'])\n",
    "predictor_df = predictor_df[predictor_df.predictor_subcategory.apply(lambda x: x not in {'Course-specific', 'Course-subject-specific', 'Instructor-related'})]\n",
    "predictors = list(predictor_df.predictor)\n",
    "len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_cw(y):\n",
    "    # Calculate the weight of each letter grade to be used in the modeling fitting procedure: the weight is inversely proportional to the square root of the frequency of the letter grade in the training sample\n",
    "    cw = Counter(y)\n",
    "    class_weight = {k:np.sqrt(cw.most_common()[0][-1]/v, dtype=np.float32) for k,v in cw.items()}\n",
    "    return class_weight # The output is a dictionary mapping letter grade to the corresponding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight={0: 1.9044098, 1: 1.0},\n",
       "            criterion='entropy', max_depth=20, max_features=7,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=200, n_jobs=-1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, criterion=\"entropy\",\n",
    "                            max_depth=20,\n",
    "                            random_state=0, n_jobs=-1, max_features=7,\n",
    "                            class_weight = calc_cw(train_df.grade))\n",
    "rf.fit(train_df.loc[:,predictors], train_df.grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in ['ENG_111', 'ENG_112', 'BIO_101', 'MTH_154', 'MTH_161']:\n",
    "    test_df_sub = test_df[test_df.course == c]\n",
    "    original = list(original_test_grade[test_df.course == c])\n",
    "    y_test_pred = list(rf.predict_proba(test_df_sub.loc[:,predictors])[:,1])\n",
    "    y_test_real = list(test_df_sub.grade)\n",
    "    y_df = pd.DataFrame({'pred_y': y_test_pred, 'real_y': y_test_real, 'grade': original,\n",
    "                         'first_ind': [0]*len(y_test_pred)})\n",
    "    y_df.to_csv(results_dir + \"{}_admin_only_subcategory2.csv\".format(c), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5487180019514506\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_rf = rf.predict_proba(test_df.loc[:,predictors])[:,1]\n",
    "best_threshold = np.sort(y_test_pred_rf)[int(len(y_test_pred_rf) * (1-np.mean(train_df.grade)))-1]\n",
    "print(best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_threshold_2 = 0.5561843232193934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_confusion_matrix(y_real, y_pred, y_pred_2, original_test_grade, best_threshold, best_threshold_2, fname):\n",
    "    cm_arr = confusion_matrix(y_real, np.concatenate([np.where(y_pred > best_threshold, 1, 0), np.where(y_pred_2 > best_threshold_2, 1, 0)]))\n",
    "    cm_df = pd.DataFrame(cm_arr, columns=['Pred_DFW','Pred_ABC'], index=['Actual_DFW', 'Actual_ABC'])\n",
    "    cm_df.loc[:,''] = cm_df.sum(axis=1)\n",
    "    cm_df.loc['',:] = cm_df.sum(axis=0)\n",
    "    p1 = cm_df.iloc[1,1]/cm_df.iloc[2,1]\n",
    "    r1 = cm_df.iloc[1,1]/cm_df.iloc[1,2]\n",
    "    p0 = cm_df.iloc[0,0]/cm_df.iloc[2,0]\n",
    "    r0 = cm_df.iloc[0,0]/cm_df.iloc[0,2] \n",
    "    y_pred_bin = np.concatenate([np.where(y_pred > best_threshold, 1, 0), np.where(y_pred_2 > best_threshold_2, 1, 0)])\n",
    "    cm_dict = {}\n",
    "    cm_dict['Pred_DFW'] = Counter(original_test_grade[np.where(y_pred_bin==0)[0]])\n",
    "    cm_dict['Pred_ABC'] = Counter(original_test_grade[np.where(y_pred_bin==1)[0]])\n",
    "    new_cm = pd.DataFrame.from_dict(cm_dict, orient='index').T.loc[['W','F','D','C','B','A'],['Pred_DFW','Pred_ABC']]\n",
    "    new_cm.index = [\"Actual_\"+e for e in new_cm.index]\n",
    "    new_cm.loc[:,''] = new_cm.sum(axis=1)\n",
    "    new_cm.loc['',:] = new_cm.sum(axis=0)\n",
    "    new_cm.to_csv(results_dir + fname + \"_6x2.csv\")\n",
    "    return round(p1,4),round(r1,4),round(p0,4),round(r0,4),round(2*p1*r1/(p1+r1),4),round(2*p0*r0/(p0+r0),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENG_111\n",
      "AUC = 0.7601\n",
      "(0.7477, 0.6744, 0.5848, 0.6683, 0.7091, 0.6238)\n",
      "ENG_112\n",
      "AUC = 0.8276\n",
      "(0.8593, 0.8457, 0.5711, 0.5974, 0.8524, 0.584)\n",
      "BIO_101"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:842: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:842: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:842: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC = 0.8248\n",
      "(0.8401, 0.8373, 0.5981, 0.603, 0.8387, 0.6005)\n",
      "MTH_154\n",
      "AUC = 0.7854\n",
      "(0.76, 0.7628, 0.6258, 0.6222, 0.7614, 0.624)\n",
      "MTH_161\n",
      "AUC = 0.7704\n",
      "(0.7269, 0.7674, 0.6526, 0.6023, 0.7466, 0.6264)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:842: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:842: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n"
     ]
    }
   ],
   "source": [
    "for c in ['ENG_111', 'ENG_112', 'BIO_101', 'MTH_154', 'MTH_161']:\n",
    "    t1 = pd.read_csv(results_dir + \"{}_admin_only_subcategory2.csv\".format(c))\n",
    "    t2 = pd.read_csv(results_dir_2 + \"{}_admin_only_subcategory2.csv\".format(c))\n",
    "    t = pd.concat([t1, t2])\n",
    "    print(c)\n",
    "    print(\"AUC = {}\".format(round(roc_auc_score(t.real_y, t.pred_y),4)))\n",
    "    pr_rf = create_confusion_matrix(np.array(t.real_y), np.array(t1.pred_y), np.array(t2.pred_y), t.grade, best_threshold, best_threshold_2, \"admin_only_subcategory2_applied_to_{}_cm\".format(c))\n",
    "    print(pr_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
